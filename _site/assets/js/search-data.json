{"0": {
    "doc": "About",
    "title": "About",
    "content": "Sequencing Techniques Portfolio . This portfolio showcases a variety of approaches to sequencing technology, focusing on the data processing and analysis of different samples. The purpose of this repository is not to present a single tool, but to display the range of techniques and coding strategies I have employed in my research. Each directory or section of this repository corresponds to different sequencing projects, including but not limited to RNA-seq and ChIP-seq analyses. These projects demonstrate how I handle diverse data sets and apply unique analysis methodologies. This portfolio is broadly organized into two main categories: Data Processing and Data Analysis (RNA/ChIP-seq). ",
    "url": "/docs/About/",
    
    "relUrl": "/docs/About/"
  },"1": {
    "doc": "About",
    "title": "Table of Contents",
    "content": "Data Processing . | Basal QC with FastQC | Trimmed reads with Trimmomatic | Mapping reads with HISAT2 for RNA-seq | Mapping reads with Bowtie2 for ChIP-seq | File Conversion and Management with SAMtools | Feature counts with htseqCount | File storage with Genozip | Basal setting and troubleshooting | . Data Analysis - RNA-seq . | Normalization and DEG analysis with edgeR | DEG: Correlation plot | DEG: Visualization | DEG: Gene ontology and KEGG pathway analysis | DEG: Heatmap | . Data Analysis - ChIP-seq . | Exploring Sequencing Data with deepTools | Efficient Analysis and Visualization of ChIP-seq Data with ngs.plot | Peak detection: MACS3 | Peak detection: SICER2 | Peak Annotation with ChIPseeker | Motif analysis with HOMER and MEME | . Data Science - Animal Locomotion Analysis WIP . | Tracking Animal Movement with R | Converting Tracking Data to Coordinates and Calculating Physical Properties Using Python | Plotting the Results with R | . ",
    "url": "/docs/About/#table-of-contents",
    
    "relUrl": "/docs/About/#table-of-contents"
  },"2": {
    "doc": "About",
    "title": "Featured Projects",
    "content": "Project 1: Identification of Gene Expression and Chromatin Dynamics Changes During Oxidative Stress . | Description: In this project, we explored the effects of hydrogen peroxide-induced oxidative stress in a normal human keratinocyte cell line and three knockdown cell lines. We identified crucial changes in gene expression and chromatin dynamics of H3K4/H3K27me3, shedding light on the cellular mechanisms that activate NRF2-defense programs under oxidative stress. | Techniques Used: RNA-seq and ChIP-seq | Key Finding: Choi J &amp; Lee H. Free Radic. Biol. Med. 217 (2024): 48-59. Pubmed | Dataset: Access the detailed datasets from GEO SuperSeries GSE250128, including SubSeries GSE250126 and GSE250127. | . Project 2: Establishing the Chromatin Landscape Regulating Stemness in Mesenchymal Stem Cells . | Description: We examined gene expression and chromatin alterations in normal and knockdown mesenchymal stem cell (MSC) lines exposed to differentiation stimuli. Our advanced bioinformatics analysis showed the critical roles of lineage-specific transcription factors and histone-modifying enzymes in maintaining MSC stemness and identity. | Techniques Used: RNA-seq and ChIP-seq | Key Findings: Choi J &amp; Lee H. J. Biol. Chem. 299.10 (2023). Pubmed, Choi J &amp; Lee H. Sci. Rep. 10.1 (2020): 3050. Pubmed | Datasets: Further explore our findings with GEO SuperSeries GSE227538 and GSE131369. | . Project 3: Comparative Transcriptome Analysis in Young vs. Middle-Aged Zebrafish Brains . | Description: We compared whole brain transcriptomes from 3-month-old and 12-month-old zebrafish to identify significant gene expression changes related to aging. | Techniques Used: RNA-seq | Status: The research findings are currently being prepared for submission. Upon acceptance of the paper, the dataset will be released to the public. | . Project 4: Robust Link Between Gene Expression and Histone Dynamics During Short-Day Treatment in Plants . | Description: We studied gene expression and histone acetylation in normal and knockout plants under short-day (SD) treatment to reveal the epigenetic mechanisms that trigger flowering. | Techniques Used: RNA-seq and ChIP-seq | Status: The research findings are currently being prepared for submission. Upon acceptance of the paper, the dataset will be released to the public. | . ",
    "url": "/docs/About/#featured-projects",
    
    "relUrl": "/docs/About/#featured-projects"
  },"3": {
    "doc": "About",
    "title": "Implications of This Portfolio",
    "content": "This portfolio not only showcases a range of sophisticated sequencing techniques but also serves as a testament to my commitment to rigorous data analysis and innovative problem-solving in the field of genomics. The methodologies and strategies demonstrated here reflect my ability to adapt and optimize processes to meet the challenges presented by diverse datasets. For newcomers to sequencing, this portfolio will act as a valuable learning resource. It offers practical examples and workflows that clarify RNA-seq and ChIP-seq analysis complexities. Sharing these insights allows me to support the broader community and help others master the latest sequencing technologies. Furthermore, my work highlights the importance of transparency and reproducibility in scientific research. Each project within this repository is documented in a way that not only facilitates understanding but also enables others to replicate the results, fostering a culture of open science. In conclusion, through this portfolio, I aim to demonstrate not just the technical skills necessary for high-quality genomic analysis but also my enthusiasm for advancing the field and educating others. I believe that the tools and techniques provided here will be invaluable for anyone looking to deepen their understanding of sequencing and its applications in modern biology. ",
    "url": "/docs/About/#implications-of-this-portfolio",
    
    "relUrl": "/docs/About/#implications-of-this-portfolio"
  },"4": {
    "doc": "About",
    "title": "About This portfolio",
    "content": ". | Content License Copyright © 2020-2024 Janghyun Choi, Licensed under CC BY-NC-SA 4.0 | Design License Copyright © 2017-2024 Patrick Marsceill, Distributed under an MIT license. | . ",
    "url": "/docs/About/#about-this-portfolio",
    
    "relUrl": "/docs/About/#about-this-portfolio"
  },"5": {
    "doc": "Barcode Generator",
    "title": "바코드 형성기(CODE 39)",
    "content": "xxxx-xx-xx-xxxx에서 하이픈 제거하고 입력하세요. 가로 길이 조절(Barcode Width): 2 세로 길이 조절(Barcode Height): 100 . ",
    "url": "/docs/BarGen/",
    
    "relUrl": "/docs/BarGen/"
  },"6": {
    "doc": "Barcode Generator",
    "title": "Barcode Generator",
    "content": "Real-Time Code 39 Barcode Generator . ",
    "url": "/docs/BarGen/",
    
    "relUrl": "/docs/BarGen/"
  },"7": {
    "doc": "Mapping reads with Bowtie2 for ChIP-seq",
    "title": "Alignment with Reference Genome using bowtie2",
    "content": "Bowtie2 that is an ultrafast and memory-efficient tool coded in python can be aligned sequencing reads to long reference genomes. Notably, Bowtie is suitable for ChIP-seq or ATAC-seq, but not RNA-seq. If you have to analyze transcriptome, go to the section on RNA-seq using HISAT2 tool. Bowtie can run on any computer installed on Linux or macOS and works in python version &gt; 2.6. This protocol was created based on Bowtie2 version 2.5.1 running on a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes Python version 3.8.5, SciPy version 1.6.2, NumPy version 1.20.1, and pySam version 0.16.0.1 under macOS 12.4 environment. This course takes very long time and spends a lot of RAM and CPU resource. ",
    "url": "/docs/DataProcess/Bowtie2_MANUAL/#alignment-with-reference-genome-using-bowtie2",
    
    "relUrl": "/docs/DataProcess/Bowtie2_MANUAL/#alignment-with-reference-genome-using-bowtie2"
  },"8": {
    "doc": "Mapping reads with Bowtie2 for ChIP-seq",
    "title": "Installation bowtie2",
    "content": ". To install bowtie2 using homebrew, use the following command: . $ brew install bowtie2 . ",
    "url": "/docs/DataProcess/Bowtie2_MANUAL/#installation-bowtie2",
    
    "relUrl": "/docs/DataProcess/Bowtie2_MANUAL/#installation-bowtie2"
  },"9": {
    "doc": "Mapping reads with Bowtie2 for ChIP-seq",
    "title": "Establish Genome Builder",
    "content": "bowtie2-build builds a bowtie index from a set of DNA sequence. This builder consists of a set of 6 files with suffixes .1.bt2, .2.bt2, .3.bt2, .4.bt2, .rev.1.bt2, and .rev.2.bt2. These files together constitute the index for the alignment reads to that reference. You can download from the index section of official website all the files for a given assembly as a single zip file, or as 6 seperate bt2 files. There are two types of genome builder method; manual and automatic. | Automatic method: uncompress builder files and uses ‘bowtie2-build’ or ‘make_XX_.sh’ syntax. For more information, refer to Bowtie2’s manual. | Manual method: uncompress builder files and moves them to the desired path. | . the build step is a prerequisite for the main sequence. Unlike “HISAT2”, this tool provides index files for most species from the index zone of official site. ",
    "url": "/docs/DataProcess/Bowtie2_MANUAL/#establish-genome-builder",
    
    "relUrl": "/docs/DataProcess/Bowtie2_MANUAL/#establish-genome-builder"
  },"10": {
    "doc": "Mapping reads with Bowtie2 for ChIP-seq",
    "title": "Running bowtie2",
    "content": "Use the following command to perform mapping to the genome with bowtie2: . # Usage for single-end $ bowtie2 -x &lt;GenomeBuilder&gt; -U &lt;reads.fq&gt; -S &lt;output.sam&gt; --&lt;mode&gt; --&lt;preset&gt; -p &lt;int&gt; # Usage for pair-end $ bowtie2 -x &lt;GenomeBuilder&gt; -1 &lt;forward_reads.fq&gt; -2 &lt;reverse_reads.fq&gt; \\ -S &lt;output.sam&gt; --&lt;mode&gt; --&lt;preset&gt; -p &lt;int&gt; . In these commands, . | Parameter | Description | . | -x &lt;GenomeBuilder&gt; | Specifies the reference genome as the builder format. | . | -U &lt;reads.fq&gt; (only SE mode) | Specifies input read sequence. Possible file types is fastq formats (fastq or fq). | . | -1 and -2 (only PE mode) | Specifies forward input read and reverse input read, respectively. | . | -S &lt;output.sam&gt; | Specifies output file. | . | --&lt;mode&gt;&gt; option | Bowtie2 provides two algorithms for maaping reads to the genome. The end-to-end mode (--end-to-end, default) aligns the entire length of reads to the reference genome, utilizing all available information. In contrast, the local mode (--local) flexibly aligns only the best-matching segments of reads to the reference, which is especially useful when the quality of reads is uneven. For more information, refer to Bowtie2’s manual. This manual provides the local algorithm. | . | --&lt;preset&gt; option | Specifies preset options for the mapping algorithm. Possivle presers for the local mode are --very-fast-local, --fast-local, --sensitive-local (default) or --very-sensitive-local. For more information, refer to Bowtie2’s manual. | . | -p &lt;int&gt; | number of processors to use in addition to main thread . | . ",
    "url": "/docs/DataProcess/Bowtie2_MANUAL/#running-bowtie2",
    
    "relUrl": "/docs/DataProcess/Bowtie2_MANUAL/#running-bowtie2"
  },"11": {
    "doc": "Mapping reads with Bowtie2 for ChIP-seq",
    "title": "Example Code",
    "content": "Here is an example command to perform alignment with the mouse mm10 genome on trimmed fastq files: . $ bowtie2 -x /Users/jchoi/Desktop/mm10/mm10 \\ -1 /Users/jchoi/Desktop/Trim/Trim_pair_NFIB_1.fq.gz \\ -2 /Users/jchoi/Desktop/Trim/Trim_pair_NFIB_2.fq.gz \\ -S /Users/jchoi/Desktop/NFIB.sam --local --very-fast-local -p 20 . Enter your code: Copy Clear ",
    "url": "/docs/DataProcess/Bowtie2_MANUAL/#example-code",
    
    "relUrl": "/docs/DataProcess/Bowtie2_MANUAL/#example-code"
  },"12": {
    "doc": "Mapping reads with Bowtie2 for ChIP-seq",
    "title": "Output",
    "content": "When bowtie2 finishes running, it prints messages summarizing what happened. 23156585 reads; of these: 23156585 (100.00%) were paired; of these: 2044536 (8.83%) aligned concordantly 0 times 11769262 (50.82%) aligned concordantly exactly 1 time 9342787 (40.35%) aligned concordantly &gt;1 times ---- 2044536 pairs aligned concordantly 0 times; of these: 686243 (33.56%) aligned discordantly 1 time ---- 1358293 pairs aligned 0 times concordantly or discordantly; of these: 2716586 mates make up the pairs; of these: 1327258 (48.86%) aligned 0 times 453087 (16.68%) aligned exactly 1 time 936241 (34.46%) aligned &gt;1 times 97.13% overall alignment rate . | This message can also be outputted by samtools. | . The subsequent process utilizes the resulting ‘SAM’ file. ",
    "url": "/docs/DataProcess/Bowtie2_MANUAL/#output",
    
    "relUrl": "/docs/DataProcess/Bowtie2_MANUAL/#output"
  },"13": {
    "doc": "Mapping reads with Bowtie2 for ChIP-seq",
    "title": "Citations",
    "content": "Bowtie2 . | Langmead, B., &amp; Salzberg, S. L. (2012). Fast gapped-read alignment with Bowtie 2. Nature methods, 9(4), 357-359. DOI | Langmead, B., Wilks, C., Antonescu, V., &amp; Charles, R. (2019). Scaling read aligners to hundreds of threads on general-purpose processors. Bioinformatics, 35(3), 421-432. DOI | . ",
    "url": "/docs/DataProcess/Bowtie2_MANUAL/#citations",
    
    "relUrl": "/docs/DataProcess/Bowtie2_MANUAL/#citations"
  },"14": {
    "doc": "Mapping reads with Bowtie2 for ChIP-seq",
    "title": "Mapping reads with Bowtie2 for ChIP-seq",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/DataProcess/Bowtie2_MANUAL/",
    
    "relUrl": "/docs/DataProcess/Bowtie2_MANUAL/"
  },"15": {
    "doc": "CV",
    "title": "CV",
    "content": "Janghyun Choi . jchoi@inha.ac.kr . Research Institute for Molecular Cell Biology Inha University, Room 5N521 100 Inha-ro, Michuhol-gu Incheon 22212, Korea Current Position Research Institute for Molecular Cell Biology, Inha University Incheon, Korea . Postdoctoral Fellow 2021-present . Education Inha University Incheon, Korea . Ph.D. in Biological Sciences 2015-2021 . Thesis: Studies on the molecular mechanism by which KDM4D-NFIB-MLL1 complex regulates mesenchymal stem cell differentiation . Inha University Incheon, Korea . M.S. in Biological Sciences 2013-2015 . Thesis: The histone lysine demethylase JMJD2B is required for myogenic differentiation of C2C12 myoblast cells . Research Interest • Molecular Pathways in Mesenchymal Stem Cell Differentiation Understanding the specific epigenetic and transcriptional regulations governing mesenchymal stem cell (MSC) differentiation into muscle (myogenesis), fat (adipogenesis), and bone (osteogenesis) is a key area of interest. The focus is on identifying key genes and regulatory pathways through advanced techniques in biochemistry, molecular biology, and bioinformatics. • Epigenetic Regulation of Cellular Defense in Response to Oxidative Stress Examine how cells utilize epigenetic modifications to response and adapt to oxidative stress, including exposures to hydrogen peroxide (H2O2) and nanoparticles, is also a significant area of interest. This area of interest involves examining the role of epigenetic regulators in altering the chromatin landscape, potentially leading to new insights into stress resistance and cellular longevity. Skills and Techniques • Molecular Biology Proficient in the extraction, manipulation, and amplification of nucleic acids across diverse cells and tissues. Skilled in both traditional end-point PCR and advanced quantitative PCR techniques, emphasizing precision in genetic analysis. • Cell Culture Experienced in culturing a diverse range of cell types, including MSCs, epithelial cells, and neuronal cells. Specialized focus on conducting in vitro differentiation assays and employing genetic manipulation techniques such as transfection and viral infection. Proficient in performing cytotoxicity and apoptotic tests to assess cell health. Expert in preparing and processing samples for transmission electron microscopy (TEM) to ensure high-quality, detailed ultrastructural analysis. • Biochemistry Expert in the purification of recombinant proteins, extraction of proteins, and nuclear fractionation from cells. Proficient in protein quantification and gel electrophoresis techniques, including both native and denatured SDS-PAGE, to analyze protein integrity, functional states, and post-translational modifications. • Immunology Advanced skills in immunological techniques including immunoblotting (IB), immunofluorescence (IF) with proficiency in using confocal scanning laser microscopy (CSLM) to enhance visualization and analysis of target genes/proteins. Experienced in immunoprecipitation (IP) and chromatin IP (ChIP), along with fluorescence-activated cell sorting (FACS) for precise cellular analysis and sorting. • Data Science Strong computational skills in analyzing RNA and ChIP sequencing data using programming languages and statistical analysis. Experience includes custom script development for data analysis and visualization, enhancing research outcomes and insights. Publications . | Choi, J.* and Lee, H. (2024). MLL1 histone methyltransferase and UTX histone demethylase functionally cooperate to regulate the expression of NRF2 in response to ROS-induced oxidative stress. Free Radical Biology and Medicine, 217, 48-59. (*Co-corresponding author) | Choi, J.* and Lee, H. (2023). NFIB–MLL1 complex is required for the stemness and Dlx5-dependent osteogenic differentiation of C3H10T1/2 mesenchymal stem cells. Journal of Biological Chemistry, 299(10). (*Co-corresponding author) | Choi, J. H., Lee, H., Lee, H., and Lee, H. (2021). Dopant-dependent toxicity of CeO2 nanoparticles is associated with dynamic changes in H3K4me3 and H3K27me3 and transcriptional activation of NRF2 gene in HaCaT human keratinocytes. International Journal of Molecular Sciences, 22(6), 3087. | Choi, J. H. and Lee, H. (2020). Histone demethylase KDM4D cooperates with NFIB and MLL1 complex to regulate adipogenic differentiation of C3H10T1/2 mesenchymal stem cells. Scientific Reports, 10(1), 3050. | Choi, J. H., Hong, J. A., Son, Y. R., Wang, J., Kim, H. S., Lee, H., and Lee, H. (2020). Comparison of enhanced photocatalytic degradation efficiency and toxicity evaluations of CeO2 nanoparticles synthesized through double-modulation. Nanomaterials, 10(8), 1543. | Song, Y. J., Choi, J. H., and Lee, H. (2015). Setdb1 is required for myogenic differentiation of C2C12 myoblast cells via maintenance of MyoD expression. Molecules and cells, 38(4), 362. | Choi, J. H., Song, Y. J., and Lee, H. (2015). The histone demethylase KDM4B interacts with MyoD to regulate myogenic differentiation in C2C12 myoblast cells. Biochemical and biophysical research communications, 456(4), 872-878. | . ",
    "url": "/docs/CV/",
    
    "relUrl": "/docs/CV/"
  },"16": {
    "doc": "Data Analysis - ChIP-seq",
    "title": "Data Analysis - ChIP-seq",
    "content": "ChIP-seq data provides invaluable insights into the interactions between proteins and DNA, offering a comprehensive view of gene regulation and epigenetic modifications. In this section, I explore the methods used to examine and visualize this data. This includes data exploration techniques to identify significant patterns and distributions, as well as advanced visualization tools to represent these findings effectively. I also delve into peak calling methods to identify regions of enriched signal corresponding to protein (histone and non-histone)-DNA interactions, and sequence analysis to uncover underlying motifs and regulatory elements. ",
    "url": "/docs/ChIPSeq",
    
    "relUrl": "/docs/ChIPSeq"
  },"17": {
    "doc": "DEG - Correlation plot",
    "title": "Correlation Plot",
    "content": "Correlation plot analysis in RNA-seq is essential for evaluating the relationships between gene expression levels across various samples or conditions. This analysis aids in identifying co-expressed genes and potential regulatory mechanisms, thus providing insights into the underlying biological processes and pathways. Of particular importance, correlation plots can detect sample outliers or batch effects, which, if unaddressed, may distort the results and interpretations. Identifying these outliers allows researchers to implement corrective measures, thereby ensuring the reliability and accuracy of the analysis. This protocol was developed using a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes R version 4.4.0 running on macOS 14.4.1. Required Packages: . library(ggplot2) library(ggrepel) library(egg) . ",
    "url": "/docs/RNASeq/DEG_CorPlot_MANUAL/#correlation-plot",
    
    "relUrl": "/docs/RNASeq/DEG_CorPlot_MANUAL/#correlation-plot"
  },"18": {
    "doc": "DEG - Correlation plot",
    "title": "Step-by-Step Guide Between Biological Replicates",
    "content": "1. Load Your CPM Data as Base Type . | Load the CPM data from a CSV file into a data frame. Ensure that the first row contains headers and the first column contains row names: logcpm &lt;- read.csv(\"cpmlog.csv\", head = T, row.names = 1) . | Example of the first few rows of the data: &gt; head(logcpm) MA_rep1 MA_rep2 Y_rep1 Y_rep2 ENSDARG00000000001 4.520536 4.359122 4.668621 4.243662 ENSDARG00000000002 4.064591 3.908802 3.991407 3.714391 ENSDARG00000000018 5.781629 5.705938 5.891582 5.955444 ENSDARG00000000019 7.903514 7.711072 7.884873 7.745864 ENSDARG00000000068 3.844325 3.642902 3.769026 3.906018 ENSDARG00000000069 3.584263 3.828018 3.533662 4.049387 . | . 2. Calculate Correlation and Linear Model . | Calculate the Pearson correlation coefficient and fit a linear model to the data: correlation &lt;- cor(logcpm$Y_rep1, logcpm$Y_rep2, method = \"pearson\") # Possible methods are \"pearson\", \"spearman\", and \"kendall\" (default: \"pearson\") model &lt;- lm(Y_rep2 ~ Y_rep1, data = logcpm) coefficients &lt;- coef(model) slope &lt;- coefficients[\"Y_rep1\"] intercept &lt;- coefficients[\"(Intercept)\"] equation &lt;- paste(\"y =\", round(slope, 4), \"x +\", round(intercept, 4)) cor_text &lt;- paste(\"Pearson r =\", round(correlation, 4)) . | . 3. Make the correlation plot . | Use ggplot2 to create the correlation plot, adding points, and a linear regression line: ggplot(logcpm, aes(x = Y_rep1, y = Y_rep2)) + geom_point() + geom_smooth(method = lm, color = \"blue\") + xlab(\"Expression in rep 1 (log CPM)\") + ylab(\"Expression in rep 2 (log CPM)\") + ggtitle(paste(\"Correlation Plot between Young Groups (Correlation:\", round(correlation, 4), \")\")) . | Output: . | . 4. Identify Outliers . | Calculate standardized residuals, Cook’s distance, and leverage values to identify outliers: std_residuals &lt;- rstandard(model) cooks_d &lt;- cooks.distance(model) leverages &lt;- hatvalues(model) logcpm$outlier &lt;- (abs(std_residuals) &gt; 2) | (cooks_d &gt; 4/nrow(logcpm)) | (leverages &gt; 2*mean(leverages)) . | . 5. Create the Correlation Plot with Outliers Highlighted . | Update the plot to highlight outliers in red: plot &lt;- ggplot(logcpm, aes(x = Y_rep1, y = Y_rep2)) + geom_point(aes(fill = factor(outlier)), size = 4, shape = 21, alpha = 0.7, stroke = 0.5) + geom_smooth(method = lm, color = \"blue\") + scale_fill_manual(values = c(\"FALSE\" = \"#ECECEC\", \"TRUE\" = \"#BE1826\"), name = \"Outlier\", labels = c(\"FALSE\" = \"Non-Outlier\", \"TRUE\" = \"Outlier\")) + theme_minimal() + theme(panel.border = element_rect(color = \"black\", fill = NA, size = 1)) + xlab(\"Expression in rep 1 (log CPM)\") + ylab(\"Expression in rep 2 (log CPM)\") + ggtitle(\"Correlation Plot between Young Groups\") + annotate(\"text\", x = Inf, y = Inf, label = equation, hjust = 2.9, vjust = 1.5, size = 5, color = \"black\") + annotate(\"text\", x = Inf, y = Inf, label = cor_text, hjust = 3.3, vjust = 3, size = 5, color = \"black\") . | Output: (Clicking on the image will open it in a larger view.) . | . &times; &#10094; &#10095; | . Summarize . logcpm &lt;- read.csv(\"cpmlog.csv\", head = T, row.names = 1) correlation &lt;- cor(logcpm$Y_rep1, logcpm$Y_rep2, method = \"pearson\") model &lt;- lm(Y_rep2 ~ Y_rep1, data = logcpm) coefficients &lt;- coef(model) slope &lt;- coefficients[\"Y_rep1\"] intercept &lt;- coefficients[\"(Intercept)\"] equation &lt;- paste(\"y =\", round(slope, 4), \"x +\", round(intercept, 4)) cor_text &lt;- paste(\"Pearson r =\", round(correlation, 4)) std_residuals &lt;- rstandard(model) cooks_d &lt;- cooks.distance(model) leverages &lt;- hatvalues(model) logcpm$outlier &lt;- (abs(std_residuals) &gt; 2) | (cooks_d &gt; 4/nrow(logcpm)) | (leverages &gt; 2*mean(leverages)) plot &lt;- ggplot(logcpm, aes(x = Y_rep1, y = Y_rep2)) + geom_point(aes(fill = factor(outlier)), size = 4, shape = 21, alpha = 0.7, stroke = 0.5) + geom_smooth(method = lm, color = \"blue\") + scale_fill_manual(values = c(\"FALSE\" = \"#ECECEC\", \"TRUE\" = \"#BE1826\"), name = \"Outlier\", labels = c(\"FALSE\" = \"Non-Outlier\", \"TRUE\" = \"Outlier\")) + theme_minimal() + theme(panel.border = element_rect(color = \"black\", fill = NA, size = 1)) + xlab(\"Expression in rep 1 (log CPM)\") + ylab(\"Expression in rep 2 (log CPM)\") + ggtitle(\"Correlation Plot between Young Groups\") + annotate(\"text\", x = Inf, y = Inf, label = equation, hjust = 2.9, vjust = 1.5, size = 5, color = \"black\") + annotate(\"text\", x = Inf, y = Inf, label = cor_text, hjust = 3.3, vjust = 3, size = 5, color = \"black\") # Adjust plot size for publication plot2 &lt;- set_panel_size(plot, width = unit(49, \"mm\"), height = unit(49, \"mm\")) grid.arrange(plot2) . Enter your code: Copy Clear ",
    "url": "/docs/RNASeq/DEG_CorPlot_MANUAL/#step-by-step-guide-between-biological-replicates",
    
    "relUrl": "/docs/RNASeq/DEG_CorPlot_MANUAL/#step-by-step-guide-between-biological-replicates"
  },"19": {
    "doc": "DEG - Correlation plot",
    "title": "Step-by-Step Guide Between Groups (Conditions)",
    "content": "1. Load the Data and Calculate the Mean Across Replicas in each Group . ```R logcpm &lt;- read.csv(\"cpmlog.csv\", head = T, row.names = 1) logcpm$MA_mean &lt;- rowMeans(logcpm[, c(\"MA_rep1\", \"MA_rep2\")]) logcpm$Y_mean &lt;- rowMeans(logcpm[, c(\"Y_rep1\", \"Y_rep2\")]) ``` . 2. Calculate Correlation and Linear Model . | Calculate the Pearson correlation coefficient and fit a linear model to the data: correlation &lt;- cor(logcpm$Y_mean, logcpm$MA_mean, method = \"pearson\") model &lt;- lm(MA_mean ~ Y_mean, data = logcpm) coefficients &lt;- coef(model) slope &lt;- coefficients[\"Y_mean\"] intercept &lt;- coefficients[\"(Intercept)\"] equation &lt;- paste(\"y =\", round(slope, 4), \"x +\", round(intercept, 4)) cor_text &lt;- paste(\"Pearson r =\", round(correlation, 4)) . 3. Make the correlation plot . | Use ggplot2 to create the correlation plot, adding points, and a linear regression line: plot &lt;- ggplot(logcpm, aes(x = Y_mean, y = MA_mean)) + geom_point(fill = \"#ECECEC\", size = 4, shape = 21, alpha = 0.7, stroke = 0.5) + geom_smooth(method = lm, color = \"blue\") + geom_abline(slope = slope, intercept = intercept + 1, color = \"red\", linetype = \"dashed\") + geom_abline(slope = slope, intercept = intercept - 1, color = \"red\", linetype = \"dashed\") + theme_minimal() + theme(panel.border = element_rect(color = \"black\", fill = NA, size = 1)) + xlab(\"Mean Expression in Young (log CPM)\") + ylab(\"Mean Expression in MA (log CPM)\") + ggtitle(\"Correlation Plot between Groups\") + annotate(\"text\", x = Inf, y = Inf, label = equation, hjust = 2.9, vjust = 1.5, size = 5, color = \"black\") + annotate(\"text\", x = Inf, y = Inf, label = cor_text, hjust = 3.3, vjust = 3, size = 5, color = \"black\") . | Output: . | . ",
    "url": "/docs/RNASeq/DEG_CorPlot_MANUAL/#step-by-step-guide-between-groups-conditions",
    
    "relUrl": "/docs/RNASeq/DEG_CorPlot_MANUAL/#step-by-step-guide-between-groups-conditions"
  },"20": {
    "doc": "DEG - Correlation plot",
    "title": "t-SNE Plot",
    "content": "The t-SNE (t-Distributed Stochastic Neighbor Embedding) plot is used to visualize high-dimensional gene expression data in a two-dimensional space. This plot helps to reveal patterns and clusters in the data, allowing for the identification of similarities and differences between groups of samples. By reducing the dimensionality of the data while preserving its structure, t-SNE provides an intuitive way to explore and understand complex biological datasets. Required Packages: . library(ggplot2) library(Rtsne) . ",
    "url": "/docs/RNASeq/DEG_CorPlot_MANUAL/#t-sne-plot",
    
    "relUrl": "/docs/RNASeq/DEG_CorPlot_MANUAL/#t-sne-plot"
  },"21": {
    "doc": "DEG - Correlation plot",
    "title": "Step-by-Step t-SNE Guide",
    "content": "1. Load CPM Data and Prepare Analytic Data Set . | Load the CPM data from a CSV file into a data frame, and select the analytic data: logcpm &lt;- read.csv(\"cpmlog.csv\", header = TRUE, row.names = 1) group &lt;- factor(c(\"MA\", \"MA\", \"Y\", \"Y\")) top_genes &lt;- head(order(apply(logcpm, 1, var), decreasing = TRUE), 1000) logcpm_top &lt;- logcpm[top_genes, ] logcpm_unique &lt;- logcpm_top[!duplicated(logcpm_top), ] gene_groups &lt;- ifelse(rowMeans(logcpm_unique[, group == \"MA\"]) &gt; rowMeans(logcpm_unique[, group == \"Y\"]), \"MA\", \"Y\") . | In these codes: . | Line 2 (factor syntax): Create a factor vector for your sample groups. | Line 3 and 4 (applysyntax): Select the top 1000 genes based on variance. | Line 5: Remove duplicate rows to avoid issues with t-SNE. | Line 6 (ifelse syntax): Assign each gene to a group based on the average expression in each sample group (If the average expression in the MA group is higher, assign MA; otherwise, assign Y). | . | . 2. Perform t-SNE . | Set the seed for reproducibility and run the t-SNE algorithm: set.seed(42) tsne_res &lt;- Rtsne(as.matrix(logcpm_unique), dims = 2, perplexity = 30, verbose = TRUE, max_iter = 500) . | In these codes, . | Line 1: Set the seed for the random number generator. The number 42 is commonly used due to its reference in “The Hitchhiker’s Guide to the Galaxy” as the “answer to the ultimate question of life, the universe, and everything.” Setting the seed ensures that the same results can be reproduced. | Line 2: as.matrix(logcpm_unique) converts the data to a matrix format for t-SNE analysis. dims = 2 reduces the data to 2 dimensions. perplexity = 30 controls the local clustering of data points, typically set between 1/3 and 1/10 of the number of data points. Here, it is set to 30 for 1000 genes. max_iter = 500 sets the maximum number of iterations to 500. | . | Output: &gt; tsne_res &lt;- Rtsne(as.matrix(logcpm_unique), dims = 2, perplexity = 30, verbose = TRUE, max_iter = 500) Performing PCA Read the 921 x 4 data matrix successfully! Using no_dims = 2, perplexity = 30.000000, and theta = 0.500000 Computing input similarities... Building tree... Done in 0.05 seconds (sparsity = 0.121822)! Learning embedding... Iteration 50: error is 69.750356 (50 iterations in 0.07 seconds) Iteration 100: error is 65.012543 (50 iterations in 0.07 seconds) Iteration 150: error is 64.965118 (50 iterations in 0.07 seconds) Iteration 200: error is 64.972655 (50 iterations in 0.07 seconds) Iteration 250: error is 64.978724 (50 iterations in 0.07 seconds) Iteration 300: error is 1.027332 (50 iterations in 0.06 seconds) Iteration 350: error is 0.899678 (50 iterations in 0.06 seconds) Iteration 400: error is 0.872497 (50 iterations in 0.07 seconds) Iteration 450: error is 0.863688 (50 iterations in 0.06 seconds) Iteration 500: error is 0.856872 (50 iterations in 0.06 seconds) Fitting performed in 0.67 seconds. | . 3. Visualization . | Transform the t-SNE results into a data frame and create the plot: tsne_data &lt;- data.frame(tsne_res$Y, Group = gene_groups) colnames(tsne_data) &lt;- c(\"Dim1\", \"Dim2\", \"Group\") p &lt;- ggplot(data = tsne_data, aes(x = Dim1, y = Dim2)) + geom_point(aes(color = Group, fill = Group), size = 4, shape = 21, alpha = 0.7, stroke = 0.5) + scale_fill_manual(values = c(\"MA\" = \"#294A99\", \"Y\" = \"#BE1826\")) + scale_color_manual(values = c(\"MA\" = \"#294A99\", \"Y\" = \"#BE1826\")) + theme_minimal() + theme( legend.position = c(0.9, 0.9), legend.background = element_rect(fill = \"white\", color = \"black\", size = 0.5), panel.border = element_rect(color = \"black\", fill = NA, size = 1) ) + labs(title = \"t-SNE Plot of Top 1000 Gene Expression Data\", x = \"Dimension 1\", y = \"Dimension 2\") . | In these codes, . | Line 1: Combine the t-SNE results (tsne_res) with the group information into a data frame. | Line 2: Rename the columns for clarity. | Line 3: Make a plot using ggplot2. | . | Output: . | . Summarize . logcpm &lt;- read.csv(\"cpmlog.csv\", header = TRUE, row.names = 1) group &lt;- factor(c(\"MA\", \"MA\", \"Y\", \"Y\")) top_genes &lt;- head(order(apply(logcpm, 1, var), decreasing = TRUE), 1000) logcpm_top &lt;- logcpm[top_genes, ] logcpm_unique &lt;- logcpm_top[!duplicated(logcpm_top), ] gene_groups &lt;- ifelse(rowMeans(logcpm_unique[, group == \"MA\"]) &gt; rowMeans(logcpm_unique[, group == \"Y\"]), \"MA\", \"Y\") set.seed(42) tsne_res &lt;- Rtsne(as.matrix(logcpm_unique), dims = 2, perplexity = 30, verbose = TRUE, max_iter = 500) tsne_data &lt;- data.frame(tsne_res$Y, Group = gene_groups) colnames(tsne_data) &lt;- c(\"Dim1\", \"Dim2\", \"Group\") p &lt;- ggplot(data = tsne_data, aes(x = Dim1, y = Dim2)) + geom_point(aes(color = Group, fill = Group), size = 4, shape = 21, alpha = 0.7, stroke = 0.5) + scale_fill_manual(values = c(\"MA\" = \"#294A99\", \"Y\" = \"#BE1826\")) + scale_color_manual(values = c(\"MA\" = \"#294A99\", \"Y\" = \"#BE1826\")) + theme_minimal() + theme( legend.position = c(0.9, 0.9), legend.background = element_rect(fill = \"white\", color = \"black\", size = 0.5), panel.border = element_rect(color = \"black\", fill = NA, size = 1) ) + labs(title = \"t-SNE Plot of Top 1000 Gene Expression Data\", x = \"Dimension 1\", y = \"Dimension 2\") # Adjust plot size for publication p2 &lt;- set_panel_size(p, width = unit(49, \"mm\"), height = unit(49, \"mm\")) grid.arrange(p2) . Enter your code: Copy Clear ",
    "url": "/docs/RNASeq/DEG_CorPlot_MANUAL/#step-by-step-t-sne-guide",
    
    "relUrl": "/docs/RNASeq/DEG_CorPlot_MANUAL/#step-by-step-t-sne-guide"
  },"22": {
    "doc": "DEG - Correlation plot",
    "title": "Citations",
    "content": "linear regression . | Fox, J., &amp; Weisberg, S. (2018). An R companion to applied regression. Sage publications. HTML | . limma . | Van der Maaten, L., &amp; Hinton, G. (2008). Visualizing data using t-SNE. Journal of machine learning research, 9(11). HTML | . ",
    "url": "/docs/RNASeq/DEG_CorPlot_MANUAL/#citations",
    
    "relUrl": "/docs/RNASeq/DEG_CorPlot_MANUAL/#citations"
  },"23": {
    "doc": "DEG - Correlation plot",
    "title": "DEG - Correlation plot",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/RNASeq/DEG_CorPlot_MANUAL/",
    
    "relUrl": "/docs/RNASeq/DEG_CorPlot_MANUAL/"
  },"24": {
    "doc": "Normalization and DEG analysis with edgeR",
    "title": "Advanced RNA-seq Data Analysis with EdgeR: Identifying Differentially Expressed Genes and Beyond",
    "content": "EdgeR is a powerful tool designed for the data analysis phase of RNA-seq experiments, specifically for identifying differentially expressed genes (DEGs) across various conditions. It employs a negative binomial model to account for overdispersion in count data and uses empirical Bayes methods to stabilize variance estimates. Key features include effective normalization techniques, robust statistical testing for DEGs, and comprehensive visualization tools. While both EdgeR and DESeq are popular tools for RNA-seq data analysis, EdgeR is particularly noted for its flexibility and performance with small sample sizes due to its advanced empirical Bayes methods for dispersion estimation. This makes EdgeR especially useful in experiments where the number of biological replicates is limited. Additionally, EdgeR offers extensive options for data exploration and visualization, enhancing its utility in deriving meaningful biological insights. This protocol was created based on edgeR version 4.1.2 running on a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes R version 4.4.0 under macOS 12.4 environment. ",
    "url": "/docs/RNASeq/DEG_edgeR_MANUAL/#advanced-rna-seq-data-analysis-with-edger-identifying-differentially-expressed-genes-and-beyond",
    
    "relUrl": "/docs/RNASeq/DEG_edgeR_MANUAL/#advanced-rna-seq-data-analysis-with-edger-identifying-differentially-expressed-genes-and-beyond"
  },"25": {
    "doc": "Normalization and DEG analysis with edgeR",
    "title": "The Importance of Normalization",
    "content": "RNA-seq data analysis requires normalization to fairly compare samples by accounting for differences in sequencing depth and library size. For example, suppose the control group and drug-treated group have the following counts for genes A, B, C, D, and E. In the control group, the counts are 100, 200, 300, 400, and 500, respectively. In the drug-treated group, the counts are 100, 200, 300, 400, and 2000, respectively. The total counts for the control group and drug-treated group are 1500 (100+200+300+400+500) and 3000 (100+200+300+400+2000), respectively. At first glance, the gene expression levels seem identical between the groups. However, normalization reveals a different picture (see the bellow table). Normalized Values . | Gene | Control Group | Drug-Treated Group | . | A | 100/1500 = 0.067 | 100/3000 = 0.033 | . | B | 200/1500 = 0.133 | 200/3000 = 0.067 | . | C | 300/1500 = 0.2 | 300/3000 = 0.1 | . | D | 400/1500 = 0.267 | 400/3000 = 0.133 | . | E | 500/1500 = 0.333 | 2000/3000 = 0.667 | . | Normalized values indicate that genes A, B, C, and D are relatively less expressed in the drug-treated group, while gene E is significantly more expressed. Although the raw counts are the same, normalization considers the total count differences between samples. | Sometimes people try to determine gene expression trends by looking at read counts alone. This is never a scientific method and always requires normalization and statistical analysis. | . In practice, EdgeR employs more sophisticated normalization methods beyond simple division by total counts. EdgeR uses the TMM (Trimmed Mean of M-values) method to calculate normalization factors, adjusting for sequencing depth and library size differences: . | Calculate \\( M \\) and \\( A \\) values: . \\[ M = \\log_2 \\left(\\frac{X}{\\bar{X}}\\right) - \\log_2 \\left(\\frac{Y}{\\bar{Y}}\\right) \\] . \\[ A = \\frac{1}{2} \\left(\\log_2(X) + \\log_2(Y)\\right) \\] . \\( X \\): Read count for a particular gene in sample 1, \\(\\bar{X}\\): Geometric mean of read counts in sample 1 . \\( Y \\): Read count for the same gene in sample 2, \\(\\bar{Y}\\): Geometric mean of read counts in sample 2 . | Compute the weight (\\( w \\)): . \\[ w = \\frac{\\text{Trimmed mean of } M}{\\log_2(\\bar{Y}/\\bar{X})} \\] . The weight \\( w \\) is used to normalize the read counts, reducing technical variability and allowing for more accurate comparison of gene expression levels between samples. | . This complex normalization reduces technical variability and enhances the detection of genuine biological differences. EdgeR combines this advanced normalization with robust statistical techniques to accurately identify differentially expressed genes. ",
    "url": "/docs/RNASeq/DEG_edgeR_MANUAL/#the-importance-of-normalization",
    
    "relUrl": "/docs/RNASeq/DEG_edgeR_MANUAL/#the-importance-of-normalization"
  },"26": {
    "doc": "Normalization and DEG analysis with edgeR",
    "title": "Installation edgeR",
    "content": ". | Check and install edgeR Start by ensuring the BiocManager package is installed, then install edgeR using it: if (!require(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"edgeR\") . | Install Required Libraries Install additional libraries necessary for edgeR to function properly. You can install these packages manually using the BiocManager::install(\"PackageName\"). The list of packages is shown below. | . Library list (PackageName) . | limma: EdgeR dependent package | HTSFilter: A filtering tool for a global Jaccard similarity index | MASS: Functions and datasets to support Venables and Ripley | lattice: For trellis graphics system | mixOmics: For multivariate methods | biomaRt: For annotation | ggplot2 | RColorBrewer | rtracklayer | GenomeInfoDb | . ",
    "url": "/docs/RNASeq/DEG_edgeR_MANUAL/#installation-edger",
    
    "relUrl": "/docs/RNASeq/DEG_edgeR_MANUAL/#installation-edger"
  },"27": {
    "doc": "Normalization and DEG analysis with edgeR",
    "title": "Step-by-Step Running Guide edgeR",
    "content": "1. Load edgeR and its dependency packages . library(edgeR) library(limma) library(biomaRt) library(ggplot2) library(RColorBrewer) library(stats) # For PCA plot library(data.table) . 2. Prepare metadata . | Metadata in RNA-seq is used to organize samples, adjust statistical models, ensure reproducibility, facilitate comparisons, and manage data effectively. | . the metadata must be associated with the raw count table. This file can be created in Excel, saved as a csv and txt, and imported via read.csv and read.table, or it can be created by typing directly in R as shown below. File &lt;- c(\"shControl_Unt_rep1\", \"shControl_Unt_rep2\", \"shControl_H2O2_rep1\", \"shControl_H2O2_rep2\", \"shMLL1_Unt_rep1\", \"shMLL1_Unt_rep2\", \"shMLL1_H2O2_rep1\", \"shMLL1_H2O2_rep2\", \"shUTX_Unt_rep1\", \"shUTX_Unt_rep2\", \"shUTX_H2O2_rep1\", \"shUTX_H2O2_rep2\", \"shNRF2_Unt_rep1\", \"shNRF2_Unt_rep2\", \"shNRF2_H2O2_rep1\", \"shNRF2_H2O2_rep2\") Rep &lt;- c(\"rep1\", \"rep2\", \"rep1\", \"rep2\", \"rep1\", \"rep2\", \"rep1\", \"rep2\", \"rep1\", \"rep2\", \"rep1\", \"rep2\", \"rep1\", \"rep2\", \"rep1\", \"rep2\") Condition &lt;- c(\"Unt\", \"Unt\", \"H2O2\", \"H2O2\", \"Unt\", \"Unt\", \"H2O2\", \"H2O2\", \"Unt\", \"Unt\", \"H2O2\", \"H2O2\", \"Unt\", \"Unt\", \"H2O2\", \"H2O2\") KD &lt;- c(\"WT\", \"WT\", \"WT\", \"WT\", \"MLL1\", \"MLL1\", \"MLL1\", \"MLL1\", \"UTX\", \"UTX\", \"UTX\", \"UTX\", \"NRF2\", \"NRF2\", \"NRF2\", \"NRF2\") Group &lt;- c(\"CU\", \"CU\", \"CH\", \"CH\", \"MU\", \"MU\", \"MH\", \"MH\", \"UU\", \"UU\", \"UH\", \"UH\", \"NU\", \"NU\", \"NH\", \"NH\") sampleInfo &lt;- data.frame(File, Rep, KD, Condition, Group) sampleInfo # Check metadata . Enter your code: Copy Clear . | Output: &gt; sampleInfo File Rep KD Condition Group 1 shControl_Unt_rep1 rep1 WT Unt CU 2 shControl_Unt_rep2 rep2 WT Unt CU 3 shControl_H2O2_rep1 rep1 WT H2O2 CH 4 shControl_H2O2_rep2 rep2 WT H2O2 CH 5 shMLL1_Unt_rep1 rep1 MLL1 Unt MU 6 shMLL1_Unt_rep2 rep2 MLL1 Unt MU 7 shMLL1_H2O2_rep1 rep1 MLL1 H2O2 MH 8 shMLL1_H2O2_rep2 rep2 MLL1 H2O2 MH 9 shUTX_Unt_rep1 rep1 UTX Unt UU 10 shUTX_Unt_rep2 rep2 UTX Unt UU 11 shUTX_H2O2_rep1 rep1 UTX H2O2 UH 12 shUTX_H2O2_rep2 rep2 UTX H2O2 UH 13 shNRF2_Unt_rep1 rep1 NRF2 Unt NU 14 shNRF2_Unt_rep2 rep2 NRF2 Unt NU 15 shNRF2_H2O2_rep1 rep1 NRF2 H2O2 NH 16 shNRF2_H2O2_rep2 rep2 NRF2 H2O2 NH . | . 3. Load raw count table . | This example is based on the raw count table obtained via htseq-count. | The raw count table is a tab-delimited .txt file where the first column contains gene or transcript IDs, and the remaining columns are the names of each sample. However, it lacks a header, making columns difficult to distinguish, and the last four rows contain summary information. | While you can open this file in Excel to add a header and remove the last 4 lines, I will perform these steps programmatically in R. rawCountTable &lt;- read.delim(\"~/Desktop/H2O2.txt\", header = FALSE, row.names = NULL) rawCountTable &lt;- rawCountTable[1:(nrow(rawCountTable) - 4), ] rownames(rawCountTable) &lt;- rawCountTable[,1] rawCountTable &lt;- rawCountTable[,-1] colnames(rawCountTable) &lt;- c(\"shControl_Unt_rep1\", \"shControl_Unt_rep2\", \"shControl_H2O2_rep1\", \"shControl_H2O2_rep2\", \"shMLL1_Unt_rep1\", \"shMLL1_Unt_rep2\", \"shMLL1_H2O2_rep1\", \"shMLL1_H2O2_rep2\", \"shUTX_Unt_rep1\", \"shUTX_Unt_rep2\", \"shUTX_H2O2_rep1\", \"shUTX_H2O2_rep2\", \"shNRF2_Unt_rep1\", \"shNRF2_Unt_rep2\", \"shNRF2_H2O2_rep1\", \"shNRF2_H2O2_rep2\") head(rawCountTable) # Check raw count table # After processing the data in Excel, you can load it in R using the following command: rawCountTable &lt;- read.csv(\"~/Desktop/H2O2.csv\", header = TRUE, row.names = 1) rawCountTable &lt;- read.table(\"/path/to/the/file.txt\", sep = \",\", header = TRUE, row.names = 1) . | . Enter your code: Copy Clear . | Output: &gt; head(rawCountTable) shControl_Unt_rep1 shControl_Unt_rep2 shControl_H2O2_rep1 shControl_H2O2_rep2 shMLL1_Unt_rep1 ENSG00000000003 0 12 1 1 1 ENSG00000000005 119 140 133 160 141 ENSG00000000419 1 1 1 1 1 ENSG00000000457 2 5 3 5 1 ENSG00000000460 273 196 279 282 242 ENSG00000000938 55 69 98 117 76 shMLL1_Unt_rep2 shMLL1_H2O2_rep1 shMLL1_H2O2_rep2 shUTX_Unt_rep1 shUTX_Unt_rep2 shUTX_H2O2_rep1 ENSG00000000003 1 1 1 0 1 0 ENSG00000000005 182 151 166 142 109 118 ENSG00000000419 2 2 2 2 3 1 ENSG00000000457 1 1 1 2 3 7 ENSG00000000460 193 218 209 214 235 203 ENSG00000000938 57 61 77 128 117 97 shUTX_H2O2_rep2 shNRF2_Unt_rep1 shNRF2_Unt_rep2 shNRF2_H2O2_rep1 shNRF2_H2O2_rep2 ENSG00000000003 1 1 2 1 0 ENSG00000000005 129 133 147 178 170 ENSG00000000419 0 1 1 0 0 ENSG00000000457 0 12 9 13 4 ENSG00000000460 204 100 171 179 180 ENSG00000000938 108 61 52 70 61 . | . 4. Object setup for RNA-seq analysis . | In this step, I will set up a DGEList object for edgeR analysis using the previously prepared raw count data and metadata. dgeFull &lt;- DGEList(rawCountTable, group = sampleInfo$Group) dgeFull # check the object . Key arguments . | rawCountTable: Specifies the object for raw count table. | group = &lt;Name&gt;: Specifies the grouping of samples based on metadata, such as experimental conditions or sample types. | . This grouping is crucial for DEG analysis in edgeR. Output: . &gt; dgeFull An object of class \"DGEList\" $counts shControl_Unt_rep1 shControl_Unt_rep2 shControl_H2O2_rep1 shControl_H2O2_rep2 shMLL1_Unt_rep1 ENSG00000000003 0 12 1 1 1 ENSG00000000005 119 140 133 160 141 ENSG00000000419 1 1 1 1 1 ENSG00000000457 2 5 3 5 1 ENSG00000000460 273 196 279 282 242 shMLL1_Unt_rep2 shMLL1_H2O2_rep1 shMLL1_H2O2_rep2 shUTX_Unt_rep1 shUTX_Unt_rep2 shUTX_H2O2_rep1 ENSG00000000003 1 1 1 0 1 0 ENSG00000000005 182 151 166 142 109 118 ENSG00000000419 2 2 2 2 3 1 ENSG00000000457 1 1 1 2 3 7 ENSG00000000460 193 218 209 214 235 203 shUTX_H2O2_rep2 shNRF2_Unt_rep1 shNRF2_Unt_rep2 shNRF2_H2O2_rep1 shNRF2_H2O2_rep2 ENSG00000000003 1 1 2 1 0 ENSG00000000005 129 133 147 178 170 ENSG00000000419 0 1 1 0 0 ENSG00000000457 0 12 9 13 4 ENSG00000000460 204 100 171 179 180 61494 more rows ... $samples group lib.size norm.factors shControl_Unt_rep1 CU 11738068 1 shControl_Unt_rep2 CU 11905476 1 shControl_H2O2_rep1 CH 12069056 1 shControl_H2O2_rep2 CH 12237122 1 shMLL1_Unt_rep1 MU 11781709 1 11 more rows ... | . 5. Check Library Size and Distribution . | In this step, I will check the library size and distribution of the samples before proceeding with normalization. pseudoCounts &lt;- log2(dgeFull$counts+1) # the values are converted to non-zero values. FullCol &lt;- as.numeric(factor(sampleInfo$Group)) + 1 boxplot(pseudoCounts, col=FullCol, las=2) abline(h=median(as.matrix(pseudoCounts)), col=\"blue\") # Save boxplot . Output: . | . 6. TMM Normalization . | In this process, I will perform TMM normalization. dgeFull &lt;- DGEList(dgeFull$counts[apply(dgeFull$counts, 1, sum) != 0, ], group=dgeFull$samples$group) dge &lt;- calcNormFactors(dgeFull) design &lt;- model.matrix(~0+group, data=dge$samples) dge &lt;- estimateDisp(dge, design = design) . | in these codes, . | Line 1: Creates a DGEList object with count data, excluding genes with zero counts across all samples, and includes group information. This step improves data quality by removing noise. | Line 2: Calculates TMM normalization factors to adjust for differences in library sizes between samples, ensuring accurate comparisons. | Line 3: Constructs a design matrix for DEG analysis, indicating group membership of each sample. The ~0+group command facilitates group comparisons. | Line 4: Estimates the dispersion for each gene, crucial for reliable DEG analysis, by accounting for variability in gene expression levels. | . Output: . &gt; dgeFull &lt;- DGEList(dgeFull$counts[apply(dgeFull$counts, 1, sum) != 0, ], group=dgeFull$samples$group) &gt; dgeFull$counts # **Check the selected transcripts. I will not show results in this example because it is too long. &gt; dge &lt;- calcNormFactors(dgeFull) &gt; dge$samples # Check norm.factor group lib.size norm.factors shControl_Unt_rep1 CU 11738068 1.0531166 shControl_Unt_rep2 CU 11905476 0.8733873 shControl_H2O2_rep1 CH 12069056 1.1370291 shControl_H2O2_rep2 CH 12237122 0.8497171 shMLL1_Unt_rep1 MU 11781709 1.1008688 shMLL1_Unt_rep2 MU 11949117 0.8701975 shMLL1_H2O2_rep1 MH 10394452 1.0873398 shMLL1_H2O2_rep2 MH 10562518 0.9844330 shUTX_Unt_rep1 UU 11606646 1.1195918 shUTX_Unt_rep2 UU 11774054 0.8831360 shUTX_H2O2_rep1 UH 10663731 1.1049622 shUTX_H2O2_rep2 UH 10831797 0.9599600 shNRF2_Unt_rep1 NU 10051201 1.0067264 shNRF2_Unt_rep2 NU 10218609 1.0175643 shNRF2_H2O2_rep1 NH 10533324 1.0512145 shNRF2_H2O2_rep2 NH 10701390 0.9716580 . After caculation of norm.factors: . &gt; design &lt;- model.matrix(~0+group, data=dge$samples) &gt; design groupCH groupCU groupMH groupMU groupNH groupNU groupUH groupUU shControl_Unt_rep1 0 1 0 0 0 0 0 0 shControl_Unt_rep2 0 1 0 0 0 0 0 0 shControl_H2O2_rep1 1 0 0 0 0 0 0 0 shControl_H2O2_rep2 1 0 0 0 0 0 0 0 shMLL1_Unt_rep1 0 0 0 1 0 0 0 0 shMLL1_Unt_rep2 0 0 0 1 0 0 0 0 shMLL1_H2O2_rep1 0 0 1 0 0 0 0 0 shMLL1_H2O2_rep2 0 0 1 0 0 0 0 0 shUTX_Unt_rep1 0 0 0 0 0 0 0 1 shUTX_Unt_rep2 0 0 0 0 0 0 0 1 shUTX_H2O2_rep1 0 0 0 0 0 0 1 0 shUTX_H2O2_rep2 0 0 0 0 0 0 1 0 shNRF2_Unt_rep1 0 0 0 0 0 1 0 0 shNRF2_Unt_rep2 0 0 0 0 0 1 0 0 shNRF2_H2O2_rep1 0 0 0 0 1 0 0 0 shNRF2_H2O2_rep2 0 0 0 0 1 0 0 0 attr(,\"assign\") [1] 1 1 1 1 1 1 1 1 attr(,\"contrasts\") attr(,\"contrasts\")$group [1] \"contr.treatment\" . | . 7. Check Library Size and Distribution after Normalization . | Next, I will now plot a boxplot based on the normalized data to observe the correlation between each sample or between groups. | Depicting a box plot normCounts &lt;- cpm(dge) pseudoNormCounts &lt;- log2(normCounts + 1) FullColNorm &lt;- as.numeric(factor(dge$samples$group)) + 1 boxplot(pseudoNormCounts, col=FullColNorm, las=2) abline(h=median(as.matrix(pseudoNormCounts)), col=\"blue\") # can save a plot . | Output: . | Drwing a principal component analysis (PCA) plot: PCA visualizes the major sources of variation in the data by transforming it into principal components. It highlights the directions (principal components) where the data varies the most, helping to identify patterns and groupings among the samples. The PCA plot is useful for understanding the overall structure and key sources of variation in the dataset. pca_result &lt;- prcomp(t(pseudoNormCounts), scale. = TRUE) summary(pca_result) # PCA Visulaize pca_data &lt;- data.frame(Sample = rownames(pca_result$x), PC1 = pca_result$x[,1], PC2 = pca_result$x[,2], Group = dge$samples$group) # PCA plot ggplot(pca_data, aes(x = PC1, y = PC2, color = Group)) + geom_point(size = 3) + labs(title = \"PCA Plot\", x = \"Principal Component 1\", y = \"Principal Component 2\") + theme_minimal() . | Making a multidimensional scaling (MDS) plot: MDS plots represent the pairwise distances between samples in a low-dimensional space, preserving the original distances as much as possible. This helps in visualizing the similarity or dissimilarity among samples based on their expression profiles. The MDS plot is particularly useful for detecting patterns and relationships in the data that are not immediately apparent. # Basal format plotMDS(pseudoNormCounts) # Advanced format plotMDS(pseudoNormCounts, col = FullColNorm, pch = 19, main = \"MDS Plot\") legend(\"topright\", legend=levels(factor(dge$samples$group)), col = 1:length(levels(factor(dge$samples$group))), pch = 19) . | Prepare log10 transformed CPM prior.count = 1 cpmlog &lt;- cpm(dge, log = T, prior.count = prior.count) write.csv(cpmlog, \"path/to/the/file.csv\") # Save the CPM file . | . 8. Remove Overdispersion and DEG Analysis . | In this step, I will perform DEG analysis based on the TMM normalized counts (dge) and the design matrix. Overdispersion, which is the presence of greater variability in the data than expected under a negative binomial or Poisson distribution, must be addressed to ensure accurate results. | This can be effectively removed using linear regression approaches, such as the Generalized Linear Model-Quasi Likelihood (GLM-QL) method. The GLM-QL approach accounts for overdispersion by modeling the extra variability and provides more reliable statistical inferences. | If no specific parameters are added, the GLM-QL typically calculates statistical significance by comparing the degrees of freedom between samples. Additionally, the false discovery rate (FDR) is computed using the Benjamini-Hochberg (BH) method to control for multiple testing and reduce the likelihood of false positives. # Model fitting using the GML-QL and modeling overdispersion fit &lt;- glmQLFit(dge, design = design) glmQLFTest(fit) # (Optional) Test QL F-test across all samples # The process of specifying what to compare based on design object my.contrasts &lt;- makeContrasts(CU_CH = groupCH-groupCU, CU_MU = groupMU-groupCU, CU_UU = groupUU-groupCU, CU_NU = groupNU-groupCU, MU_MH = groupMH-groupMU, UU_UH = groupUH-groupUU, NU_NH = groupNH-groupNU, CH_MH = groupMH-groupCH, CH_UH = groupUH-groupCH, CH_NH = groupNH-groupCH, levels = design) # DEG Analysis H2O2 &lt;- glmQLFTest(fit, contrast=my.contrasts[,\"CU_CH\"]) # DEG analysis using the QL F-test under the [my.contrasts] conditions. H2O2_FDR &lt;- topTags(H2O2, n = Inf)$table # FDR calculation with BH (default) method write.csv(H2O2_FDR, \"H2O2_DEG.csv\") # Save as csv format shMLL1 &lt;- glmQLFTest(fit, contrast=my.contrasts[,\"MU_MH\"]) shMLL1_FDR &lt;- topTags(shMLL1, n = Inf)$table write.csv(shMLL1_FDR, \"shMLL1_DEG.csv\") shUTX &lt;- glmQLFTest(fit, contrast=my.contrasts[,\"UU_UH\"]) shUTX_FDR &lt;- topTags(shUTX, n = Inf)$table write.csv(shUTX_FDR, \"shUTX_DEG.csv\") shNRF2 &lt;- glmQLFTest(fit, contrast=my.contrasts[,\"NU_NH\"]) shNRF2_FDR &lt;- topTags(shNRF2, n = Inf)$table write.csv(shNRF2_FDR, \"shNRF2_DEG.csv\") . | . Enter your code: Copy Clear . | Output: logFC represents the log2-transformed value of the target group’s (H2O2) expression divided by the control group’s (Unt) expression, while logCPM is the average of log2(CPM + 1) for each sample. The F value is the result of the F-test (glmQL), and the PValue(p-value) indicates the statistical significance of the result. FDR is the False Discovery Rate, which is a multiple testing correction of the p-value. In general, values with $|logFC|$ &gt; 1 and FDR &lt; 0.05 are considered significant DEGs (see the bellow). &gt; head(H2O2_FDR) logFC logCPM F PValue FDR ENSG00000261089 -7.753531 3.5081044 1499.6617 0.000000e+00 0.000000e+00 ENSG00000205358 -8.403098 1.3033323 706.6869 1.355224e-155 4.167246e-151 ENSG00000181019 3.767159 2.5203353 486.9699 7.338978e-108 1.504466e-103 ENSG00000181625 -5.324815 1.1710369 311.2585 1.220608e-69 1.876655e-65 ENSG00000204472 6.711876 0.8264076 227.5472 2.097907e-51 2.580384e-47 ENSG00000155070 -1.582992 3.5280535 148.1809 4.380133e-34 4.489563e-30 . | . IMPORTANT . | More genes with FDR &gt; 0.05 could emerge in your actual DEG analysis, despite the distinctiveness evident in the PCA and MDS plot between the samples from the two conditions under comparison. | In this case, it may be helpful to change the test for statistical significance to fitness (glmLRT; Generalized Linear Model Likelihood Ratio Test function) rather than degrees of freedom (glmQL function). | Here is an example of R code for DEG analysis using the glmLRT: . fit &lt;- glmQLFit(dge, design = design) # DEG analysis using the Likelihood Ratio Test H2O2_LRT &lt;- glmLRT(fit, contrast=my.contrasts[,\"CU_CH\"]) H2O2_LRT_FDR &lt;- topTags(H2O2_LRT, n=Inf)$table # p.adjust.method = \"[BY/holm/etc]\" write.csv(H2O2_LRT_FDR, \"H2O2_DEG_glmLRT.csv\") . | There are several methods to determine the FDR value based on statistical analysis, including BH, BY, holm, bonferroni, hommel, hochberg, or none, but the BH (default) method has greater tolerance rather than other methods and most users accept BH. You can choose these methods from the topTags command as shown below: shMLL1_FDR &lt;- topTags(shMLL1, n=Inf, p.adjust.method = \"&lt;BY/holm/etc&gt;\")$table . | . 9. Single Sample DEG analysis: Importance of Biological Replicates in RNA-seq . IMPORTANT Biological replicates in RNA-seq are crucial for ensuring reliable, reproducible results by accounting for natural biological variability. They improve statistical power, ensure reproducibility, and reduce bias. However, researchers may be constrained to single samples due to economic limitations, scarcity of samples, or ethical considerations. Despite these constraints, single-sample RNA-seq can still provide valuable insights, though results must be interpreted with caution, acknowledging the limitations imposed by the lack of biological replicates. | In particular, the coefficient of dispersion between samples cannot be calculated directly, necessitating the addition of an arbitrary factor. This factor is referred to as the biological coefficient of variation (BCV). Researchers can estimate this value based on prior knowledge or data from analogous experiments. | It is crucial to acknowledge that the inability to calculate the dispersion coefficient implies that linear models and methods for removing overdispersion will not be effective. | Typically, a BCV value of 0.4 is utilized. If the dataset under analysis is anticipated to exhibit high biological variation, the BCV value can be set to 0.6 or higher. For instance, samples from different species or those collected under varying environmental conditions might necessitate a higher BCV value. Conversely, for datasets with low biological variation, a BCV value of 0.2 may be appropriate. For example, a low BCV value might be used when repeatedly collecting the same cell line under identical conditions. These values should be considered as guidelines rather than strict rules. | There are two methods to apply BCV to perform DEG analysis, the extractTest and glmFit methods. Until the normalization step, both methods are same. Here, I will provide how to use both methods after normalization: . | extractTest method: dge &lt;- calcNormFactors(dgeFull) # TMM normalization bcv &lt;- 0.4 dgeTest_H2O2 &lt;- exactTest(dgeFull, dispersion = bcv^2, pair = c(\"CU\",\"CH\")) dgeTest_H2O2_FDR &lt;- topTags(dgeTest_H2O2, n = Inf)$table write.csv(dgeTest_H2O2_FDR, \"H2O2_DEG_extract,csv\") . Output . &gt; dgeTest_H2O2 &lt;- exactTest(dgeFull, dispersion = bcv^2, pair = c(\"CU\",\"CH\")) &gt; dgeTest_H2O2_FDR &lt;- topTags(dgeTest_H2O2, n = Inf)$table &gt; dgeTest_H2O2_FDR &lt;- dgeTest_H2O2_FDR[order(rownames(dgeTest_H2O2_FDR)), ] &gt; head(dgeTest_H2O2_FDR) logFC logCPM PValue FDR ENSG00000000003 0.00000000 -1.5072179 1.0000000 1 ENSG00000000005 0.01620179 4.6487540 1.0000000 1 ENSG00000000419 -3.25162822 -1.0936018 1.0000000 1 ENSG00000000457 0.78712182 -0.4296291 0.7447837 1 ENSG00000000460 -0.14629616 5.1399138 0.8668006 1 ENSG00000000938 0.71112235 3.7377811 0.4122082 1 . | glmFit methods: dge &lt;- calcNormFactors(dgeFull) # TMM normalization design &lt;- model.matrix(~0+group, data=dge$samples) # design matrix bcv &lt;- 0.4 my.contrasts &lt;- makeContrasts(CU_CH = groupCH-groupCU, CU_MU = groupMU-groupCU, CU_UU = groupUU-groupCU, CU_NU = groupNU-groupCU, MU_MH = groupMH-groupMU, UU_UH = groupUH-groupUU, NU_NH = groupNH-groupNU, CH_MH = groupMH-groupCH, CH_UH = groupUH-groupCH, CH_NH = groupNH-groupCH, levels = design) fit &lt;- glmFit(dge, design = design, dispersion=bcv^2) glmLRT(fit) IND_H2O2_LRT &lt;- glmLRT(fit, contrast=my.contrasts[,\"CU_CH\"]) IND_H2O2_LRT_FDR &lt;- topTags(IND_H2O2_LRT, n=Inf)$table write.csv(IND_H2O2_LRT_FDR, \"H2O2_DEG_LRT.csv\") . Output . &gt; IND_H2O2_LRT &lt;- glmLRT(fit, contrast=my.contrasts[,\"CU_CH\"]) &gt; IND_H2O2_LRT_FDR &lt;- topTags(IND_H2O2_LRT, n=Inf)$table &gt; IND_H2O2_LRT_FDR &lt;- IND_H2O2_LRT_FDR[order(rownames(IND_H2O2_LRT_FDR)), ] &gt; head(IND_H2O2_LRT_FDR) logFC logCPM LR PValue FDR ENSG00000000003 0.0000000 -1.5072179 0.0000000000 1.0000000 1.0000000 ENSG00000000005 0.0162005 4.6487540 0.0003788167 0.9844716 1.0000000 ENSG00000000419 -3.1350554 -1.0936018 1.4297184098 0.2318104 0.9934706 ENSG00000000457 0.7839430 -0.4296291 0.3116571808 0.5766650 1.0000000 ENSG00000000460 -0.1462899 5.1399138 0.0314383257 0.8592660 1.0000000 ENSG00000000938 0.7110305 3.7377811 0.7053500976 0.4009918 1.0000000 . | . | . Enter your code: Copy Clear 10. Annotation . After performing DEG analysis, the results may be displayed using gene (or transcript) IDs instead of gene symbols. To convert these IDs into various information such as gene symbols and biotypes, annotation is required. Two main methods for this are using the biomaRt R package or extracting information directly from a GTF file. | Biomart (biomaRt) offers access to a vast array of biological data through the Ensembl database, facilitating the easy conversion of gene IDs to gene symbols. However, this conversion can be more challenging and complex for species other than humans and mice. Therefore, it is recommended to use Biomart for gene conversion in the cases of human and mouse data. | Alternatively, the GTF file method entails extracting information from a locally stored gene annotation file. By parsing the GTF file, one can map gene IDs to gene symbols. This approach is versatile and can be applied to any species, provided that a GTF file is available. | the biomaRt method for human and mouse data: . mart &lt;- useDataset(\"hsapiens_gene_ensembl\", useMart(\"ensembl\")) anno &lt;- getBM(filters = \"ensembl_gene_id\", attributes= c(\"ensembl_gene_id\", \"gene_biotype\", \"external_gene_name\"), values = row.names(IND_H2O2_LRT_FDR), mart = mart) Compare &lt;- setDT(IND_H2O2_LRT_FDR, keep.rownames = \"ensembl_gene_id\")[] MergeDEG &lt;- merge(IND_H2O2_LRT_FDR, anno, by=\"ensembl_gene_id\", all=TRUE) write.csv(MergeDEG, \"IND_H2O2_LRT_Annotated.csv\") . | in these codes, . | Line 1: Connects to the Ensembl database (useMart(\"ensembl\")) and specifies the dataset to use (useDataset), in this case, the human gene dataset from Ensembl (mouse: \"mmusculus_gene_ensembl\"). The available useDataset can be found via the listDatasets(mart) command, note the case of the lists. | Line 2: filters specifies that the filter for the query is the Ensembl gene ID. attributes defines the attributes to retrieve, including the Ensembl gene ID, gene biotype, and external gene name (gene symbol). values provides the list of Ensembl gene IDs to be annotated, which are the row names of the IND_H2O2_LRT_FDR object. The available attributes can be found via the listAttributes(mart) command, note the case of the lists. | Line 3: Converts IND_H2O2_LRT_FDR to a data.table and keeps the row names as a column named ensembl_gene_id. [] ensures the operation is executed immediately and the result is assigned to Compare. | Line 4: Merges the DEG results (IND_H2O2_LRT_FDR) with the annotation information (anno) based on the by = \"ensembl_gene_id\" column. The all = TRUE argument ensures that all entries from both data frames are included in the result, performing a full outer join. | . Output . &gt; mart &lt;- useDataset(\"hsapiens_gene_ensembl\", useMart(\"ensembl\")) &gt; anno &lt;- getBM(filters= \"ensembl_gene_id\", attributes= c(\"ensembl_gene_id\", \"gene_biotype\", \"external_gene_name\"), values = row.names(IND_H2O2_LRT_FDR),mart= mart) &gt; head(anno) ensembl_gene_id gene_biotype external_gene_name 1 ENSG00000000003 protein_coding TSPAN6 2 ENSG00000000005 protein_coding TNMD 3 ENSG00000000419 protein_coding DPM1 4 ENSG00000000457 protein_coding SCYL3 5 ENSG00000000460 protein_coding FIRRM 6 ENSG00000000938 protein_coding FGR &gt; Compare &lt;- setDT(IND_H2O2_LRT_FDR, keep.rownames = \"ensembl_gene_id\")[] &gt; head(Compare) ensembl_gene_id logFC logCPM LR PValue FDR &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; 1: ENSG00000000003 0.0000000 -1.5072179 0.0000000000 1.0000000 1.0000000 2: ENSG00000000005 0.0162005 4.6487540 0.0003788167 0.9844716 1.0000000 3: ENSG00000000419 -3.1350554 -1.0936018 1.4297184098 0.2318104 0.9934706 4: ENSG00000000457 0.7839430 -0.4296291 0.3116571808 0.5766650 1.0000000 5: ENSG00000000460 -0.1462899 5.1399138 0.0314383257 0.8592660 1.0000000 6: ENSG00000000938 0.7110305 3.7377811 0.7053500976 0.4009918 1.0000000 &gt; MergeDEG &lt;- merge(IND_H2O2_LRT_FDR, anno, by=\"ensembl_gene_id\", all=TRUE) &gt; head(MergeDEG) Key: &lt;ensembl_gene_id&gt; ensembl_gene_id logFC logCPM LR PValue FDR gene_biotype external_gene_name &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;char&gt; &lt;char&gt; 1: ENSG00000000003 0.0000000 -1.5072179 0.0000000000 1.0000000 1.0000000 protein_coding TSPAN6 2: ENSG00000000005 0.0162005 4.6487540 0.0003788167 0.9844716 1.0000000 protein_coding TNMD 3: ENSG00000000419 -3.1350554 -1.0936018 1.4297184098 0.2318104 0.9934706 protein_coding DPM1 4: ENSG00000000457 0.7839430 -0.4296291 0.3116571808 0.5766650 1.0000000 protein_coding SCYL3 5: ENSG00000000460 -0.1462899 5.1399138 0.0314383257 0.8592660 1.0000000 protein_coding FIRRM 6: ENSG00000000938 0.7110305 3.7377811 0.7053500976 0.4009918 1.0000000 protein_coding FGR . | . | . Enter your code: Copy Clear . | the GTF file method for zebrafish: gtf_path &lt;- \"/Users/jchoi/Desktop/Danio_rerio.GRCz11.111.gtf\" gtf_data &lt;- rtracklayer::import(gtf_path) gene_info &lt;- subset(gtf_data, type == \"gene\") all_attributes &lt;- elementMetadata(gene_info) gene_attributes_df &lt;- data.frame(all_attributes, stringsAsFactors = FALSE) write.csv(gene_attributes_df, \"annot.csv\") . | in these codes, . | Line 1: Specify the GTF file path. | Line 2: Import the information from the GTF file using rtracklayer package. | Line 3: Creates a subset of gtf_data that includes only the entries where the type is \"gene\". The gene_info object will now contain only the gene-level annotations. | Line 4: Extracts the metadata (attributes) of the gene_info object using the elementMetadata function. The all_attributes object will contain all the attributes of the gene annotations. | Line 5: Converts the all_attributes object into a data frame named gene_attributes_df using the data.frame function. The stringsAsFactors = FALSE argument ensures that string columns are not converted to factors. | . Output . &gt; gene_attributes_df &lt;- data.frame(all_attributes, stringsAsFactors = FALSE) &gt; head(gene_attributes_df) source type score phase gene_id gene_version gene_name gene_source gene_biotype 1 havana gene NA NA ENSDARG00000103202 2 CR383668.1 havana lincRNA 2 ensembl_havana gene NA NA ENSDARG00000009657 8 fgfr1op2 ensembl_havana protein_coding 3 havana gene NA NA ENSDARG00000096472 2 AL845295.2 havana processed_transcript 4 havana gene NA NA ENSDARG00000096156 3 si:dkey-21h14.12 havana protein_coding 5 havana gene NA NA ENSDARG00000076160 6 si:dkey-285e18.2 havana protein_coding 6 havana gene NA NA ENSDARG00000117163 1 znf1114 havana protein_coding transcript_id transcript_version transcript_name transcript_source transcript_biotype tag exon_number exon_id 1 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 2 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 3 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 4 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 5 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; exon_version protein_id protein_version 1 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 2 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 3 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 4 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 5 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; . | . | For some other species (e.g. rice), there are also symbol conversion packages: library(riceidconverter) library(org.Osativa.eg.db) RAP &lt;- RiceIDConvert(myID = data$Name, fromType = \"MSU\", toType = \"RAP\") Symbol &lt;- RiceIDConvert(myID = data$MSU, fromType = \"MSU\", toType = \"SYMBOL\") ## Symbol indicates Gene ID (LOCXXXXXXX format) . | . ",
    "url": "/docs/RNASeq/DEG_edgeR_MANUAL/#step-by-step-running-guide-edger",
    
    "relUrl": "/docs/RNASeq/DEG_edgeR_MANUAL/#step-by-step-running-guide-edger"
  },"28": {
    "doc": "Normalization and DEG analysis with edgeR",
    "title": "Citations",
    "content": "edgeR/TMM . | Robinson, M. D., McCarthy, D. J., &amp; Smyth, G. K. (2010). edgeR: a Bioconductor package for differential expression analysis of digital gene expression data. bioinformatics, 26(1), 139-140. DOI | McCarthy, D. J., Chen, Y., &amp; Smyth, G. K. (2012). Differential expression analysis of multifactor RNA-Seq experiments with respect to biological variation. Nucleic acids research, 40(10), 4288-4297. DOI | . limma . | Ritchie, M. E., Phipson, B., Wu, D. I., Hu, Y., Law, C. W., Shi, W., &amp; Smyth, G. K. (2015). limma powers differential expression analyses for RNA-sequencing and microarray studies. Nucleic acids research, 43(7), e47-e47. DOI | . ",
    "url": "/docs/RNASeq/DEG_edgeR_MANUAL/#citations",
    
    "relUrl": "/docs/RNASeq/DEG_edgeR_MANUAL/#citations"
  },"29": {
    "doc": "Normalization and DEG analysis with edgeR",
    "title": "Normalization and DEG analysis with edgeR",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/RNASeq/DEG_edgeR_MANUAL/",
    
    "relUrl": "/docs/RNASeq/DEG_edgeR_MANUAL/"
  },"30": {
    "doc": "DEG - Visualization",
    "title": "Visualizing Differentially Expressed Genes: Volcano Plot and CPM Scatter Plot",
    "content": "Visual representation of differential expression analysis results is crucial for interpreting and communicating findings in RNA-seq experiments. Two common and highly informative plots used in this context are the volcano plot and the CPM (Counts Per Million) scatter plot. These visualizations provide intuitive insights into the data, highlighting genes that are significantly differentially expressed and their expression levels across conditions. This protocol was developed using a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes R version 4.4.0 running on macOS 14.4.1. ",
    "url": "/docs/RNASeq/DEG_plotting_MANUAL/#visualizing-differentially-expressed-genes-volcano-plot-and-cpm-scatter-plot",
    
    "relUrl": "/docs/RNASeq/DEG_plotting_MANUAL/#visualizing-differentially-expressed-genes-volcano-plot-and-cpm-scatter-plot"
  },"31": {
    "doc": "DEG - Visualization",
    "title": "Volcano Plot",
    "content": "A volcano plot combines statistical significance with the magnitude of change (fold change) in a single plot, making it a powerful tool for identifying DEGs. It plots the negative log10 adjust p-value or false discovery rate (FDR) against the log2 fold change, allowing for easy identification of genes that are both statistically significant and biologically meaningful. Required Packages: . library(ggplot2) library(ggrepel) library(egg) . ",
    "url": "/docs/RNASeq/DEG_plotting_MANUAL/#volcano-plot",
    
    "relUrl": "/docs/RNASeq/DEG_plotting_MANUAL/#volcano-plot"
  },"32": {
    "doc": "DEG - Visualization",
    "title": "Step-by-Step Guide",
    "content": "1. Load Your DEG Data as Base Type . | Load the DEG data from a CSV (can be used a txt file) file into a data frame. Ensure that the first row contains headers and the first column contains row names. Ctr &lt;- read.csv(\"Volcano.csv\", head = T, row.names = 1) . | The DEG data can be utilized directly for analysis. In this instance, ROS marker genes are identified (ROS.hallmark) and labeled (ROS) separately. Example of the first few rows of the data: &gt; head(Ctr) SYMBOL logFC logCPM PValue FDR ROS.hallmark ENSG00000204472 AIF1 9.025174 1.58214476 2.34e-40 1.62e-38 ENSG00000142168 SOD1 7.315282 -0.07862934 3.15e-13 3.49e-12 ROS ENSG00000268651 CTAG1A 6.390608 0.43013880 1.64e-07 1.06e-06 ENSG00000170417 TMEM182 6.254823 0.32867916 6.20e-07 3.72e-06 ENSG00000214960 CRPPA 6.254823 0.37677955 6.20e-07 3.72e-06 ENSG00000164675 IQUB 6.104918 -0.43713437 2.35e-06 1.32e-05 . | . 2. Draw a Basal Plot . | Use ggplot2 to create the basl Volcano plot: ggplot(data = Ctr, aes(x = logFC, y = FDR)) + geom_point() . | . 3. Adjust the y-axis to Display in Negative log10 FDR Format and Add Guide Lines . | Update the plot to transform the y-axis and add guide lines: p &lt;- ggplot(data = Ctr, aes(x = logFC, y = -log10(FDR))) + geom_point() + theme_minimal() p2 &lt;- p + geom_vline(xintercept=c(-1, 1), col = \"red\") + geom_hline(yintercept = -log10(0.05), col = \"red\") . | . 4. Seperate the Section of Significance by Appying FC and FDR . | Update the plot to distinguish the section of significant DEGs by appying FC and FDR: . # Filter data Ctr$diffexpressed &lt;- \"NO\" Ctr$diffexpressed[Ctr$logFC &gt; 1 &amp; Ctr$PValue &lt; 0.05] &lt;- \"UP\" Ctr$diffexpressed[Ctr$logFC &lt; -1 &amp; Ctr$PValue &lt; 0.05] &lt;- \"DOWN\" # Plotting p &lt;- ggplot(data = Ctr, aes(x = logFC, y = -log10(FDR))) + geom_point(aes(color = diffexpressed), size = 4, shape = 21, fill = c(\"#294A99\", \"#ECECEC\", \"#BE1826\")[factor(Ctr$diffexpressed)], alpha = 0.7, stroke = 0.1) + scale_color_manual(values = c(\"DOWN\" = \"black\", \"UP\" = \"black\", \"NO\" = \"black\")) + theme_minimal() + theme(legend.position = \"none\") + geom_vline(xintercept = c(-1, 1), col = \"red\") + geom_hline(yintercept = -log10(0.05), col = \"red\") . | In these codes, you can adjust the size (size), shape (shape), transparency (alpha), and stroke (stroke) of the points to fit your preferences. The fill parameter allows you to specify colors for \"DOWN\", \"NO\", and \"UP\" states using hex codes. Refer to the ggplot2 documentation for more detailed information. | Output: . | . 5. Represent Gene Names that Satisfy Specific Conditions Using ggrepel . | In this case, I found ROS-related genes in papers and databases and labeled them as ROS in the ROS.hallmark column. Replace the values in this column with the corresponding values in the SYMBOL column for plotting: . p2 &lt;- p + geom_text_repel( data = subset(Ctr, ROS.hallmark == \"ROS\"), aes(label = SYMBOL), box.padding = 0.35, point.padding = 0.3, max.overlaps = Inf, segment.color = 'black' ) . | To display only genes that meet specific criteria (e.g. DEGs), filter the data accordingly: # Filter data filtered_data &lt;- subset(Ctr, ROS.hallmark == \"ROS\" &amp; (logFC &gt;= 1 | logFC &lt;= -1) &amp; FDR &lt; 0.05) # Plotting p2 &lt;- p + geom_text_repel( data = filtered_data, aes(label = SYMBOL), box.padding = 0.35, point.padding = 0.3, max.overlaps = Inf, segment.color = 'black' ) . | Output: . | . Summarize . Ctr &lt;- read.csv(\"Volcano.csv\", head = T, row.names = 1) filtered_data &lt;- subset(Ctr, ROS.hallmark == \"ROS\" &amp; (logFC &gt;= 1 | logFC &lt;= -1) &amp; FDR &lt; 0.05) p &lt;- ggplot(data = Ctr, aes(x = logFC, y = -log10(FDR))) + geom_point(aes(color = diffexpressed), size = 4, shape = 21, fill = c(\"#294A99\", \"#ECECEC\", \"#BE1826\")[factor(Ctr$diffexpressed)], alpha = 0.7, stroke = 0.1) + scale_color_manual(values = c(\"DOWN\" = \"black\", \"UP\" = \"black\", \"NO\" = \"black\")) + theme_minimal() + theme(legend.position = \"none\", panel.border = element_rect(color = \"black\", fill = NA, size = 1)) + geom_vline(xintercept = c(-1, 1), col = \"red\") + geom_hline(yintercept = -log10(0.05), col = \"red\") + geom_text_repel( data = filtered_data, aes(label = SYMBOL), box.padding = 0.35, point.padding = 0.3, max.overlaps = Inf, segment.color = 'black', size = 3 ) # Adjust plot size for publication p2 &lt;- set_panel_size(p, width = unit(49, \"mm\"), height = unit(49, \"mm\")) grid.arrange(p2) . Enter your code: Copy Clear ",
    "url": "/docs/RNASeq/DEG_plotting_MANUAL/#step-by-step-guide",
    
    "relUrl": "/docs/RNASeq/DEG_plotting_MANUAL/#step-by-step-guide"
  },"33": {
    "doc": "DEG - Visualization",
    "title": "CPM Scatter Plot",
    "content": "The CPM scatter plot is used to visualize the normalized expression levels of genes between two conditions. By plotting the log-transformed CPM values of one condition against another, this scatter plot highlights the overall distribution and correlation of gene expression levels, helping to identify outliers and trends. ",
    "url": "/docs/RNASeq/DEG_plotting_MANUAL/#cpm-scatter-plot",
    
    "relUrl": "/docs/RNASeq/DEG_plotting_MANUAL/#cpm-scatter-plot"
  },"34": {
    "doc": "DEG - Visualization",
    "title": "Step-by-Step Guide",
    "content": "1. Load Your CPM Data as Base Type . | Load the CPM data from a CSV file into a data frame. Ensure that the first row contains headers and the first column contains row names: Ctr &lt;- read.csv(\"Scatter_CPM.csv\", head = T, row.names = 1) . | Example of the first few rows of the data: &gt; head(Ctr) shCon shMLL1 shNRF2 shUTX ENSG00000000003 -2.680285 -2.680285 -2.680285 -1.549635 ENSG00000000005 4.307581 4.677028 4.580042 4.872485 ENSG00000000419 -1.749770 -1.753980 -1.171245 -1.549635 ENSG00000000460 5.275807 5.093826 5.081307 4.986667 ENSG00000000938 3.287921 3.437214 4.075670 3.266172 ENSG00000000971 5.988133 4.288445 5.394514 4.854088 . | . 2. Caculate Correlation Coefficiency Between Samples . | Calculate the linear model to assess the relationship between two samples. This can help determine how similar the expression levels are between two conditions: # Fit a lineat model model &lt;- lm(formula = shCon ~ shMLL1, data = Ctr) # Summarize the model to get the correlation coefficient model_summary &lt;- summary(model) # Extract coefficiency intercept &lt;- model$coefficients[1] slope &lt;- model$coefficients[2] r_squared &lt;- model_summary$r.squared . | Output: &gt; model &lt;- lm(formula = shCon ~ shMLL1, data = Ctr) &gt; model Call: lm(formula = shCon ~ shMLL1, data = Ctr) Coefficients: (Intercept) shMLL1 -0.01902 0.97918 . &gt; model_summary &lt;- summary(model) &gt; model_summary Call: lm(formula = shCon ~ shMLL1, data = Ctr) Residuals: Min 1Q Median 3Q Max -4.9938 -0.2207 -0.0368 0.2283 7.4868 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -0.019021 0.007697 -2.471 0.0135 * shMLL1 0.979179 0.001696 577.328 &lt;2e-16 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Residual standard error: 0.6539 on 10026 degrees of freedom Multiple R-squared: 0.9708, Adjusted R-squared: 0.9708 F-statistic: 3.333e+05 on 1 and 10026 DF, p-value: &lt; 2.2e-16 . | . 3. Make a scatter plot . | In this section, you will create a scatter plot to visualize the relationship between two conditions (shCon and shMLL1) and classify genes based on their expression changes: # Calculate difference between samples classify &lt;- (Ctr$shMLL1) - (Ctr$shCon) # Classify genes Ctr$diffexpressed &lt;- \"NO\" Ctr$diffexpressed[classify &gt; 0.5] &lt;- \"UP\" Ctr$diffexpressed[classify &lt; (-0.5)] &lt;- \"DOWN\" # Depict a plot with the linear model p &lt;- ggplot(data = Ctr, aes(x = shCon, y = shMLL1)) + geom_point(aes(color = diffexpressed), size = 4, shape = 21, fill = c(\"#294A99\", \"#ECECEC\", \"#BE1826\")[factor(Ctr$diffexpressed)], alpha = 0.7, stroke = 0.1) + scale_color_manual(values = c(\"DOWN\" = \"black\", \"UP\" = \"black\", \"NO\" = \"black\")) + theme_minimal() + theme(legend.position = \"none\", panel.border = element_rect(color = \"black\", fill = NA, size = 1)) + geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") + annotate(\"text\", x = Inf, y = -Inf, label = sprintf(\"y = %.4fx + %.4f\\nR² = %.4f\", slope, intercept, r_squared), hjust = 1.1, vjust = -0.1, size = 5, color = \"blue\") . | Output: . | . Summarize . Ctr &lt;- read.csv(\"Scatter_CPM.csv\", head = T, row.names = 1) model &lt;- lm(formula = shCon ~ shMLL1, data = Ctr) model_summary &lt;- summary(model) intercept &lt;- model$coefficients[1] slope &lt;- model$coefficients[2] r_squared &lt;- model_summary$r.squared p &lt;- ggplot(data = Ctr, aes(x = shCon, y = shMLL1)) + geom_point(aes(color = diffexpressed), size = 4, shape = 21, fill = c(\"#294A99\", \"#ECECEC\", \"#BE1826\")[factor(Ctr$diffexpressed)], alpha = 0.7, stroke = 0.1) + scale_color_manual(values = c(\"DOWN\" = \"black\", \"UP\" = \"black\", \"NO\" = \"black\")) + theme_minimal() + theme(legend.position = \"none\", panel.border = element_rect(color = \"black\", fill = NA, size = 1)) + geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") + annotate(\"text\", x = Inf, y = -Inf, label = sprintf(\"y = %.4fx + %.4f\\nR² = %.4f\", slope, intercept, r_squared), hjust = 1.1, vjust = -0.1, size = 5, color = \"blue\") # Adjust plot size for publication p2 &lt;- set_panel_size(p, width = unit(49, \"mm\"), height = unit(49, \"mm\")) grid.arrange(p2) . Enter your code: Copy Clear ",
    "url": "/docs/RNASeq/DEG_plotting_MANUAL/#step-by-step-guide-1",
    
    "relUrl": "/docs/RNASeq/DEG_plotting_MANUAL/#step-by-step-guide-1"
  },"35": {
    "doc": "DEG - Visualization",
    "title": "Citations",
    "content": "R/ggplot . | R Core Team, R. (2013). R: A language and environment for statistical computing. HTML | Wilkinson, L. (2011). ggplot2: elegant graphics for data analysis by WICKHAM, H. DOI | . ",
    "url": "/docs/RNASeq/DEG_plotting_MANUAL/#citations",
    
    "relUrl": "/docs/RNASeq/DEG_plotting_MANUAL/#citations"
  },"36": {
    "doc": "DEG - Visualization",
    "title": "DEG - Visualization",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/RNASeq/DEG_plotting_MANUAL/",
    
    "relUrl": "/docs/RNASeq/DEG_plotting_MANUAL/"
  },"37": {
    "doc": "Data Process",
    "title": "Data Process",
    "content": "In the sequencing data processing section, we delve into the essential steps required to prepare raw sequencing data for downstream analyses. This includes quality control (QC) to assess and ensure data integrity, trimming to remove low-quality sequences and adapters, and mapping reads to reference genomes for both RNA and ChIP-seq data. Additionally, I cover file conversion to appropriate formats and proper storage methods to maintain data accessibility and integrity. These preprocessing steps are critical for generating reliable and accurate results in any sequencing-based study. ",
    "url": "/docs/DataProcess",
    
    "relUrl": "/docs/DataProcess"
  },"38": {
    "doc": "Basal Quality Control with FastQC",
    "title": "Quality Check (QC) on Sequencing Files with FastQC",
    "content": "This part performs the quality check (QC) on fastq sequencing files, which are received from the sequencing facility. The fastq files store raw sequencing data, capturing both the nucleotide sequence and its corresponding quality score. Various QC tools have been developed and modified, although we still recommend using FastQC originated by Babraham Bioinformatics. As FastQC is based on GUI, it can be easily accessible and intuitive. However, GUI-based FastQC provides single-core processing. To operate with multithreaded processing, python-coded FastQC is required. This protocol was created based on FastQC version 0.11.9 running on a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes *Python version 3.8.5 under macOS 12.4 environment. ",
    "url": "/docs/DataProcess/FastQC_manual/#quality-check-qc-on-sequencing-files-with-fastqc",
    
    "relUrl": "/docs/DataProcess/FastQC_manual/#quality-check-qc-on-sequencing-files-with-fastqc"
  },"39": {
    "doc": "Basal Quality Control with FastQC",
    "title": "Viewing a fastq File",
    "content": "To understand the structure of fastq files, you can use the following commands: . $ gzip -cd &lt;filenames.gz&gt; | head -n &lt;int&gt; # &lt;int&gt;: Specify the number of lines to output. # for example $ gzip -cd shCon_Unt_1.fastq.gz | head -n 6 $ gzip -cd shCon_Unt_1.fastq.gz | tail -n 10 . ",
    "url": "/docs/DataProcess/FastQC_manual/#viewing-a-fastq-file",
    
    "relUrl": "/docs/DataProcess/FastQC_manual/#viewing-a-fastq-file"
  },"40": {
    "doc": "Basal Quality Control with FastQC",
    "title": "Output",
    "content": "When gzip finished typing, it prints messages showing fastq file look like this: . $ gzip -cd shCon_Unt_1.fastq.gz | head -n 4 @A00718:626:HH5N7DSXC:3:1101:2067:1000 1:N:0:TTCTATAC+GGTTCCAA # Line 1 NCCGCCGCCGACCACCAGAATACAGCTGTACATCTTACGCTTCGTCTCGTCCGACGCACAGGAGTCGATGCTGTGCAGGATGGCTTTATCGATGCCCAGAG # Line 2 + # Line 3 %FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF # Line 4 . In this result, . | Line 1 specifies “Header Line” that contains the sequencing information, including platform ID, flow cell ID/coordinated, filtering, multiplex sequence. | Line 2 specifies “Sequence Line” that represents the actual cDNA sequence. The letter “N” is used when a specific base cannot be determined. | Line 3 specifies “Plus Line” that contains just a “+”, and this is ignored. | Line 4 specifies “Quality Score Line” that displays the quality scores for each base as ASCII characters. | . ",
    "url": "/docs/DataProcess/FastQC_manual/#output",
    
    "relUrl": "/docs/DataProcess/FastQC_manual/#output"
  },"41": {
    "doc": "Basal Quality Control with FastQC",
    "title": "Installation FastQC",
    "content": ". To install FastQC via homebrew, use the following commands: . $ brew install fastqc . ",
    "url": "/docs/DataProcess/FastQC_manual/#installation-fastqc",
    
    "relUrl": "/docs/DataProcess/FastQC_manual/#installation-fastqc"
  },"42": {
    "doc": "Basal Quality Control with FastQC",
    "title": "Running FastQC",
    "content": "Use the following command to perform QC with FastQC: . $ fastqc -o &lt;output_folder&gt; -f &lt;format&gt; -t &lt;int&gt; &lt;input-1&gt; ... &lt;input-N&gt; . In these commands: . | -o &lt;output_folder&gt;: Specifies the output folder. | -f &lt;format&gt;: Specifies the input file types. | -t &lt;int&gt;: Specifies the number of threads used in this operation. | &lt;input-1&gt; ... &lt;input-N&gt;: Specifies the input data, it is must be separated by spaces. | . ",
    "url": "/docs/DataProcess/FastQC_manual/#running-fastqc",
    
    "relUrl": "/docs/DataProcess/FastQC_manual/#running-fastqc"
  },"43": {
    "doc": "Basal Quality Control with FastQC",
    "title": "Example Code",
    "content": "Here is an example command to perform QC on multiple fastq files: . $ fastqc -o ~/Desktop/Fastq/FastQC/ -f fastq -t 10 \\ shCon_H2O2_1.fastq.gz shCon_Unt_1.fastq.gz shMLL1_NP_1.fastq.gz shNRF2_H2O2_1.fastq.gz \\ shNRF2_Unt_1.fastq.gz shUTX_NP_1.fastq.gz shCon_H2O2_2.fastq.gz shCon_Unt_2.fastq.gz \\ shMLL1_NP_2.fastq.gz shNRF2_H2O2_2.fastq.gz shNRF2_Unt_2.fastq.gz shUTX_NP_2.fastq.gz \\ shCon_NP_1.fastq.gz shMLL1_H2O2_1.fastq.gz shMLL1_Unt_1.fastq.gz shNRF2_NP_1.fastq.gz \\ shUTX_H2O2_1.fastq.gz shUTX_Unt_1.fastq.gz shCon_NP_2.fastq.gz shMLL1_H2O2_2.fastq.gz \\ shMLL1_Unt_2.fastq.gz shNRF2_NP_2.fastq.gz shUTX_H2O2_2.fastq.gz shUTX_Unt_2.fastq.gz . Open the name_fastqc.html file that is created in the output folder to check the QC information. ",
    "url": "/docs/DataProcess/FastQC_manual/#example-code",
    
    "relUrl": "/docs/DataProcess/FastQC_manual/#example-code"
  },"44": {
    "doc": "Basal Quality Control with FastQC",
    "title": "Installation MultiQC",
    "content": ". MultiQC is a tool to create a single report with interactive plots for multiple bioinformatics analyses across many samples. Reports are generated by scanning given directories for recognised log files. These are parsed and a single HTML report is generated summarising the statistics for all logs found. To install multiqc via PyPI, use the following command: . $ pip install multiqc . ",
    "url": "/docs/DataProcess/FastQC_manual/#installation-multiqc",
    
    "relUrl": "/docs/DataProcess/FastQC_manual/#installation-multiqc"
  },"45": {
    "doc": "Basal Quality Control with FastQC",
    "title": "Export Report via multiqc",
    "content": "Once installed, you can use multiqc by navigating to your analysis directory (or a parent directory) and running the tool: . $ multiqc ./ . That is it. multiqc will scan the specified directory (. is the current dir) and produce a report detailing whatever it finds. ",
    "url": "/docs/DataProcess/FastQC_manual/#export-report-via-multiqc",
    
    "relUrl": "/docs/DataProcess/FastQC_manual/#export-report-via-multiqc"
  },"46": {
    "doc": "Basal Quality Control with FastQC",
    "title": "Citations",
    "content": "FastQC . | Andrews, S., Krueger, F., Segonds-Pichon, A., Biggins, L., Krueger, C., &amp; Wingett, S. (2010). FastQC. A quality control tool for high throughput sequence data, 370. | . MultiQC . | Ewels, P., Magnusson, M., Lundin, S., &amp; Käller, M. (2016). MultiQC: summarize analysis results for multiple tools and samples in a single report. Bioinformatics, 32(19), 3047-3048. DOI | . ",
    "url": "/docs/DataProcess/FastQC_manual/#citations",
    
    "relUrl": "/docs/DataProcess/FastQC_manual/#citations"
  },"47": {
    "doc": "Basal Quality Control with FastQC",
    "title": "Basal Quality Control with FastQC",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/DataProcess/FastQC_manual/",
    
    "relUrl": "/docs/DataProcess/FastQC_manual/"
  },"48": {
    "doc": "DEG - Gene ontology and KEGG pathway analysis",
    "title": "Understanding Gene Functions: An Overview of Gene Ontology and KEGG Pathway Analysis",
    "content": "Gene Ontology (GO) and KEGG Pathway analysis are essential bioinformatics tools for understanding gene functions and their roles within biological systems. GO provides a structured framework for classifying gene functions across different species, organizing them into three main categories: Biological Process, Molecular Function, and Cellular Component. This classification helps researchers comprehend the biological context and interactions of genes. On the other hand, KEGG Pathway analysis maps genes to known biological pathways, allowing scientists to visualize and interpret complex biochemical processes and molecular interactions within the cell. Together, these tools facilitate a deeper understanding of gene functions and their contributions to various biological phenomena. This protocol was developed using a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes R version 4.4.0 running on macOS 14.4.1. Currently, GO/KEGG analysis is generally categorized into web-based and terminal-based formats. In this section, I will elaborate on the functional analysis of genes using the widely-used web-based tool, DAVID, as well as the terminal-based tools, enrichGO and enrichKEGG, which are part of the clusterProfile R package. ",
    "url": "/docs/RNASeq/GO_KEGG_MANUAL/#understanding-gene-functions-an-overview-of-gene-ontology-and-kegg-pathway-analysis",
    
    "relUrl": "/docs/RNASeq/GO_KEGG_MANUAL/#understanding-gene-functions-an-overview-of-gene-ontology-and-kegg-pathway-analysis"
  },"49": {
    "doc": "DEG - Gene ontology and KEGG pathway analysis",
    "title": "Web-based Tool: DAVID",
    "content": "DAVID (Database for Annotation, Visualization, and Integrated Discovery) is a comprehensive web-based tool that offers functional annotation tools for interpreting the biological significance of large gene lists. Integrates multiple annotation resources, including GO and KEGG, for functional annotation, gene ontology enrichment, pathway mapping, and visualization. | Advantage | Disadvantage | . | - User-friendly interface with integrated resources. - Allows easy upload of gene lists and quick retrieval of functional annotations. - Provides a variety of visualization tools to aid interpretation. | - Limited customization options compared to command-line tools. - Dependent on internet access and server availability. - Can be slower with very large datasets. | . ",
    "url": "/docs/RNASeq/GO_KEGG_MANUAL/#web-based-tool-david",
    
    "relUrl": "/docs/RNASeq/GO_KEGG_MANUAL/#web-based-tool-david"
  },"50": {
    "doc": "DEG - Gene ontology and KEGG pathway analysis",
    "title": "Step-by-Step DAVID Guide",
    "content": ". | Go to the DAVID website. | Click Start Analysis on the website. | Paste your gene list in the step 1 box. | In this example, I selected 1962 upragulated DEGs included by osteogenic stimuli and uploaded them. These genes designated as Ensembl IDs rather than gene symbols. | . | Select identifier. | Choose your gene type. In this example, I selected “ENSEMBL_GENE_ID”. | Note that Ensembl IDs have different prefixes for different species, so specifying a species is not necessary, but some identifiers may require it. | . | Select the list type as either gene list or ‘background’. | Gene List: This is the primary list of genes you are interested in analyzing. It is the focus of your enrichment analysis. | Background (Optional): This is an optional list used to define the background set of genes against which your gene list is compared. If not provided, DAVID uses a default background set based on the genome of the organism. | . | Click Submit List. | Check the Gene List Manager in the left panel. | The number of genes that DAVID recognized and those it did not (Unknown) will appear. If there are many unknown genes, consider re-uploading using a conversion tool or another identifier. | . | Click Functional Annotation Tool in the center panel. | DAVID will display the Annotation Summary Results. | Use the Gene Ontology section and the Pathway section in the results to explore the functional annotation and enrichment of your gene list. | All data is available for download as tab-delimited text. | . | . ",
    "url": "/docs/RNASeq/GO_KEGG_MANUAL/#step-by-step-david-guide",
    
    "relUrl": "/docs/RNASeq/GO_KEGG_MANUAL/#step-by-step-david-guide"
  },"51": {
    "doc": "DEG - Gene ontology and KEGG pathway analysis",
    "title": "Understanding Gene Ontology section",
    "content": "In DAVID functional annotation results, when you click on the GO section, you encounter several subsections labeled as BP (Biological Process), MF (Molecular Function), CC (Cellular Component), followed by labels such as _1 to _5, ALL, and DIRECT. Here is what each of these terms signifies: . | BP (Biological Process): This section pertains to biological objectives or roles completed by sets of molecular activities. Examples include cellular processes and metabolic functions. | MF (Molecular Function): This section describes the biochemical activity of genes, such as binding or catalysis, independent of the gene products (e.g., protein) performing them. | CC (Cellular Component): This part describes where gene products are located in the cell, such as membranes or organelles. | ALL: This category provides a consolidated view of the results across all three GO domains (BP, MF, CC), offering a comprehensive overview without the segregation into specific domains. | DIRECT: This indicates the annotation derived directly from the primary literature and not inferred from other sources or computational predictions. It is typically more specific and can be considered more reliable as it is directly tied to experimental evidence. | . | Lower numbers (like _1 or _2) generally indicate groups of GO terms that are more general and broadly applicable to a variety of biological contexts. As the numbers increase (towards _3, _4, and _5), the GO terms become more specific and detailed. These higher numbers represent more niche and precise annotations that are closely related to the specific functions or locations of the genes in your list. | . ",
    "url": "/docs/RNASeq/GO_KEGG_MANUAL/#understanding-gene-ontology-section",
    
    "relUrl": "/docs/RNASeq/GO_KEGG_MANUAL/#understanding-gene-ontology-section"
  },"52": {
    "doc": "DEG - Gene ontology and KEGG pathway analysis",
    "title": "Understanding GO/KEGG Analysis Output",
    "content": ". | Open GO result with R: &gt; GO_DAVID &lt;- read.table(\"Up_GO.txt\", sep = \"\\t\", header = TRUE) &gt; GO_DAVID Category Term Count Percent PValue Genes ListTotal PopHits 1 GOTERM_BP_DIRECT GO:0006629~lipid metabolic process 119 6.0994362 6.263319e-12 ENSMUSG00000025350 1695 741 2 GOTERM_BP_DIRECT GO:0001666~response to hypoxia 43 2.2039979 1.888764e-07 ENSMUSG00000034205 1695 215 3 GOTERM_BP_DIRECT GO:0006811~ion transport 84 4.3054844 5.390971e-06 ENSMUSG00000031075 1695 605 4 GOTERM_BP_DIRECT GO:0006956~complement activation 12 0.6150692 7.838427e-06 ENSMUSG00000022018 1695 28 5 GOTERM_BP_DIRECT GO:0001649~osteoblast differentiation 25 1.2813942 1.118882e-05 ENSMUSG00000008136 1695 110 PopTotal FoldEnrichment Bonferroni Benjamini FDR 1 20199 1.913766 3.367162e-08 3.367160e-08 3.352128e-08 2 20199 2.383363 1.014884e-03 5.076997e-04 5.054332e-04 3 20199 1.654566 2.856599e-02 9.660621e-03 9.617493e-03 4 20199 5.107206 4.126402e-02 9.976222e-03 9.931685e-03 5 20199 2.708367 5.837805e-02 9.976222e-03 9.931685e-03 . | Open KEGG result with R: &gt; KEGG_DAVID &lt;- read.table(\"Up_KEGG.txt\", sep = \"\\t\", header = TRUE) &gt; KEGG_DAVID Category Term Count Percent PValue 1 KEGG_PATHWAY mmu01100:Metabolic pathways 214 10.968734 3.927550e-11 2 KEGG_PATHWAY mmu00982:Drug metabolism - cytochrome P450 21 1.076371 1.615860e-06 3 KEGG_PATHWAY mmu00760:Nicotinate and nicotinamide metabolism 13 0.666325 1.704787e-04 4 KEGG_PATHWAY mmu05208:Chemical carcinogenesis - reactive oxygen species 37 1.896463 2.304140e-04 5 KEGG_PATHWAY mmu04014:Ras signaling pathway 36 1.845208 1.168008e-03 Genes ListTotal PopHits PopTotal FoldEnrichment Bonferroni Benjamini FDR 1 ENSMUSG00000031231827 1625 9463 9463 1.506898 1.327511e-08 1.327512e-08 1.284309e-08 2 ENSMUSG00000074183 827 71 9463 3.384420 5.460121e-04 2.730804e-04 2.641932e-04 3 ENSMUSG00000115338 827 42 9463 3.541746 5.599775e-02 1.920727e-02 1.858218e-02 4 ENSMUSG00000074183 827 224 9463 1.890066 7.493281e-02 1.946998e-02 1.883635e-02 5 ENSMUSG00000031453 827 235 9463 1.752903 3.263318e-01 6.597445e-02 6.382735e-02 . | . When interpreting the results of a GO or KEGG analysis, several key metrics are presented: . | Count: This metric indicates the number of genes associated with a particular GO and KEGG term within the list of genes being analyzed. | List Total: Represents the total number of genes analyzed. This value serves as the denominator for calculating proportions of genes associated with specific GO/KEGG terms. | Pop Hits: Refers to the number of genes associated with the same GO term in the reference gene set, which typically includes all genes in the organism’s genome. | Pop Total: The total number of genes in the reference gene set. This number is used to normalize the data and helps in calculating how representative the term is in the context of the entire genome. | Fold Enrichment: This is a crucial statistic that indicates how much more often genes associated with a particular GO term are observed in the list of analyzed genes compared to what would be expected based on their representation in the genome. | . ",
    "url": "/docs/RNASeq/GO_KEGG_MANUAL/#understanding-gokegg-analysis-output",
    
    "relUrl": "/docs/RNASeq/GO_KEGG_MANUAL/#understanding-gokegg-analysis-output"
  },"53": {
    "doc": "DEG - Gene ontology and KEGG pathway analysis",
    "title": "Alternative Web-based Tool: Gene Ontology Resource",
    "content": "The Gene Ontology Resource provides web-based tools for exploring GO annotations and performing enrichment analysis. This tools offers access to extensive GO annotations, tools for functional profiling, and interfaces for browsing and searching GO terms. Go to the Gene Ontology Resource. | Advantage | Disadvantage | . | - User-friendly and accessible without needing programming skills. - Comprehensive and detailed GO term information. - Regularly updated with the latest GO terms and annotations. | - Limited to GO analysis without extensive pathway mapping like KEGG. - Customization and advanced analysis options are less flexible than in command-line tools. - Relies on internet access and web interface performance. | . ",
    "url": "/docs/RNASeq/GO_KEGG_MANUAL/#alternative-web-based-tool-gene-ontology-resource",
    
    "relUrl": "/docs/RNASeq/GO_KEGG_MANUAL/#alternative-web-based-tool-gene-ontology-resource"
  },"54": {
    "doc": "DEG - Gene ontology and KEGG pathway analysis",
    "title": "Depicting a Bubble Chart from GO/KEGG Analysis Results",
    "content": "A bubble chart is an exceptionally effective visual tool for presenting the results of GO and KEGG analyses. This type of chart enhances the visualization of the significance and impact of gene sets across different biological processes, molecular functions, and cellular components. In a bubble chart: . | Each bubble represents a specific GO/KEGG term, providing a direct visual correlation to the biological aspect being analyzed. | The size of the bubble is determined by the number of genes associated with each GO/KEGG term, visually emphasizing terms with a greater gene count. | The color of each bubble varies according to the statistical significance (e.g., p-value), offering an immediate sense of the term relevance and the robustness of the associated data. | . In this section, I will construct a bubble chart using ggplot2 to display the GO analysis results. The y-axis will list the GO terms, while the x-axis will represent the gene ratio, indicating the proportion of genes linked to each GO term relative to the total number of genes analyzed. The size of each bubble will be proportional to the gene count associated with each term, and the color of bubble will reflect the statistical significance, providing a comprehensive and intuitive visual summary of the data. Required Packages: . library(ggplot2) library(dplyr) library(gridExtra) library(egg) library(readxl) . ",
    "url": "/docs/RNASeq/GO_KEGG_MANUAL/#depicting-a-bubble-chart-from-gokegg-analysis-results",
    
    "relUrl": "/docs/RNASeq/GO_KEGG_MANUAL/#depicting-a-bubble-chart-from-gokegg-analysis-results"
  },"55": {
    "doc": "DEG - Gene ontology and KEGG pathway analysis",
    "title": "Step-by-Step Guide for Depicting Bubble Chart with Multiple Facets",
    "content": "1. Data Preparation . | Import the Gene Ontology results from text files into R, ensuring that the files have headers in the first row and do not contain row names. This example uses data from a GO analysis of genes upregulated and downregulated by differentiation stimuli in normal mesenchymal stem cells: UP &lt;- read.table(\"upDEG.txt\", sep = \"\\t\", header = TRUE) DOWN &lt;- read.table(\"downDEG.txt\", sep = \"\\t\", header = TRUE) . | Next, select the five GO terms with the lowest False Discovery Rate (FDR). top_up &lt;- UP %&gt;% arrange(FDR) %&gt;% slice_head(n = 5) %&gt;% mutate(Type = \"Up-regulated\") top_down &lt;- DOWN %&gt;% arrange(FDR) %&gt;% slice_head(n = 5) %&gt;% mutate(Type = \"Down-regulated\") . | . Selecting the top 5-10 terms based on FDR is a common practice but not a strict rule. Researchers are encouraged to tailor the selection criteria based on the specific narrative and needs of their study. | Combine the top GO terms from both datasets into a single object and compute the Ratio of Count to List.Total for each term: combined &lt;- bind_rows(top_up, top_down) data &lt;- combined %&gt;% mutate(Ratio = Count / List.Total) . | Output: &gt; data Category Term Count X. PValue List.Total Pop.Hits Pop.Total 1 GOTERM_BP_DIRECT GO:0006629~lipid metabolic process 119 6.0994362 6.263319e-12 1695 741 20199 2 GOTERM_BP_DIRECT GO:0001666~response to hypoxia 43 2.2039979 1.888764e-07 1695 215 20199 3 GOTERM_BP_DIRECT GO:0006811~ion transport 84 4.3054844 5.390971e-06 1695 605 20199 4 GOTERM_BP_DIRECT GO:0006956~complement activation 12 0.6150692 7.838427e-06 1695 28 20199 5 GOTERM_BP_DIRECT GO:0001649~osteoblast differentiation 25 1.2813942 1.118882e-05 1695 110 20199 6 GOTERM_BP_DIRECT GO:0007049~cell cycle 190 9.8752599 9.081317e-52 1798 649 20199 7 GOTERM_BP_DIRECT GO:0051301~cell division 126 6.5488565 2.885314e-37 1798 404 20199 8 GOTERM_BP_DIRECT GO:0007059~chromosome segregation 55 2.8586279 9.352744e-28 1798 111 20199 9 GOTERM_BP_DIRECT GO:0006260~DNA replication 55 2.8586279 7.029347e-26 1798 119 20199 10 GOTERM_BP_DIRECT GO:0006281~DNA repair 100 5.1975052 5.008471e-22 1798 395 20199 Fold.Enrichment Bonferroni Benjamini FDR Type Ratio 1 1.913766 3.367162e-08 3.367160e-08 3.352128e-08 Up-regulated 0.070206490 2 2.383363 1.014884e-03 5.076997e-04 5.054332e-04 Up-regulated 0.025368732 3 1.654566 2.856599e-02 9.660621e-03 9.617493e-03 Up-regulated 0.049557522 4 5.107206 4.126402e-02 9.976222e-03 9.931685e-03 Up-regulated 0.007079646 5 2.708367 5.837805e-02 9.976222e-03 9.931685e-03 Up-regulated 0.014749263 6 3.288888 5.278062e-48 5.278062e-48 5.175443e-48 Down-regulated 0.105672970 7 3.503720 1.676944e-33 8.384722e-34 8.221701e-34 Down-regulated 0.070077864 8 5.566470 5.435815e-24 1.811938e-24 1.776710e-24 Down-regulated 0.030589544 9 5.192254 4.085457e-22 1.021364e-22 1.001506e-22 Down-regulated 0.030589544 10 2.844088 2.910923e-18 5.821847e-19 5.708655e-19 Down-regulated 0.055617353 . In this example, the ‘Genes’ column was excessively lengthy and has been remove to NULL to streamline the dataset. | When working with data not originating directly from txt files, such as arbitrarily selected GO terms for specific analyses, using Excel can be advantageous. Pre-calculate Type and Ratio in Excel using its functions. This preparation makes the data ready for immediate plotting upon import into R. data &lt;- read_excel(\"PlotGO.xlsx\", sheet = \"DOWN_Facet\") . | . 2. Plotting . | Draw a Basal Plot: S1 &lt;- ggplot(data, aes(x = Ratio, y = reorder(Term, Ratio), size = Count, color = PValue)) + geom_point(alpha = 1) + facet_grid(factor(Type, levels = c(\"Up-regulated\", \"Down-regulated\")) ~ ., scales = \"free\") + labs(x = \"Gene Ratio\", y = \"\") + theme(panel.background = element_rect(fill = 'white', color = 'black', linetype = 'solid', size = 1), panel.grid.major = element_line(color = \"grey\", size = 0.2), strip.background = element_rect(fill = \"grey80\", color = \"black\", size = 1, linetype = 'solid'), strip.text = element_text(color = \"black\"), legend.key = element_blank(), legend.text = element_text(size = 10), legend.title = element_text(face = \"bold\"), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) + guides(color = guide_colourbar(barwidth = 0.8, barheight = 4)) . | Change graphical components: # Color space S1 = S1 + scale_color_gradient(low = \"red2\", high = \"mediumblue\", space = \"Lab\") # Buble size range can be variable as follow: S2 &lt;- S1+scale_size(range = c(2, 5)) # Adjust the x-axis S3 &lt;- S2 + xlim(0, 0.12) # Adjust chart size for publication, 26.5/25 (width) and 30/33/40 (height) combination S4 &lt;- set_panel_size(S3, width = unit(26.5, \"mm\"), height = unit(30, \"mm\")) grid.arrange(S4) . | Output: . | . Enter your code: Copy Clear ",
    "url": "/docs/RNASeq/GO_KEGG_MANUAL/#step-by-step-guide-for-depicting-bubble-chart-with-multiple-facets",
    
    "relUrl": "/docs/RNASeq/GO_KEGG_MANUAL/#step-by-step-guide-for-depicting-bubble-chart-with-multiple-facets"
  },"56": {
    "doc": "DEG - Gene ontology and KEGG pathway analysis",
    "title": "Step-by-Step Guide for Depicting Bubble Chart with a Single Column",
    "content": "1. Data Preparation . | Import the Gene Ontology results from text files into R. This example uses data from a GO analysis of genes upregulated by differentiation stimuli in normal mesenchymal stem cells: UP &lt;- read.table(\"upDEG.txt\", sep = \"\\t\", header = TRUE) . | Next, select the 10 GO terms with the lowest FDR. Once again, selecting 10 GO terms as FDR criteria is not mandatory. Then, calculate the ‘Ratio’ of ‘Count’ to ‘List.Total’. top_up &lt;- UP %&gt;% arrange(FDR) %&gt;% slice_head(n = 10) data &lt;- top_up %&gt;% mutate(Ratio = Count / List.Total) . | . 2. Plotting . | Draw a Basal Plot: S1 &lt;- ggplot(data, aes(x = Ratio, y = reorder(Term, Ratio), size = Count, color = PValue)) + geom_point(alpha = 1) + labs(x = \"Gene Ratio\", y = \"\") + theme(panel.background = element_rect(fill = 'white', color = 'black', linetype = 'solid', size = 1), panel.grid.major = element_line(color = \"grey\", size = 0.2), strip.text = element_text(color = \"black\"), legend.key = element_blank(), legend.text = element_text(size = 10), legend.title = element_text(face = \"bold\"), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) + guides(color = guide_colourbar(barwidth = 0.8, barheight = 4)) . | Change graphical components: # Color space S1 = S1 + scale_color_gradient(low = \"red2\", high = \"mediumblue\", space = \"Lab\") # Buble size range can be variable as follow: S2 &lt;- S1+scale_size(range = c(2, 5)) # Adjust the x-axis S3 &lt;- S2 + xlim(0, 0.09) # Adjust chart size for publication S4 &lt;- set_panel_size(S3, width = unit(26.5, \"mm\"), height = unit(48, \"mm\")) grid.arrange(S4) . | Output: . | . Enter your code: Copy Clear ",
    "url": "/docs/RNASeq/GO_KEGG_MANUAL/#step-by-step-guide-for-depicting-bubble-chart-with-a-single-column",
    
    "relUrl": "/docs/RNASeq/GO_KEGG_MANUAL/#step-by-step-guide-for-depicting-bubble-chart-with-a-single-column"
  },"57": {
    "doc": "DEG - Gene ontology and KEGG pathway analysis",
    "title": "Terminal-based GO Tools: enrichGO and enrichKEGG",
    "content": "The enrichGO and enrichKEGG are powerful R package part of the clusterProfiler suite, designed for the functional annotation and enrichment analysis of gene lists. They provide robust tools for GO and pathway enrichment analyses, allowing researchers to interpret the biological significance of large gene sets through comprehensive statistical analyses. | Advantage | Disadvantage | . | - High level of customization and flexibility. - Capable of handling large datasets efficiently. - Integrates well with other R packages for further analysis and visualization. - Provides reproducible results as part of R scripts or workflows. | - Requires knowledge of R and command-line operations. - Steeper learning curve for users unfamiliar with programming. - Lack of a graphical user interface, which may be less intuitive for some users. | . Required Packages: . library(clusterProfiler) library(org.Mm.eg.db) # Organism-specific genome data package, refer to bellow. library(dplyr) library(enrichplot) library(ggplot2) library(gridExtra) library(egg) library(readxl) . ",
    "url": "/docs/RNASeq/GO_KEGG_MANUAL/#terminal-based-go-tools-enrichgo-and-enrichkegg",
    
    "relUrl": "/docs/RNASeq/GO_KEGG_MANUAL/#terminal-based-go-tools-enrichgo-and-enrichkegg"
  },"58": {
    "doc": "DEG - Gene ontology and KEGG pathway analysis",
    "title": "Choosing the Appropriate Organism Database",
    "content": ". | For organisms other than mouse, you need to use the appropriate organism-specific database. To find the appropriate database for your organism, you can search the Bioconductor website or use the BiocManager package’s search functionality: BiocManager::available(\"org.\") . &gt; BiocManager::available(\"org.\") 'getOption(\"repos\")' replaces Bioconductor standard repositories, see 'help(\"repositories\", package = \"BiocManager\")' for details. Replacement repositories: CRAN: http://cran.rstudio.com/ [1] \"AnnotationForge\" \"BarBorGradient\" \"BSgenomeForge\" \"facebookorganicR\" \"forge\" [6] \"IsoCorrectoRGUI\" \"KTensorGraphs\" \"org.Ag.eg.db\" \"org.At.tair.db\" \"org.Bt.eg.db\" [11] \"org.Ce.eg.db\" \"org.Cf.eg.db\" \"org.Dm.eg.db\" \"org.Dr.eg.db\" \"org.EcK12.eg.db\" [16] \"org.EcSakai.eg.db\" \"org.Gg.eg.db\" \"org.Hs.eg.db\" \"org.Mm.eg.db\" \"org.Mmu.eg.db\" [21] \"org.Mxanthus.db\" \"org.Pf.plasmo.db\" \"org.Pt.eg.db\" \"org.Rn.eg.db\" \"org.Sc.sgd.db\" [26] \"org.Ss.eg.db\" \"org.Xl.eg.db\" \"Organism.dplyr\" \"OrganismDbi\" \"organizr\" [31] \"OrgMassSpecR\" \"orgR\" \"orgutils\" \"OscillatorGenerator\" \"pd.porgene.1.0.st\" [36] \"pd.porgene.1.1.st\" \"PriorGen\" \"rNeighborGWAS\" \"RNGforGPD\" \"sectorgap\" . | Then you can install the required organism database using Bioconductor: BiocManager::install(\"org.*.eg.db\") # '*' is organism abb. library(org.*.eg.db) . | . ",
    "url": "/docs/RNASeq/GO_KEGG_MANUAL/#choosing-the-appropriate-organism-database",
    
    "relUrl": "/docs/RNASeq/GO_KEGG_MANUAL/#choosing-the-appropriate-organism-database"
  },"59": {
    "doc": "DEG - Gene ontology and KEGG pathway analysis",
    "title": "Step-by-Step enrichGO Guide",
    "content": "1. Data Preparation . | Load raw DEG data obtained from edgeR or user-modified DEG data into R, ensuring that the files have headers in the first row and do not contain row names. In this section, I will load the raw data of gene list (result of edgeR) that change on osteogenic stimuli in mouse stem cells, filtering out only the DEGs that are upregulated: . # Load data data &lt;- read.csv(\"DEG.csv\", header = T) # Filter data UP &lt;- data %&gt;% filter(logFC &gt;= 1, FDR &lt; 0.05) . &gt; head(UP) Symbol ensembl_gene_id logFC logCPM PValue FDR osteoMarker 1 Tbx2 ENSMUSG00000000093 3.044420 0.1584658 8.460000e-09 1.020000e-07 2 Axin2 ENSMUSG00000000142 1.695402 -0.9306477 8.412736e-03 2.965543e-02 Osteo 3 Itgb2 ENSMUSG00000000290 2.506077 0.8950346 2.250000e-11 3.870000e-10 4 Fap ENSMUSG00000000392 2.422669 0.4124939 1.695242e-03 7.284350e-03 5 Septin1 ENSMUSG00000000486 1.792568 2.3315912 8.820000e-12 1.600000e-10 6 Acvr1b ENSMUSG00000000532 1.094280 5.3096726 3.170000e-07 2.980000e-06 . | Next, check the resources of the inputs available to enrichGO. keytypes(org.Mm.eg.db) . &gt; keytypes(org.Mm.eg.db) [1] \"ACCNUM\" \"ALIAS\" \"ENSEMBL\" \"ENSEMBLPROT\" \"ENSEMBLTRANS\" \"ENTREZID\" \"ENZYME\" \"EVIDENCE\" [9] \"EVIDENCEALL\" \"GENENAME\" \"GENETYPE\" \"GO\" \"GOALL\" \"IPI\" \"MGI\" \"ONTOLOGY\" [17] \"ONTOLOGYALL\" \"PATH\" \"PFAM\" \"PMID\" \"PROSITE\" \"REFSEQ\" \"SYMBOL\" \"UNIPROT\" . | In this case, I can use the Symbol row and the ensembl_gene_id row as input from the UP object. This corresponds to SYMBOL and ENSEMBL in the keytype information (keytypes(org.Mm.eg.db)), which means that enrichGO supports both gene symbol and gene ID row as resource keytypes. For this example, I will use ENSEMBL as the keytype. | . 2. Run enrichGO and enrichKEGG . | Although a filter has been applied, the example output remains extensive due to the substantial number of genes under analysis. Therefore, in this section, I will focus on filtering only the osteogenic markers among the upregulated DEGs: data &lt;- read.csv(\"DEG.csv\", header = T) Filter_UP &lt;- data %&gt;% filter(logFC &gt;= 1, FDR &lt; 0.05, osteoMarker == \"Osteo\") . | Run enrichGO: ego &lt;- enrichGO(gene = Filter_UP$ensembl_gene_id, keyType = \"ENSEMBL\", OrgDb = org.Mm.eg.db, ont = \"BP\", pAdjustMethod = \"fdr\", qvalueCutoff = 0.05, readable = TRUE) # Save GO results write.csv(ego, \"GOenrich.csv\") . | in these codes, | . | . | gene = Filter_UP$ensembl_gene_id: Specifies the list of genes to analyze. In this case, it uses the ensembl_gene_id column from the Filter_UP dataframe. | keyType = \"ENSEMBL\": Defines the type of gene identifier. | OrgDb = org.Mm.eg.db: Specifies the gene annotation database. | ont = \"BP\": Specifies the type of GO terms to analyze. Possible terms are BP, MP, and CC. | pAdjustMethod = \"fdr\": Defines the method for p-value adjustment. Possible methods are holm, hochberg, hommel, bonferroni, BH, BY, fdr, none. | qvalueCutoff = 0.05: Specifies the cutoff for q-value. | readable = TRUE: If set to TRUE, converts gene IDs in the results to a more readable form (e.g., gene symbols). | . | Before running enrichKEGG, check the KEGG organism code: search_kegg_organism('Mus musculus', by='scientific_name') # 'Mus musculus' specifies your organism. | Output: &gt; search_kegg_organism('Mus musculus', by='scientific_name') kegg_code scientific_name common_name 30 mmu Mus musculus house mouse . | Run enrichKEGG: ekegg &lt;- enrichKEGG(gene = Filter_UP$ensembl_gene_id, keyType = \"ENSEMBL\", organism = \"mmu\", # This value (mmu) can be obtained from above 'search_kegg' code. pAdjustMethod = \"fdr\", qvalueCutoff = 0.05) # Save KEGG results write.csv(ekegg, \"KEGGenrich.csv\") . | . 3. Visualization . | The enrichplot package offers a variety of visualization methods for the GO and KEGG analyses obtained from the enrichGO and enrichKEGG results. In addition to enrichplot, bubble charts can be created using the ggplot2 package by selecting the desired GO/KEGG terms from the saved csv file (refer to the Depicting a Bubble Chart from GO Analysis Results section). In this section, I will present only some of the most frequently used features of enrichplot based on the GO results. | When using enrichGO and enrichKEGG consecutively and then visualizing the results, it is not necessary to load the data separately. Adjusting the graphical parameters is beyond the scope of this lesson. For further details, please refer to the enrichplot manual. | . 3-1. Bar plot: . barplot(ego, showCategory=15) barplot(ekegg, showCategory=10) . 3-2. Bubble chart: . dotplot(ego, showCategory=15) dotplot(ekegg, showCategory=10) . | Output (Left; Barplot, Right; Dotplot): (Clicking on the image will open it in a larger view.) . | . &times; &#10094; &#10095; | . 3-3. Gene-concept network: . geneList &lt;- setNames(Filter_UP$logFC, Filter_UP$ensembl_gene_id) ego2 &lt;- setReadable(ego, \"org.Mm.eg.db\", \"ENSEMBL\") p1 &lt;- cnetplot(ego2, color.params = list(foldChange = geneList), showCategory = 5) + scale_color_gradient(name = \"logFC\", low = \"blue\", high = \"red\") p2 &lt;- cnetplot(ego2, color.params = list(foldChange = geneList), circular = TRUE, colorEdge = TRUE, showCategory = 5) + scale_color_gradient(name = \"logFC\", low = \"blue\", high = \"red\") . | Output: (Clicking on the image will open it in a larger view.) . | . &times; &#10094; &#10095; | . 3-4. Heatmap-like functional classification: . p1 &lt;- heatplot(ego2, foldChange = geneList, showCategory = 5) p2 &lt;- p1 + scale_fill_gradient(name = \"logFC\", low = \"blue\", high = \"red\") + coord_fixed(ratio = 1) + guides(fill = guide_colorbar(barwidth = 0.8, barheight = 5)) . | Output: . | . 3-5. Tree plot . egoTree &lt;- pairwise_termsim(ego2) p1 &lt;- treeplot(egoTree, hclust_method = \"average\") . | Output: . | . 3-6. Gene Set Enrichment Analysis (GSEA) . Note . | GSEA is a computational method that determines if a predefined set of genes shows statistically significant differences between two biological states by comparing gene ranks within the set to those in the entire genome. | GSEA is crucial in RNA-seq analyses as it reveals differentially regulated biological pathways and processes, offering a comprehensive understanding beyond individual gene expression changes. | GSEA effectively analyzes the human transcriptome/genome using the Molecular Signatures Database and tools from the Broad Institute. In this section, I will provide code to plot GSEA correlation plot, and create a separate section and explain more about GSEA later. | . | Data selection: . data &lt;- read.csv(\"DEG.csv\") # Load raw DEG data obtained from edgeR result filtered_data &lt;- data %&gt;% filter(!(logFC &gt; 1 &amp; FDR &gt; 0.05) &amp; !(logFC &lt; -1 &amp; FDR &gt; 0.05)) . | Output: &gt; head(filtered_data) Symbol ensembl_gene_id logFC logCPM PValue FDR osteoMarker 1 Gnai3 ENSMUSG00000000001 -1.028899 7.5123714 7.94000e-07 6.96e-06 2 Cdc45 ENSMUSG00000000028 -2.245032 4.7831577 1.61000e-22 8.34e-21 3 Scml2 ENSMUSG00000000037 -1.842400 2.3288016 4.06000e-10 5.96e-09 4 Apoh ENSMUSG00000000049 -0.161434 -0.1108714 8.26452e-01 1.00e+00 5 Narf ENSMUSG00000000056 -1.124729 5.6864476 1.27000e-07 1.28e-06 6 Cav2 ENSMUSG00000000058 -1.028229 6.7405093 1.12000e-06 9.54e-06 . | Run GSEA: . # Make samll varience (based on normal distribution) to reduce ties in the preranked stats set.seed(42) filtered_data$logFC &lt;- filtered_data$logFC + rnorm(n = nrow(filtered_data), mean = 0, sd = 1e-5) # Make compare list geneList &lt;- setNames(filtered_data$logFC, filtered_data$ensembl_gene_id) geneList &lt;- sort(geneList, decreasing = TRUE) # Run GSEA gsea_results &lt;- gseGO(geneList = geneList, OrgDb = org.Mm.eg.db, ont = \"BP\", keyType = \"ENSEMBL\", pAdjustMethod = \"fdr\", pvalueCutoff = 0.25, eps = 0, verbose = FALSE) # Call GO terms from the GSEA results go_terms &lt;- gsea_results@result[, c(\"ID\", \"Description\", \"NES\", \"p.adjust\", \"qvalue\")] osteo_terms &lt;- go_terms[grep(\"osteoblast\", go_terms$Description, ignore.case = TRUE), ] . | Output: &gt; osteo_terms &lt;- go_terms[grep(\"osteoblast\", go_terms$Description, ignore.case = TRUE), ] &gt; osteo_terms ID Description NES p.adjust qvalue GO:0045667 GO:0045667 regulation of osteoblast differentiation -1.314391 0.2478609 0.2221023 . | Plotting: . # Make a correlation plot go_id &lt;- \"GO:0045667\" gseaplot2(gsea_results, geneSetID = go_id, title = paste(\"GSEA Plot for\", go_id)) # Make an information table nes &lt;- gsea_results@result$NES[gsea_results@result$ID == go_id] pvalue &lt;- gsea_results@result$pvalue[gsea_results@result$ID == go_id] padj &lt;- gsea_results@result$p.adjust[gsea_results@result$ID == go_id] lab &lt;- paste0(\"NES = \", round(nes, 4), \"\\nFDR = \", round(padj, 4)) ## The 'annotate' function is currently not operational; therefore, I will implement a workaround by overlaying the table on the plot. # Plot with the table grid.text(lab, x = unit(0.95, \"npc\"), y = unit(0.95, \"npc\"), just = c(\"right\", \"top\"), gp = gpar(col = \"black\", fontsize = 15)) . | Output: . | . ",
    "url": "/docs/RNASeq/GO_KEGG_MANUAL/#step-by-step-enrichgo-guide",
    
    "relUrl": "/docs/RNASeq/GO_KEGG_MANUAL/#step-by-step-enrichgo-guide"
  },"60": {
    "doc": "DEG - Gene ontology and KEGG pathway analysis",
    "title": "Citations",
    "content": "GO analysis . | Huang, D. W., Sherman, B. T., Tan, Q., Kir, J., Liu, D., Bryant, D., ... &amp; Lempicki, R. A. (2007). DAVID Bioinformatics Resources: expanded annotation database and novel algorithms to better extract biology from large gene lists. Nucleic acids research, 35(suppl_2), W169-W175. DOI | Gene Ontology Consortium. (2001). Creating the gene ontology resource: design and implementation. Genome research, 11(8), 1425-1433. DOI | . enrichGO/GSEA . | Yu, G., Wang, L. G., Han, Y., &amp; He, Q. Y. (2012). clusterProfiler: an R package for comparing biological themes among gene clusters. Omics: a journal of integrative biology, 16(5), 284-287. DOI | Subramanian, A., Tamayo, P., Mootha, V. K., Mukherjee, S., Ebert, B. L., Gillette, M. A., ... &amp; Mesirov, J. P. (2005). Gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles. Proceedings of the National Academy of Sciences*, 102(43), 15545-15550. DOI&lt;/span&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/div&gt; | . ",
    "url": "/docs/RNASeq/GO_KEGG_MANUAL/#citations",
    
    "relUrl": "/docs/RNASeq/GO_KEGG_MANUAL/#citations"
  },"61": {
    "doc": "DEG - Gene ontology and KEGG pathway analysis",
    "title": "DEG - Gene ontology and KEGG pathway analysis",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/RNASeq/GO_KEGG_MANUAL/",
    
    "relUrl": "/docs/RNASeq/GO_KEGG_MANUAL/"
  },"62": {
    "doc": "File storage with Genozip",
    "title": "Genozip: a lossless Compressor for Sequencing Data",
    "content": "Genozip is a powerful tool specifically designed for the compression of life sciences data. It excels in efficiently handling and optimizing storage space for large genomic sequence data files. Genozip delivers high compression ratios and speeds, simplifying the transfer and storage of large and complex datasets. Additionally, it supports users in managing their data more quickly and economically, facilitating research and data analysis. While Genozip is a commercial product, it is available for free for academic use, ensuring accessibility for research purposes. This protocol was created based on Genozip version 13.0.16 running on a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes Python version 3.8.5 and conda version 22.9.0 under macOS 12.4 environment. Disclaimer: I have not assume any responsibility for problems that may arise due to the copyright restrictions of Genozip, which is provided free of charge for academic use only. Users are encouraged to ensure compliance with all applicable terms and conditions. License . ",
    "url": "/docs/DataProcess/Genozip_MANUAL/#genozip-a-lossless-compressor-for-sequencing-data",
    
    "relUrl": "/docs/DataProcess/Genozip_MANUAL/#genozip-a-lossless-compressor-for-sequencing-data"
  },"63": {
    "doc": "File storage with Genozip",
    "title": "Compression Commands by File Type Guide",
    "content": ". To install Genozip, use the following Conda commands to add the necessary channel and install the software: . $ conda config --add channels conda-forge $ conda install genozip . ",
    "url": "/docs/DataProcess/Genozip_MANUAL/#compression-commands-by-file-type-guide",
    
    "relUrl": "/docs/DataProcess/Genozip_MANUAL/#compression-commands-by-file-type-guide"
  },"64": {
    "doc": "File storage with Genozip",
    "title": "Step-by-Step Guide by File Extension",
    "content": "All output is generated in the form of .genozip. ",
    "url": "/docs/DataProcess/Genozip_MANUAL/#step-by-step-guide-by-file-extension",
    
    "relUrl": "/docs/DataProcess/Genozip_MANUAL/#step-by-step-guide-by-file-extension"
  },"65": {
    "doc": "File storage with Genozip",
    "title": "1. FASTQ Files",
    "content": "FASTQ files are typically provided in gzipped format, which already offers an efficient compression ratio. Since these files represent the raw sequence data commonly published on ENA (European Nucleotide Archive) or GEO (Gene Expression Omnibus), it is essential to maintain their integrity. Therefore, to ensure the preservation of the original data quality and integrity, it is advisable to continue using gzip compression for FASTQ files rather than switching to Genozip. Gzip not only provides satisfactory compression but also guarantees that the data remains in a widely recognized and compatible format for these databases. ",
    "url": "/docs/DataProcess/Genozip_MANUAL/#1-fastq-files",
    
    "relUrl": "/docs/DataProcess/Genozip_MANUAL/#1-fastq-files"
  },"66": {
    "doc": "File storage with Genozip",
    "title": "2. Trimmomatic FASTQ Files",
    "content": "Trimmomatic processing results in paired and unpaired forward/reverse FASTQ files. For transcriptome analysis focusing on differential gene expression, it is practical to compress only the paired sets. | Prepare Reference Genome: First, create a reference genome for efficient compression: # Guide $ genozip --make-reference &lt;referenceGenome.fa.gz&gt; # For example $ genozip --make-reference GRCh38.primary_assembly.genome.fa.gz . | . Reference genome can be downloaded from GENCODE or Ensembl as annotation fasta databases. | Compress Paired FASTQ Sets: Use the following commands to compress paired FASTQ files: # Guide $ genozip --reference &lt;reference_.genozip&gt; --pair &lt;pair1.fq.gz&gt; &lt;pair2.fq.gz&gt; # For exmaple $ genozip --reference GRCh38.primary_assembly.genome.ref.genozip --pair Trim_shCon_H2O2_1.fq.gz Trim_shCon_H2O2_2.fq.gz $ genozip --reference GRCh38.primary_assembly.genome.ref.genozip --pair Trim_shCon_NP_1.fq.gz Trim_shCon_NP_2.fq.gz $ genozip --reference GRCh38.primary_assembly.genome.ref.genozip --pair Trim_shCon_Unt_1.fq.gz Trim_shCon_Unt_2.fq.gz . | Storage: Move the resulting .genozip files to an external HDD. | . ",
    "url": "/docs/DataProcess/Genozip_MANUAL/#2-trimmomatic-fastq-files",
    
    "relUrl": "/docs/DataProcess/Genozip_MANUAL/#2-trimmomatic-fastq-files"
  },"67": {
    "doc": "File storage with Genozip",
    "title": "3. SAM Files",
    "content": "The resulting SAM files from sequencing mapping can be prohibitively large, often presenting substantial challenges in terms of storage and handling. Genozip addresses this issue adeptly, providing an effective compression solution that significantly reduces the size of SAM files. By utilizing Genozip, researchers can achieve a more manageable file size, enhancing the efficiency of data storage and transfer processes. This compression capability ensures that extensive genomic data can be stored more economically and accessed more readily. | Compress SAM files using the following command and then transfer the .genozip files to an external HDD: # Guide $ genozip &lt;input_samfile.sam&gt; # For exmaple $ genozip shCon_H2O2.sam $ genozip shCon_NP.sam $ genozip shCon_Unt.sam . | . ",
    "url": "/docs/DataProcess/Genozip_MANUAL/#3-sam-files",
    
    "relUrl": "/docs/DataProcess/Genozip_MANUAL/#3-sam-files"
  },"68": {
    "doc": "File storage with Genozip",
    "title": "4. BAM Files",
    "content": "BAM files, while being compressed forms of SAM files, still possess considerable size. The complexity and size of BAM files further increase as they undergo various processing stages of the samtools such as view, rmdup, and sort, which generate multiple individual files. Although compressing BAM files using Genozip alone might not yield optimal efficiency, combining Genozip compression with tar archiving significantly reduces the overall file size. This method effectively decreases the storage footprint, thereby enhancing the manageability of genomic data. | Compress SAM files using the following command and then transfer the .genozip files to an external HDD: . # Guide $ genozip --tar &lt;output.tar&gt; &lt;input1.bam&gt; &lt;input2.bam&gt; ... &lt;inputN.bam&gt; # For example $ genozip --tar viewBAM.tar shCon_D0.bam shCon_D7.bam shNFIB_D0.bam shNFIB_D7.bam shMLL1_D0.bam shMLL1_D7.bam $ genozip --tar rmdupBAM.tar rmdup.shCon_D0.bam rmdup.shNFIB_D0.bam rmdup.shMLL1_D0.bam rmdup.shCon_D7.bam rmdup.shNFIB_D7.bam rmdup.shMLL1_D7.bam . | . ",
    "url": "/docs/DataProcess/Genozip_MANUAL/#4-bam-files",
    
    "relUrl": "/docs/DataProcess/Genozip_MANUAL/#4-bam-files"
  },"69": {
    "doc": "File storage with Genozip",
    "title": "File storage with Genozip",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/DataProcess/Genozip_MANUAL/",
    
    "relUrl": "/docs/DataProcess/Genozip_MANUAL/"
  },"70": {
    "doc": "DEG - Heatmap",
    "title": "Essential Tools for Heatmap Visualization in Sequencing Data: pheatmap and ComplexHeatmap",
    "content": "In the analysis of sequencing data, drawing heatmaps is crucial for visualizing complex information in a comprehensible manner, allowing researchers to detect patterns, correlations, and outliers within large datasets. Heatmaps represent matrix data where individual values contained in a matrix are represented as colors, facilitating the quick absorption of insights about the underlying biological processes. Among the tools available for this purpose in R, the pheatmap and ComplexHeatmap packages are particularly noteworthy. The pheatmap package provides a simple and highly customizable interface for generating heatmaps, offering features such as clustering, annotation, and adjustments to color scales. On the other hand, ComplexHeatmap extends these functionalities by enabling the integration of multiple heatmaps, adding complex annotations, and supporting the arrangement of heatmaps and other graphical elements in a highly flexible manner. This protocol was developed using a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes R version 4.4.0 running on macOS 14.4.1. ",
    "url": "/docs/RNASeq/HEATMAP_MANUAL/#essential-tools-for-heatmap-visualization-in-sequencing-data-pheatmap-and-complexheatmap",
    
    "relUrl": "/docs/RNASeq/HEATMAP_MANUAL/#essential-tools-for-heatmap-visualization-in-sequencing-data-pheatmap-and-complexheatmap"
  },"71": {
    "doc": "DEG - Heatmap",
    "title": "pheatmap versus ComplexHeatmap",
    "content": "The packages pheatmap and complexheatmap are both apt for the generation of heatmaps, albeit with distinct differences. Refer to the following table, which outlines the respective advantages and disadvantages of each package, and select the corresponding manuals for further guidance. Additionally, unlike other plotting tutorials (Volcano, scatter, correlation, and buble chart), this guide incorporates complex parameters and fundamental logical functions of R, necessitating a foundational understanding of the R programming language. Specifically, the complexheatmap package is designed for users with an intermediate level of expertise. | Aspect | pheatmap | ComplexHeatmap | . | Ease of Use | More effective for beginners and quick implementations | Less straightforward initially, better for experienced users | . | Customization and Flexibility | Limited in customization, suitable for basic heatmaps | Highly customizable, ideal for detailed visualizations | . | Integration with Other Data Types and Visuals | Less effective for complex data integration | Highly effective for integrating multiple data types and visuals | . | Performance and Scalability | Good for smaller datasets and simpler analyses | Superior for large datasets and complex analyses | . ",
    "url": "/docs/RNASeq/HEATMAP_MANUAL/#pheatmap-versus-complexheatmap",
    
    "relUrl": "/docs/RNASeq/HEATMAP_MANUAL/#pheatmap-versus-complexheatmap"
  },"72": {
    "doc": "DEG - Heatmap",
    "title": "pheatmap",
    "content": ". In this section, the user is introduced to the techniques for visualizing basic RNA-seq data through heatmaps, using the pheatmap package. The dataset featured originates from CPM values, which were collected following RNA-seq assays on duplicate samples of both wild-type rice and genetically modified rice with certain genes knockouted. Please be advised that the pheatmap package supports only fundamental heatmap visualization. For an in-depth examination of advanced features, one is directed to consult the section dedicated to the complexheatmap package, which follows. Required Packages: . library(pheatmap) library(RColorBrewer) library(viridis) library(viridisLite) . ",
    "url": "/docs/RNASeq/HEATMAP_MANUAL/#pheatmap",
    
    "relUrl": "/docs/RNASeq/HEATMAP_MANUAL/#pheatmap"
  },"73": {
    "doc": "DEG - Heatmap",
    "title": "Step-by-Step pheatmap Guide",
    "content": "1. Load CPM Data and Prepare Data Frame . Load your data. In this guide, I will load CPM data without using row.names = 1, but this is optional: . data &lt;- read.csv(\"heatmap.csv\", header = T) . | This dataset is organized as follows: &gt; head(data) MSU WT_rep1 WT_rep2 KO_rep1 KO_Rep2 Cluster 1 LOC_Os02g57000 6.475709 6.216468 -3.0875734 -3.3857658 cluster1 2 LOC_Os02g33740 5.597263 5.432519 -2.3418637 -3.0058172 cluster1 3 LOC_Os03g59300 6.656864 6.558811 0.3320713 0.3533387 cluster1 4 LOC_Os01g21580 4.679595 4.487096 -2.7940856 -2.7053595 cluster1 5 LOC_Os02g03640 4.724022 4.939755 -2.1597539 -1.8963395 cluster1 6 LOC_Os09g29050 5.663938 5.379374 -0.4579156 -0.2427508 cluster1 . Select the values in the data that will be analyzed and specify their row names as gene numbers (data$MSU): . rownames(data) &lt;- data$MSU expression_data &lt;- data[, 2:5] . | The data frame of expression_data is organized as follows: &gt; head(expression_data) WT_rep1 WT_rep2 KO_rep1 KO_Rep2 LOC_Os02g57000 6.475709 6.216468 -3.0875734 -3.3857658 LOC_Os02g33740 5.597263 5.432519 -2.3418637 -3.0058172 LOC_Os03g59300 6.656864 6.558811 0.3320713 0.3533387 LOC_Os01g21580 4.679595 4.487096 -2.7940856 -2.7053595 LOC_Os02g03640 4.724022 4.939755 -2.1597539 -1.8963395 LOC_Os09g29050 5.663938 5.379374 -0.4579156 -0.2427508 . | . 2. Create Annotation Frames for Rows and Columns . The rows of the dataset are divided by the Cluster of data and the columns are divided by the head of the data to create the annotation: . # For row annotation &lt;- data.frame(Cluster = factor(data$Cluster)) rownames(annotation) &lt;- rownames(data) #For column annotation_col &lt;- data.frame(Type = factor(c(\"WT\", \"WT\", \"KO\", \"KO\"))) rownames(annotation_col) &lt;- colnames(expression_data) . | The structure of the annotation and annotation_col data frames is shown below: &gt; head(annotation) Cluster LOC_Os02g57000 cluster1 LOC_Os02g33740 cluster1 LOC_Os03g59300 cluster1 LOC_Os01g21580 cluster1 LOC_Os02g03640 cluster1 LOC_Os09g29050 cluster1 &gt; annotation_col Type WT_rep1 WT WT_rep2 WT KO_rep1 KO KO_Rep2 KO . | . 3. Prepare Color Palette for the Heatmap . Choose a color scheme for your heatmap visualization. This can be done by specifying either the name or hex codes of colors: . myCol &lt;- colorRampPalette(c('dodgerblue', 'black', 'yellow'))(100) . | The number 100 represents the granularity of the heatmap, affecting the differentiation between data points. More colors provide finer distinctions, helpful for detailed data visualization, whereas fewer colors might emphasize broader trends. | . If you need a broader range of color palettes, the RColorBrewer package offers a variety of user-favorite choices: . myCol &lt;- colorRampPalette(brewer.pal(11, \"RdYlBu\"))(100) myCol_reverse &lt;- colorRampPalette(rev(brewer.pal(11, \"RdYlBu\")))(100) . | In these codes, \"RdYlBu\" indicates a specific color palette, the number 11 specifically refers to the number of different colors that you want to extract from the “RdYlBu” palette provided by the RColorBrewer package. The number of 100 means the granularity in the heatmap. The rev argument is used to reverse the color order. The available color codes and numbers are shown below image. | . The viridis package is also a good one that provides a palette for color selection. myCol &lt;- viridis::viridis(100, option = \"magma\") myCol_magma_rev &lt;- viridis::viridis(100, option = \"magma\", direction = -1) . The following images display the available color palettes from Viridis: . 4. Plotting . myCol &lt;- viridis::viridis(100, option = \"viridis\") pheatmap_result &lt;- pheatmap(expression_data, annotation_row = annotation, annotation_col = annotation_col, cluster_rows = TRUE, cluster_cols = FALSE, show_rownames = FALSE, show_colnames = TRUE, scale = \"row\", color = myCol, clustering_distance_rows = \"euclidean\", clustering_method = \"average\", cellheight = 0.06, cellwidth = 30) . Important: Typically, heatmap data is normalized and presented as a z-score to ensure comparability across data points. In the provided example, normalization is achieved by computing a z-score with the scale = \"row\" option directly in the heatmap function, thus eliminating the need for using the t(scale(t())) function. | These codes utilize Euclidean distance for clustering and employs the average algorithm. | To modify the clustering distance, add the clustering_distance_rows = \"&lt;distance&gt;\" parameter. Available distance metrics include euclidean, maximum, manhattan, canberra, and binary. | Additionally, to change the clustering algorithm, adjust the clustering_method = \"&lt;algorithm&gt;\" parameter. Possible algorithms are single (minimum linkage), complete (maximum linkage), average (UPGMA), ward.D (Ward’s minimum variance method), ward.D2 (Modified Ward’s method), mcquitty (McQuitty’s method, WPGMA), median (Median linkage, WPGMC), and centroid (Centroid linkage, UPGMC). | If you want to adjust the range of the heatmap, you can do so using the breaks argument: my_breaks &lt;- seq(-1, 1, length.out = length(myCol) + 1) # Set the breaks pheatmap_result_Rev &lt;- pheatmap(expression_data, annotation_row = annotation, annotation_col = annotation_col, cluster_rows = TRUE, cluster_cols = FALSE, show_rownames = FALSE, show_colnames = TRUE, scale = \"row\", color = myCol, breaks = my_breaks, clustering_distance_rows = \"euclidean\", clustering_method = \"average\", cellheight = 0.06, cellwidth = 30) . | You can also output a list of genes in clustering order: clustered_gene_order &lt;- rownames(expression_data)[pheatmap_result$tree_row$order] clustered_genes_with_clusters &lt;- data.frame( Gene = clustered_gene_order, OriginalCluster = annotation[clustered_gene_order, \"Cluster\"] ) # Save the list as a csv format write.csv(clustered_genes_with_clusters, file = \"clustered_genes_with_clusters.csv\", row.names = FALSE, quote = FALSE) . | . 5. (Optional) Represent Specific Gene Symbols in the Heatmap . Although this functionality is not fully implemented in the current setup, it is recommended to use the ComplexHeatmap package for a robust implementation of this featur . # Specify the genes whose names you want to be displayed selected_genes &lt;- c(\"LOC_Os06g49240\", \"LOC_Os01g49710\", \"LOC_Os10g03220\", \"LOC_Os04g41680\") labels_row &lt;- ifelse(rownames(expression_data) %in% selected_genes, rownames(expression_data), \"\") # Plotting pheatmap_result_Name &lt;- pheatmap(expression_data, annotation_row = annotation, annotation_col = annotation_col, cluster_rows = TRUE, cluster_cols = FALSE, show_rownames = TRUE, show_colnames = TRUE, labels_row = labels_row, scale = \"row\", color = myCol, breaks = my_breaks, clustering_distance_rows = \"euclidean\", clustering_method = \"average\", cellheight = 0.06, cellwidth = 30) . | Output (Left; Step 4, Right; Step 5): (Clicking on the image will open it in a larger view.) | . | . &times; &#10094; &#10095; Enter your code: Copy Clear ",
    "url": "/docs/RNASeq/HEATMAP_MANUAL/#step-by-step-pheatmap-guide",
    
    "relUrl": "/docs/RNASeq/HEATMAP_MANUAL/#step-by-step-pheatmap-guide"
  },"74": {
    "doc": "DEG - Heatmap",
    "title": "CompexHeatmap",
    "content": ". In this section, the complexheatmap package will be elucidated through the analysis of three distinct case studies. Initially, data from a heatmap generated using the ‘pheatmap’ package will be implemented employing the ‘complexheatmap’ package. Subsequently, the integration of RNA-seq and ChIP-seq data will be demonstrated, utilizing the data integration parameters that constitute a principal feature of this package. Lastly, the process for integrating various RNA-seq datasets will be discussed. Required Packages: . library(ComplexHeatmap) library(circlize) library(grid) library(RColorBrewer) library(viridis) library(viridisLite) . | If you do not possess specialized knowledge, the use of the ht_opt function in the Complexheatmap may not be advisable. It is important to note that this function’s settings depend permanently on the previously saved value, even after re-invoking the library. If a reset is necessary, please utilize the command provided below. ht_opt(Reset = TRUE) print(ht_opt) # Check . | . ",
    "url": "/docs/RNASeq/HEATMAP_MANUAL/#compexheatmap",
    
    "relUrl": "/docs/RNASeq/HEATMAP_MANUAL/#compexheatmap"
  },"75": {
    "doc": "DEG - Heatmap",
    "title": "Step-by-Step Guide: Case I - RNA-seq Heatmap",
    "content": "In this case, I will visualize the CPM values of wild-type rice and rice with a specific gene has been knocked out, through the application of biological replicates. The data were subjected to DEG analysis using edgeR. Additionally, I have generated a Cluster row labeled cluster1 for genes that are upregulated and cluster2 for genes that are downregulated. 1. Load Data and Normalize with z-score . # Load data without the 'row.names' option data &lt;- read.csv(\"heatmap.csv\", header = T) # Specify the range of the data to be analyzed expression_data &lt;- as.matrix(data[, 2:5]) # Normalize to z-score z_score &lt;- t(scale(t(expression_data))) z_min &lt;- min(z_score) z_max &lt;- max(z_score) rownames(z_score) &lt;- data$MSU . | Output: &gt; head(data) MSU WT_rep1 WT_rep2 KO_rep1 KO_Rep2 Cluster 1 LOC_Os02g57000 6.475709 6.216468 -3.0875734 -3.3857658 cluster1 2 LOC_Os02g33740 5.597263 5.432519 -2.3418637 -3.0058172 cluster1 3 LOC_Os03g59300 6.656864 6.558811 0.3320713 0.3533387 cluster1 4 LOC_Os01g21580 4.679595 4.487096 -2.7940856 -2.7053595 cluster1 5 LOC_Os02g03640 4.724022 4.939755 -2.1597539 -1.8963395 cluster1 6 LOC_Os09g29050 5.663938 5.379374 -0.4579156 -0.2427508 cluster1 &gt; head(z_score) WT_rep1 WT_rep2 KO_rep1 KO_Rep2 LOC_Os02g57000 0.8890761 0.8422390 -0.8387204 -0.8925947 LOC_Os02g33740 0.8819111 0.8471257 -0.7944220 -0.9346147 LOC_Os03g59300 0.8795228 0.8524170 -0.8689095 -0.8630303 LOC_Os01g21580 0.8885737 0.8431155 -0.8763208 -0.8553683 LOC_Os02g03640 0.8382743 0.8927108 -0.8987265 -0.8322585 LOC_Os09g29050 0.9071574 0.8232973 -0.8969315 -0.8335232 . | . 2. Prepare Cluster Annotations . # Create a factor for the cluster data and setup the annotation dataframe cluster_factor &lt;- factor(data$Cluster) annotation &lt;- data.frame(Cluster = cluster_factor) rownames(annotation) &lt;- data$MSU # Define a color palette set2_palette &lt;- brewer.pal(8, \"Set2\") # Create row annotations row_anno &lt;- rowAnnotation( df = annotation, col = list(Cluster = setNames(c(set2_palette[2], set2_palette[1]), levels(cluster_factor))), annotation_name_side = \"top\", simple_anno_size = unit(3, \"mm\") ) # Create column annotations col_anno &lt;- HeatmapAnnotation( Type = factor(c(\"WT\", \"WT\", \"KO\", \"KO\")), col = list(Type = c(WT = set2_palette[3], KO = set2_palette[4])), show_annotation_name = FALSE, simple_anno_size = unit(3, \"mm\") ) . | Output: &gt; row_anno A HeatmapAnnotation object with 1 annotation name: heatmap_annotation_0 position: row items: 5981 width: 3mm height: 1npc this object is subsettable 14.4069666666667mm extension on the top name annotation_type color_mapping width Cluster discrete vector user-defined 3mm &gt; col_anno A HeatmapAnnotation object with 1 annotation name: heatmap_annotation_1 position: column items: 4 width: 1npc height: 3mm this object is subsettable name annotation_type color_mapping height Type discrete vector user-defined 3mm . | . 3. Plotting . main_heatmap &lt;- Heatmap( z_score, name = \"Expression Data\", col = colorRamp2(c(z_min, 0, z_max), c('dodgerblue', 'black', 'yellow')), show_row_names = FALSE, show_column_names = TRUE, column_title = \"Expression Data\", clustering_method_rows = \"average\", cluster_columns = FALSE, column_names_side = \"top\", column_split = factor(c(\"WT\", \"WT\", \"KO\", \"KO\")), top_annotation = col_anno, split = cluster_factor, row_title = NULL, left_annotation = row_anno, width = unit(5, \"cm\"), height = unit(12, \"cm\") ) draw(main_heatmap) . | These codes utilize Euclidean distance for clustering and employs the complete algorithm (Default). | To modify the clustering distance, add the clustering_distance_rows = \"&lt;distance&gt;\" parameter. Available distance metrics include euclidean, maximum, manhattan, canberra, and binary. | Additionally, to change the clustering algorithm, adjust the clustering_method_rows = \"&lt;algorithm&gt;\" parameter. Possible algorithms are single (minimum linkage), complete (maximum linkage), average (UPGMA), ward.D (Ward’s minimum variance method), ward.D2 (Modified Ward’s method), mcquitty (McQuitty’s method, WPGMA), median (Median linkage, WPGMC), and centroid (Centroid linkage, UPGMC). | . 4. (Optional) Represent specific gene symbols in the heatmap . # Specify the genes whose names you want to be displayed selected_genes &lt;- c(\"LOC_Os06g49240\", \"LOC_Os01g49710\", \"LOC_Os10g03220\", \"LOC_Os04g41680\") row_indices &lt;- which(data$MSU %in% selected_genes) # Plotting main_heatmap2 &lt;- main_heatmap + rowAnnotation( foo = anno_mark( at = row_indices, labels = data$MSU[row_indices], which = \"row\", labels_gp = gpar(fontsize = 8)) ) # Save draw(main_heatmap2, merge_legends = TRUE, gap = unit(0, \"mm\")) . | Output (Left; Step 3, Right; Step 4): (Clicking on the image will open it in a larger view.) | . | . &times; &#10094; &#10095; Enter your code: Copy Clear ",
    "url": "/docs/RNASeq/HEATMAP_MANUAL/#step-by-step-guide-case-i---rna-seq-heatmap",
    
    "relUrl": "/docs/RNASeq/HEATMAP_MANUAL/#step-by-step-guide-case-i---rna-seq-heatmap"
  },"76": {
    "doc": "DEG - Heatmap",
    "title": "Step-by-Step Guide: Case II - Integration of RNA-seq with Simpler Structured Dataset",
    "content": "In this dataset, genes that respond to stress in human keratinocytes and three derived knockdown cell types are categorized by their fold change values, using normal cell expression levels as a baseline. Then, these genes were manually grouped into four categories (Clusterrow) based on their expression patterns. Additionally, genes associated with ROS are enumerated in a separate row (ROS.hallmark) and identified as ROS. Moreover, the presence of MLL1, H3K4me3, UTX, and H3K27me3 peaks, as detected in normal cells under stress conditions from ChIP-seq results, is indicated by 0 (NO) and 1 (Yes) values. 1. Normalize data and prepare matrix/annotation . # Load data data &lt;- read.csv(\"ROS_heatmap.csv\", header = T) # Matrix the data as main heatmap and Normalize to Z-score. expression_data &lt;- as.matrix(data[, 2:5]) z_score &lt;- t(scale(t(expression_data))) z_min &lt;- min(z_score) z_max &lt;- max(z_score) # Create the annotation dataframe and set annotation cluster_factor &lt;- factor(data$Cluster) annotation &lt;- data.frame(Cluster = cluster_factor) rownames(annotation) &lt;- rownames(data) set2_palette &lt;- brewer.pal(8, \"Set2\") row_anno &lt;- rowAnnotation( df = annotation, col = list(Cluster = setNames(c(set2_palette[4], set2_palette[3], set2_palette[2], set2_palette[1]), levels(cluster_factor))), annotation_name_side = \"top\", simple_anno_size = unit(3, \"mm\") ) . | This dataset used in this case is organized as follows: &gt; head(data) SYMBOL shControl shNRF2 shMLL1 shUTX Cluster ROS.hallmark MLL1 H3K4 UTX H3K27 1 HHATL 1.191316 1.473315 -3.0637972 0.1852907 cluster2 0 0 0 0 2 AHR 1.478816 1.352787 -3.0637972 0.0000000 cluster2 1 0 0 0 3 NQO1 3.706885 1.283004 0.0000000 -1.2765334 cluster2 ROS 0 1 0 0 4 SSPN 1.076450 1.185496 -0.3337084 -3.2310447 cluster2 0 0 0 0 5 G6PC1 1.386497 2.442824 -0.1576905 -0.1286908 cluster2 0 0 0 1 6 PPP6R2 4.561280 4.742004 -0.1064526 3.1118796 cluster2 0 0 0 0 . | Next, matrix the dataset (ChIP-seq) that will be used as the secondary heatmap. mll1_data &lt;- matrix(data$MLL1, ncol=1, dimnames = list(rownames(data), \"MLL1\")) h3k4_data &lt;- matrix(data$H3K4, ncol=1, dimnames = list(rownames(data), \"H3K4\")) utx_data &lt;- matrix(data$UTX, ncol=1, dimnames = list(rownames(data), \"UTX\")) h3k27_data &lt;- matrix(data$H3K27, ncol=1, dimnames = list(rownames(data), \"H3K27\")) . | . 2. Plotting . | Create color palettes for the secondary heatmap. oranges_palette &lt;- c(\"white\", brewer.pal(9, \"Oranges\")) reds_palette &lt;- c(\"white\", brewer.pal(9, \"Reds\")) greens_palette &lt;- c(\"white\", brewer.pal(9, \"Greens\")) purples_palette &lt;- c(\"white\", brewer.pal(9, \"Purples\")) . | Draw the secondary heatmap. mll1_heatmap &lt;- Heatmap(mll1_data, col = colorRamp2(c(0, 1), c(\"white\", oranges_palette[5])), name = \"MLL1\", cluster_columns = FALSE, show_row_names = FALSE, show_column_names = TRUE, column_names_side = \"top\", width = unit(0.5, \"cm\")) h3k4_heatmap &lt;- Heatmap(h3k4_data, col = colorRamp2(c(0, 1), c(\"white\", reds_palette[9])), name = \"H3K4\", cluster_columns = FALSE, show_row_names = FALSE, show_column_names = TRUE, column_names_side = \"top\", width = unit(0.5, \"cm\")) utx_heatmap &lt;- Heatmap(utx_data, col = colorRamp2(c(0, 1), c(\"white\", greens_palette[9])), name = \"UTX\", cluster_columns = FALSE, show_row_names = FALSE, show_column_names = TRUE, column_names_side = \"top\", width = unit(0.5, \"cm\")) h3k27_heatmap &lt;- Heatmap(h3k27_data, col = colorRamp2(c(0, 1), c(\"white\", purples_palette[8])), name = \"H3K27\", cluster_columns = FALSE, show_row_names = FALSE, show_column_names = TRUE, column_names_side = \"top\", width = unit(0.5, \"cm\")) . | Draw a main heatmap. main_heatmap &lt;- Heatmap(z_score, name = \"Expression Data\", col = colorRamp2(c(z_min, 0, z_max), c('dodgerblue', 'black', 'yellow')), show_row_names = TRUE, show_column_names = TRUE, column_title = \"Expression Data\", cluster_columns = FALSE, column_names_side = \"top\", split = cluster_factor, row_title = NULL, left_annotation = row_anno, width = unit(5, \"cm\"), height = unit(12, \"cm\")) . | Combine the main heatmap with the secondary heatmap. heatmap_list &lt;- main_heatmap + mll1_heatmap + h3k4_heatmap + utx_heatmap + h3k27_heatmap # Draw without margin draw(heatmap_list, merge_legends = TRUE, gap = unit(0, \"mm\")) . | . Enter your code: Copy Clear 3. (Optional) Showing specific gene symbols from a large list in a heatmap . If the ROS.hallmark row is marked ROS, display the corresponding value from the SYMBOL row and annotate it accordingly: . # Specify ROS markers ros_indices &lt;- which(data$ROS.hallmark == \"ROS\") # Reflect these markers on the last heatmap among the secondary heatmaps h3k27_heatmap_Rev &lt;- h3k27_heatmap + rowAnnotation( foo = anno_mark( at = ros_indices, labels = data$SYMBOL[ros_indices], which = \"row\", labels_gp = gpar(fontsize = 8)) ) # Simple version h3k27_heatmap_Rev = h3k27_heatmap + rowAnnotation( foo = anno_mark( at = ros_indices, labels = data$SYMBOL[ros_indices], which = \"row\") ) # Advanced version h3k27_heatmap_Rev &lt;- h3k27_heatmap + rowAnnotation( foo = anno_mark( at = ros_indices, labels = data$SYMBOL[ros_indices], which = \"row\", labels_gp = gpar(fontsize = 8), padding = unit(0.5, \"cm\") ), width = unit(5.0, 'cm') + max_text_width(ros_indices, gp = gpar(fontsize = 8)) ) . I typically apply these markers to the auxiliary heatmap rather than the primary one, and their inclusion is not obligatory. Please designate these markers accordingly and subsequently integrate your heatmaps: . # Combine heatmap_final &lt;- main_heatmap + mll1_heatmap + h3k4_heatmap + utx_heatmap + h3k27_heatmap_Rev # Draw draw(heatmap_final, merge_legends = TRUE, gap = unit(0, \"mm\")) . | Output (Left; Step 2, Right; Step 3): (Clicking on the image will open it in a larger view.) | . | . &times; &#10094; &#10095; Enter your code: Copy Clear ",
    "url": "/docs/RNASeq/HEATMAP_MANUAL/#step-by-step-guide-case-ii---integration-of-rna-seq-with-simpler-structured-dataset",
    
    "relUrl": "/docs/RNASeq/HEATMAP_MANUAL/#step-by-step-guide-case-ii---integration-of-rna-seq-with-simpler-structured-dataset"
  },"77": {
    "doc": "DEG - Heatmap",
    "title": "Step-by-Step Guide: Case III - Multiple RNA-seq Combined with ChIP-seq",
    "content": "This example involves big data set derived from mouse mesenchymal stem cells (MSCs) and three different knockdown cell lines following their differentiation into osteoblasts and adipocytes, respectively. The primary data set comprises RNA-seq results from these cell lines undergone each differential stimuli. Additionally, as secondary data, ChIP-seq results are utilized for the genome-wide identification of alterations in the occupancy and enrichment of NFIB and H3K4me3 following the induction of bone differentiation in intact MSCs. Lastly, I present a heatmap to show whether the list of genes analyzed are transcription factors and regulators of each differentiation process. 1. Normalize data and prepare matrix/annotation . | Load data: data &lt;- read.csv(\"ComplexSeq.csv\", header = T) . | This dataset used in this case is organized as follows: &gt; head(data) Symbol O_Con O_NFIB O_MLL1 A_Con A_NFIB A_MLL1 NFIB H3K4me3 TF Adipo Osteo Cluster 1 1500009L16Rik 1.7141525 1.650957 -8.2522356 5.884279 -2.097777 -5.0292486 2.296628 1.787946 0 0 0 cluster2 2 A530016L24Rik 0.7738813 1.030212 -0.5199491 4.063868 -3.585915 -1.7736988 1.149132 1.370758 0 0 0 cluster3 3 Abca1 1.8617470 6.888385 0.5757785 3.776418 -2.151568 -1.5198181 2.175035 1.841612 0 0 0 cluster3 4 Abhd15 1.4146485 -0.256023 -0.3941591 3.219146 -3.508747 -3.6085345 2.350038 0.000000 0 0 0 cluster3 5 Acacb 2.4237469 2.502078 -1.0830766 2.121201 -1.460384 -0.6849265 1.762528 0.000000 0 0 0 cluster1 6 Acadm 0.7387791 6.690138 -0.1115445 1.582898 -1.675392 -1.2446482 1.935325 1.584191 0 0 0 cluster3 . | Create and normalize data frames by experiment type and sample type: # For RNA-seq RNA_data &lt;- as.matrix(data[, 2:7]) RNA_z_score &lt;- t(scale(t(RNA_data))) rownames(RNA_z_score) &lt;- rownames(data) Osteo &lt;- as.matrix(RNA_z_score[, 1:3]) Adipo &lt;- as.matrix(RNA_z_score[, 4:6]) # For ChIP-seq ChIP_data &lt;- as.matrix(data[, 8:9]) ChIP_z_score &lt;- t(scale(t(ChIP_data))) rownames(ChIP_z_score) &lt;- rownames(data) . | Create annotation: # Specifies color code and sets annotation for the row set2_palette &lt;- brewer.pal(8, \"Set2\") cluster_factor &lt;- factor(data$Cluster) annotation &lt;- data.frame(Cluster = cluster_factor) rownames(annotation) &lt;- rownames(data) # Create row annotation row_anno &lt;- rowAnnotation( df = annotation, col = list(Cluster = setNames(c(set2_palette[4], set2_palette[3], set2_palette[2]), levels(cluster_factor))), annotation_name_side = \"top\", simple_anno_size = unit(3, \"mm\") ) ordered_levels &lt;- c(\"cluster3\", \"cluster2\", \"cluster1\") cluster_factor_ordered &lt;- factor(cluster_factor, levels = ordered_levels) # Create column annotation col_osteo_anno &lt;- HeatmapAnnotation( Type = factor(c(\"Osteogenesis\", \"Osteogenesis\", \"Osteogenesis\")), col = list(Type = c(Osteogenesis = set2_palette[5])), show_annotation_name = FALSE, simple_anno_size = unit(3, \"mm\") ) col_adipo_anno &lt;- HeatmapAnnotation( Type = factor(c(\"Adipogenesis\", \"Adipogenesis\", \"Adipogenesis\")), col = list(Type = c(Adipogenesis = set2_palette[6])), show_annotation_name = FALSE, simple_anno_size = unit(3, \"mm\") ) col_chip_anno &lt;- HeatmapAnnotation( Type = factor(c(\"ChIPseq\", \"ChIPseq\")), col = list(Type = c(ChIPseq = set2_palette[7])), show_annotation_name = FALSE, simple_anno_size = unit(3, \"mm\") ) column_split_factor &lt;- factor( c(\"Osteogenesis\", \"Osteogenesis\", \"Osteogenesis\", \"Adipogenesis\", \"Adipogenesis\", \"Adipogenesis\", \"ChIPseq\", \"ChIPseq\"), levels = c(\"Osteogenesis\", \"Adipogenesis\", \"ChIPseq\") ) . | . 2. Plotting . | Create color palettes and plot the main heatmaps: # Specifies colocr pallettes osteo_color &lt;- colorRampPalette(rev(brewer.pal(7, \"RdBu\"))) osteo_color_function = osteo_color(256) adipo_color &lt;- colorRampPalette(rev(brewer.pal(8, \"PiYG\"))) adipo_color_function = adipo_color(256) chip_color &lt;- colorRampPalette(rev(brewer.pal(7, \"YlGn\"))) chip_color_function = chip_color(256) # Osteogenic RNA-seq heatmap (as a main heatmap) osteo_heatmap &lt;- Heatmap( Osteo, col = osteo_color_function, show_row_names = FALSE, show_column_names = TRUE, name = \"Osteo(z-score)\", cluster_columns = FALSE, column_names_side = \"top\", column_split = factor(c(\"Osteogenesis\", \"Osteogenesis\", \"Osteogenesis\")), top_annotation = col_osteo_anno, split = cluster_factor_ordered, row_title = NULL, left_annotation = row_anno, width = unit(3, \"cm\"), height = unit(12, \"cm\"), ) # Adipogenic RNA-seq heatmap adipo_heatmap &lt;- Heatmap( Adipo, col = adipo_color_function, show_row_names = FALSE, show_column_names = TRUE, name = \"Adipo(z-score)\", cluster_columns = FALSE, column_names_side = \"top\", column_split = factor(c(\"Adipogenesis\", \"Adipogenesis\", \"Adipogenesis\")), top_annotation = col_adipo_anno, row_title = NULL, width = unit(3, \"cm\"), height = unit(12, \"cm\") ) # ChIP-seq heatmap chip_heatmap &lt;- Heatmap( ChIP_z_score, col = chip_color_function, show_row_names = FALSE, show_column_names = TRUE, name = \"Peak intensity (z-score)\", cluster_columns = FALSE, column_names_side = \"top\", column_split = factor(c(\"ChIPseq\", \"ChIPseq\")), top_annotation = col_chip_anno, row_title = NULL, width = unit(1.5, \"cm\"), height = unit(12, \"cm\") ) # combine and draw comb &lt;- osteo_heatmap + adipo_heatmap + chip_heatmap draw(comb) . | Crate a data frame and matrix it for the secondary heatmaps: adipo_data &lt;- matrix(data$Adipo, ncol=1, dimnames = list(rownames(data), \"AdipoMarker\")) osteo_data &lt;- matrix(data$Osteo, ncol=1, dimnames = list(rownames(data), \"OsteoMarker\")) TF_data &lt;- matrix(data$TF, ncol=1, dimnames = list(rownames(data), \"TFs\")) # Make sure you have NA in your data, in this example, NA is converted to '0' as shown below. TF_data[is.na(TF_data)] &lt;- 0 . | Create color palettes and plot the secondary heatmaps: reds_palette &lt;- c(\"white\", brewer.pal(9, \"Reds\")) blues_palette &lt;- c(\"white\", brewer.pal(9, \"Blues\")) purples_palette &lt;- c(\"white\", brewer.pal(9, \"Purples\")) # Osteogenic markers heatmap with box legend osteo_marker_heatmap &lt;- Heatmap(osteo_data, col = c(\"white\", reds_palette[7]), name = \"Osteogenic Factor\", cluster_columns = FALSE, show_row_names = FALSE, show_column_names = TRUE, column_names_side = \"top\", width = unit(0.5, \"cm\"), heatmap_legend_param = list( title = \"Osteogenic\", labels = c(\"No\", \"Yes\"), at = c(0, 1), legend_gp = gpar(fill = c(\"white\", reds_palette[8]), col = \"black\", border = TRUE), labels_gp = gpar(fontsize = 10), border = TRUE )) # Adipogenic markers heatmap with box legend adipo_marker_heatmap &lt;- Heatmap(adipo_data, col = c(\"white\", blues_palette[8]), name = \"Adipogenic Factor\", cluster_columns = FALSE, show_row_names = FALSE, show_column_names = TRUE, column_names_side = \"top\", width = unit(0.5, \"cm\"), heatmap_legend_param = list( title = \"Adipogenic\", labels = c(\"No\", \"Yes\"), at = c(0, 1), legend_gp = gpar(fill = c(\"white\", blues_palette[8]), col = \"black\", border = TRUE), labels_gp = gpar(fontsize = 10), border = TRUE )) # TF heatmap with box legend TF_heatmap &lt;- Heatmap(TF_data, col = c(\"white\", purples_palette[8]), name = \"Transcription Factor\", cluster_columns = FALSE, show_row_names = FALSE, show_column_names = TRUE, column_names_side = \"top\", width = unit(0.5, \"cm\"), heatmap_legend_param = list( title = \"TF\", labels = c(\"non-TF\", \"TF\"), at = c(0, 1), legend_gp = gpar(fill = c(\"white\", purples_palette[8]), col = \"black\", border = TRUE), labels_gp = gpar(fontsize = 10), border = TRUE )) comb2 &lt;- osteo_heatmap + adipo_heatmap + chip_heatmap + osteo_marker_heatmap + adipo_marker_heatmap + TF_heatmap draw(comb2) . | . Enter your code: Copy Clear 3. Showing Specific Gene Symbols in the Heatmap . | Select a specific gene list and create logic to display it in the heatmap: . # Specific gene list selected_genes &lt;- c(\"Cebpa\", \"Dlx5\", \"Ehf\", \"Epas1\", \"Hic1\", \"Maf\", \"Nkd2\", \"Nr1h3\", \"Pparg\", \"Runx2\", \"Satb2\", \"Thrsp\", \"Trp63\", \"Twist2\", \"Zfp467\") # Find the specific gene among input data index row_indices &lt;- which(data$Symbol %in% selected_genes) # Apply the logic on the heatmap TF_heatmap_Rev &lt;- TF_heatmap + rowAnnotation( foo = anno_mark( at = row_indices, labels = data$Symbol[row_indices], which = \"row\", labels_gp = gpar(fontsize = 8)) ) # Draw comb3 &lt;- osteo_heatmap + adipo_heatmap + chip_heatmap + osteo_marker_heatmap + adipo_marker_heatmap + TF_heatmap_Rev draw(comb3, merge_legends = TRUE, gap = unit(0, \"mm\")) . | Output: . | . Enter your code: Copy Clear ",
    "url": "/docs/RNASeq/HEATMAP_MANUAL/#step-by-step-guide-case-iii---multiple-rna-seq-combined-with-chip-seq",
    
    "relUrl": "/docs/RNASeq/HEATMAP_MANUAL/#step-by-step-guide-case-iii---multiple-rna-seq-combined-with-chip-seq"
  },"78": {
    "doc": "DEG - Heatmap",
    "title": "Citations",
    "content": "pheatmap . | Kolde, R., &amp; Kolde, M. R. (2015). Package ‘pheatmap’. R package, 1(7), 790. PDF | . complexheatmap . | Gu, Z., &amp; Hübschmann, D. (2022). Make interactive complex heatmaps in R, Bioinformatics, 38(5), 1460-1462. DOI | . ",
    "url": "/docs/RNASeq/HEATMAP_MANUAL/#citations",
    
    "relUrl": "/docs/RNASeq/HEATMAP_MANUAL/#citations"
  },"79": {
    "doc": "DEG - Heatmap",
    "title": "DEG - Heatmap",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/RNASeq/HEATMAP_MANUAL/",
    
    "relUrl": "/docs/RNASeq/HEATMAP_MANUAL/"
  },"80": {
    "doc": "Mapping reads with HISAT2 for RNA-seq",
    "title": "Alignment with Reference Genome using HISAT2",
    "content": "A first key step in RNA-seq is to align short reads to a reference genome. Several mappers have been developed according to various sample types and experimental conditions. HiSAT2 that is coded in python and a spcialized algorithm for transcriptome analysis can be fast and exactly maapped to a reference genome for whole-genome, transcriptome, and exome sequencing data. HiSAT2 can run on any computer installed on Linux or macOS and operates on python version &gt; 2.6. As the alignment process takes a very long time and spends a lot of computational resources, the minimum spec of hardware is relatively higher than other bioinformatic tools (threads &gt; 4, memory &gt; 16 Gb ). This protocol was created based on HISAT version 2.2.1 running on a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes Python version 3.8.5, SciPy version 1.6.2, NumPy version 1.20.1, and pySam version 0.16.0.1 under macOS 12.4 environment. ",
    "url": "/docs/DataProcess/HISAT2_MAUNAL/#alignment-with-reference-genome-using-hisat2",
    
    "relUrl": "/docs/DataProcess/HISAT2_MAUNAL/#alignment-with-reference-genome-using-hisat2"
  },"81": {
    "doc": "Mapping reads with HISAT2 for RNA-seq",
    "title": "Installation HISAT2",
    "content": ". To install HISAT2 via anaconda, use the following commands: . $ conda install -c bioconda hisat2 # OR $ conda install -c bioconda/label/cf201901 hisat2 . ",
    "url": "/docs/DataProcess/HISAT2_MAUNAL/#installation-hisat2",
    
    "relUrl": "/docs/DataProcess/HISAT2_MAUNAL/#installation-hisat2"
  },"82": {
    "doc": "Mapping reads with HISAT2 for RNA-seq",
    "title": "Establish Genome Builder",
    "content": ". | Download desired index files from official HISAT2 site. | Uncompress it and move desired folder. | . ",
    "url": "/docs/DataProcess/HISAT2_MAUNAL/#establish-genome-builder",
    
    "relUrl": "/docs/DataProcess/HISAT2_MAUNAL/#establish-genome-builder"
  },"83": {
    "doc": "Mapping reads with HISAT2 for RNA-seq",
    "title": "Prepare Genome Builder using `hisat2-build` if not available on suitable index file",
    "content": "hisat2-build builds a HISAT2 index from a set of DNA sequences. hisat2-build outputs a set of 6 files with suffixes .1.ht2, .2.ht2, .3.ht2, .4.ht2, .5.ht2, .6.ht2, .7.ht2, and .8.ht2. Use the following command to prepare the genome builder with hisat2-build: . $ hisat2-build &lt;genome sequence.fa&gt; &lt;output folder&gt; . The genome sequence file downloads the fa format of the toplevel (e.g. species.version.dna.toplevel.fa) provided by the ENSEMBL. | Here is an example command to perform hisat2-build on the reference file: $ hisat2-build /Users/jchoi/Desktop/Build/Danio_rerio.GRCz11.dna.toplevel.fa \\ /Users/jchoi/Desktop/Build/Danio_rerio_index . | When hisat2-build finished typing, it prints messages processing genome builder file look like this: . Settings: Output files: \"/Users/jchoi/Desktop/Build/Danio_rerio_index.*.ht2l\" Line rate: 7 (line is 128 bytes) Lines per side: 1 (side is 128 bytes) Offset rate: 4 (one in 16) FTable chars: 10 Strings: unpacked Local offset rate: 3 (one in 8) Local fTable chars: 6 Local sequence length: 57344 Local sequence overlap between two consecutive indexes: 1024 Endianness: little Actual local endianness: little Sanity checking: disabled Assertions: disabled Random seed: 0 Sizeofs: void*:8, int:4, long:8, size_t:8 Input files DNA, FASTA: /Users/jchoi/Desktop/Build/Danio_rerio.GRCz11.dna.toplevel.fa Reading reference sizes Time reading reference sizes: 00:02:37 Calculating joined length Writing header Reserving space for joined string Joining reference sequences Time to join reference sequences: 00:03:47 Time to read SNPs and splice sites: 00:00:00 Using parameters --bmax 313970597 --dcv 1024 Doing ahead-of-time memory usage test Passed! Constructing with these parameters: --bmax 313970597 --dcv 1024 Constructing suffix-array element generator Building DifferenceCoverSample Building sPrime Building sPrimeOrder V-Sorting samples V-Sorting samples time: 00:00:35 Allocating rank array Ranking v-sort output Ranking v-sort output time: 00:00:07 Invoking Larsson-Sadakane on ranks Invoking Larsson-Sadakane on ranks time: 00:00:14 Sanity-checking and returning Building samples Reserving space for 12 sample suffixes Generating random suffixes QSorting 12 sample offsets, eliminating duplicates QSorting sample offsets, eliminating duplicates time: 00:00:00 Multikey QSorting 12 samples (Using difference cover) Multikey QSorting samples time: 00:00:00 Calculating bucket sizes Splitting and merging Splitting and merging time: 00:00:00 Split 1, merged 6; iterating... Splitting and merging Splitting and merging time: 00:00:00 Split 1, merged 0; iterating... Splitting and merging Splitting and merging time: 00:00:00 Avg bucket size: 2.09314e+08 (target: 313970596) Converting suffix-array elements to index image Allocating ftab, absorbFtab Entering GFM loop Getting block 1 of 8 Reserving size (313970597) for bucket 1 Calculating Z arrays for bucket 1 Entering block accumulator loop for bucket 1: bucket 1: 10% bucket 1: 20% bucket 1: 30% bucket 1: 40% bucket 1: 50% bucket 1: 60% bucket 1: 70% bucket 1: 80% bucket 1: 90% bucket 1: 100% Sorting block of length 194086053 for bucket 1 (Using difference cover) Sorting block time: 00:01:59 Returning block of 194086054 for bucket 1 ............... Returning block of 197484859 for bucket 8 Exited GFM loop fchr[A]: 0 fchr[C]: 531052068 fchr[G]: 837464927 fchr[T]: 1143883918 fchr[$]: 1674509851 Exiting GFM::buildToDisk() Returning from initFromVector Wrote 567251040 bytes to primary GFM file: /Users/jchoi/Desktop/Build/Danio_rerio_index.1.ht2l Wrote 837254932 bytes to secondary GFM file: /Users/jchoi/Desktop/Build/Danio_rerio_index.2.ht2l Re-opening _in1 and _in2 as input streams Returning from GFM constructor Returning from initFromVector Wrote 777489661 bytes to primary GFM file: /Users/jchoi/Desktop/Build/Danio_rerio_index.5.ht2l Wrote 426205032 bytes to secondary GFM file: /Users/jchoi/Desktop/Build/Danio_rerio_index.6.ht2l Re-opening _in5 and _in5 as input streams Returning from HGFM constructor Headers: len: 1674509851 gbwtLen: 1674509852 nodes: 1674509852 sz: 418627463 gbwtSz: 418627464 lineRate: 7 offRate: 4 offMask: 0xfffffffffffffff0 ftabChars: 10 eftabLen: 0 eftabSz: 0 ftabLen: 1048577 ftabSz: 8388616 offsLen: 104656866 offsSz: 837254928 lineSz: 128 sideSz: 128 sideGbwtSz: 96 sideGbwtLen: 384 numSides: 4360703 numLines: 4360703 gbwtTotLen: 558169984 gbwtTotSz: 558169984 reverse: 0 linearFM: Yes Total time for call to driver() for forward index: 00:35:21 . | . ",
    "url": "/docs/DataProcess/HISAT2_MAUNAL/#prepare-genome-builder-using-hisat2-build-if-not-available-on-suitable-index-file",
    
    "relUrl": "/docs/DataProcess/HISAT2_MAUNAL/#prepare-genome-builder-using-hisat2-build-if-not-available-on-suitable-index-file"
  },"84": {
    "doc": "Mapping reads with HISAT2 for RNA-seq",
    "title": "Running HISAT2",
    "content": "Use the following command to perform mapping to the genome with hisat2: . $ hisat2 -x &lt;GenoemeBuilder&gt; -1 &lt;forward&gt; -2 &lt;reverse&gt; -S &lt;output.sam&gt; &lt;OptionalParameters&gt; . In these commands, . | -x &lt;GenoemeBuilder&gt;: Specifies the genome index. Since index files consist of genome.X.ht2, the builder command must be typed as follows; /genome/builder/path/genome | -1, -2: Specifies the forward (-1) and reverse (-2) input files. Support gz commpressed fastq (fq) files. | -S &lt;output.sam&gt;: Specifies the output file type and name. | The &lt;OptionalParameters&gt; offer a wide range of variables as bellow, see the HISAT2’s manual for details. | Parameter | Description | . | -5/--trim5 &lt;int, -3/--trim3 &lt;int&gt; | Trim bases from 5' (left) or 3' (right) end of each read before alignment (default: 0). | . | --mp MX,MN | Sets the maximum (MX) and minimum (MN) mismatch penalties, both integers. | . | --sp MX,MN | Sets the maximum (MX) and minimum (MN) penalties for soft-clipping per base, both integers. | . | --np &lt;int&gt; | Sets penalty for positions where the read, reference, or both, contain an ambiguous character such as N. | . | --dta-cufflinks option | Report alignments tailored specifically for Cufflinks. In addition to what HISAT2 does with the above option (–dta), With this option, HISAT2 looks for novel splice sites with three signals (GT/AG, GC/AG, AT/AC), but all user-provided splice sites are used irrespective of their signals. | . | -k &lt;int&gt; | It searches for at most distinct, primary alignments for each read. Primary alignments mean alignments whose alignment score is equal or higher than any other alignments (Default: 5). | . | -p &lt;int&gt; | The number of CPU threads HISAT program will use when executing multi-processing tasks. | . | . ",
    "url": "/docs/DataProcess/HISAT2_MAUNAL/#running-hisat2",
    
    "relUrl": "/docs/DataProcess/HISAT2_MAUNAL/#running-hisat2"
  },"85": {
    "doc": "Mapping reads with HISAT2 for RNA-seq",
    "title": "Example Code",
    "content": "Here is an example command to perform alignment with the human hg19 genome on trimmed fastq files: . $ hisat2 -x /Users/jchoi/Desktop/RNA-seq/GenomeIndex/hg19_HiSat2Builder/genome \\ -1 /Users/jchoi/Desktop/Trim/Trim_shCon_H2O2_1.fq.gz \\ -2 /Users/jchoi/Desktop/Trim/Trim_shCon_H2O2_2.fq.gz \\ -S /Users/jchoi/Desktop/SAM/shCon_H2O2.sam -p 10 --dta-cufflinks -k 5 . Enter your code: Copy Clear ",
    "url": "/docs/DataProcess/HISAT2_MAUNAL/#example-code",
    
    "relUrl": "/docs/DataProcess/HISAT2_MAUNAL/#example-code"
  },"86": {
    "doc": "Mapping reads with HISAT2 for RNA-seq",
    "title": "Output",
    "content": "When HISAT2 finishes running, it prints messages summarizing what happened. 24403217 reads; of these: 24403217 (100.00%) were paired; of these: 3213764 (13.17%) aligned concordantly 0 times 18006379 (73.79%) aligned concordantly exactly 1 time 3183074 (13.04%) aligned concordantly &gt;1 times ---- 3213764 pairs aligned concordantly 0 times; of these: 316476 (9.85%) aligned discordantly 1 time ---- 2897288 pairs aligned 0 times concordantly or discordantly; of these: 5794576 mates make up the pairs; of these: 3288372 (56.75%) aligned 0 times 1992820 (34.39%) aligned exactly 1 time 513384 (8.86%) aligned &gt;1 times 93.26% overall alignment rate . | This message can also be outputted by samtools. | . The subsequent process utilizes the resulting ‘SAM’ file. ",
    "url": "/docs/DataProcess/HISAT2_MAUNAL/#output",
    
    "relUrl": "/docs/DataProcess/HISAT2_MAUNAL/#output"
  },"87": {
    "doc": "Mapping reads with HISAT2 for RNA-seq",
    "title": "Citation",
    "content": "HISAT2 . | Kim, D., Paggi, J. M., Park, C., Bennett, C., &amp; Salzberg, S. L. (2019). Graph-based genome alignment and genotyping with HISAT2 and HISAT-genotype. Nature biotechnology, 37(8), 907-915. DOI | . ",
    "url": "/docs/DataProcess/HISAT2_MAUNAL/#citation",
    
    "relUrl": "/docs/DataProcess/HISAT2_MAUNAL/#citation"
  },"88": {
    "doc": "Mapping reads with HISAT2 for RNA-seq",
    "title": "Mapping reads with HISAT2 for RNA-seq",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/DataProcess/HISAT2_MAUNAL/",
    
    "relUrl": "/docs/DataProcess/HISAT2_MAUNAL/"
  },"89": {
    "doc": "Peak Detection - MACS",
    "title": "Model-based Analysis for ChIP-Seq (MACS)",
    "content": "MACS3 is a computational tool used for the analysis of ChIP-Seq data. This tool is designed to identify transcription factor binding sites and regions of chromatin modifications across the genome with high precision and accuracy. The main features of MACS3 include the ability to handle different sequencing depths and conditions without user-defined parameters, an enhanced model-building strategy to better capture the nuances of peak distributions (callpeak). MACS3 also supports differential binding analysis (bdgdiff), facilitating the comparison between different samples to identify changes in protein-DNA interaction patterns. This protocol was created based on MACS3 version 3.0.0a6 running on a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes Python version 3.8.5, SciPy version 1.6.2, NumPy version 1.20.1, and Cython version 0.29.30 under macOS 12.4 environment. ",
    "url": "/docs/ChIPSeq/MACS_MANUAL/#model-based-analysis-for-chip-seq-macs",
    
    "relUrl": "/docs/ChIPSeq/MACS_MANUAL/#model-based-analysis-for-chip-seq-macs"
  },"90": {
    "doc": "Peak Detection - MACS",
    "title": "Installation MACS3",
    "content": ". To install MACS3 via Pypi, use the following commands: . $ pip3 install macs3 . ",
    "url": "/docs/ChIPSeq/MACS_MANUAL/#installation-macs3",
    
    "relUrl": "/docs/ChIPSeq/MACS_MANUAL/#installation-macs3"
  },"91": {
    "doc": "Peak Detection - MACS",
    "title": "Requirements for operating MACS3 version 3.0.1 (lastly released)",
    "content": "To use macs3 you need: . | Python &gt; 3.0 and its libraries scipy &gt;= 1.12, numpy &gt;= 1.25, pytest &gt;= 7.0, and scikit-learn&gt;=1.3 | Cython ~= 3.0 and its wrapper cykhash &gt;= 2.0, &lt; 3.0 | . Disclaimer . The requirements for running the latest version have changed significantly from the original specifications, incorporating numerous additional packages and updates to existing packages to newer versions. I have not tested MACS3 with this version, so I cannot ensure complete compatibility or functionality. Consequently, I advise beginners to manually install version 3.0.0a6 (alpha 6 released) from the source code. ",
    "url": "/docs/ChIPSeq/MACS_MANUAL/#requirements-for-operating-macs3-version-301-lastly-released",
    
    "relUrl": "/docs/ChIPSeq/MACS_MANUAL/#requirements-for-operating-macs3-version-301-lastly-released"
  },"92": {
    "doc": "Peak Detection - MACS",
    "title": "Running MACS3",
    "content": "Use the following command to perform peak-call analysis with macs3: . $ macs3 callpeak -t &lt;TargetFile&gt; -c &lt;ControlFile&gt; -f &lt;type&gt; -g &lt;genomeSize&gt; -n &lt;NAME&gt; \\ -B --nomodel --extsize &lt;int&gt; --shift &lt;int&gt; -q &lt;int&gt; --broad --broad-cutoff &lt;int&gt; . In these commands, . | Parameter | Description | . | -t &lt;TargetFile&gt; | Specifies the target data. | . | -c &lt;ControlFile&gt; | Specifies the control data (input). | . | -f &lt;type&gt; | Specifies the file type. Possible data type is BAM (recommended), BED, ELANDMULTI, BAMPE, or BEDPE. | . | -g &lt;genomeSize&gt; | It is the mappable genome size or effective genome size which is defined as the genome size which can be sequenced. Possible values for size are hs (2913022398/GRCh38), mm (2652783500/GRCm38), dm(142573017/dm6), or &lt;int&gt;. Genome sizes for other species are available from deeptools. | . | -n &lt;NAME&gt; | Determine the prefix to apply to the output files. | . | -B option | Specifies that store the fragment pileup, control lambda in bedGraph files. | . | --nomodel option | While on, MACS3 will bypass building the shifting model. Please combine the usage of --extsize and --shift to achieve the effect you expect. | . | --extsize &lt;int&gt; | While this option is set, MACS3 uses this parameter to extend reads in forward direction to fix-sized fragments. | . | --shift &lt;int&gt; | Specifies a starting point for reading in reads. Start reading at a position &lt;int&gt; away from the 5’ read. The size of the read is determined by &lt;--extsize&gt;. When this value is negative, the cutting ends (5’) will be moved toward 3’-&gt;5’ direction, otherwise 5’-&gt;3’ direction. | . | -q &lt;int&gt; | Specifies an FDR cutoff to call significant regions (Default: 0.05). | . | --broad option | This option, along with the bdgbroadcall command, facilitates broad peak calling, producing results in the UCSC gappedPeak format which encapsulates a nested structure of peaks. | . | --broad-cutoff &lt;int&gt; | Specifies cutoff for the broad region. This option is not available unless --broad is set (Default: 0.1). | . Critical Note . | It is important to understand that -goption means the size of the genome, not the species. | The --extsize option is particularly useful when the binding size of a specific transcription factor is known. For example, if the size of the binding region for target TF is 200 bp, this parameter can be set as 200. | The --extsize and --shiftoptions are a very useful for DNase and ATAC-seq. To find enriched cutting sites in DNAse-seq, all 5’ ends of sequenced reads should be extended in both directions (approx. 200 bp) to smooth the pileup signals as following commands: --nomodel --shift -100 --extsize 200 (shift = -1 * [a half of extsize]). | For nucleosome-seq data, need to pile up the centers of nucleosomes using a half-nucleosome size for NPS algorithm as the following command (DNA wrapped on nucleosome is about 147 bp): --nomodel --shift 37 --extsize 73. | . ",
    "url": "/docs/ChIPSeq/MACS_MANUAL/#running-macs3",
    
    "relUrl": "/docs/ChIPSeq/MACS_MANUAL/#running-macs3"
  },"93": {
    "doc": "Peak Detection - MACS",
    "title": "Example Code",
    "content": "Here is an example command to find significant peaks for histone ChIP-seq and TF ChIP-seq: . # Histone ChIP-seq $ macs3 callpeak -t Sort_shControl.bam -c Sort_Input.bam -f BAM -g mm \\ -n /home/jh/Desktop/MACS/shControl --broad --broad-cutoff 0.1 # TF ChIP-seq, with basal parameters $ macs3 callpeak -t Sort_shNFIB_MLL1.bam -c Sort_Input.bam -f BAM -g mm \\ -n /home/jh/Desktop/MACS/shNFIB_MLL1 -B -q 0.05 # TF ChIP-seq, with advanced parameters $ macs3 callpeak -t Sort_Unt_Control.bam -c Sort_Input_Control.bam -f BAM -g mm \\ -n /home/jh/Desktop/MACS/HaCaT_Unt_MLL1 -B --nomodel --extsize 150 -q 0.05 . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/MACS_MANUAL/#example-code",
    
    "relUrl": "/docs/ChIPSeq/MACS_MANUAL/#example-code"
  },"94": {
    "doc": "Peak Detection - MACS",
    "title": "Output",
    "content": "When running callpeak, it will print out the progress as shown below: . INFO @ Sun, 02 May 2021 11:55:38: # Command line: callpeak -t /home/jh/Desktop/Bam/Sort_shNFIB.bam -c /home/jh/Desktop/Bam/Sort_Input.bam --broad -B -g mm --broad-cutoff 0.1 -n /home/jh/Desktop/MACS/shNFIB # ARGUMENTS LIST: # name = /home/jh/Desktop/MACS/shNFIB # format = AUTO # ChIP-seq file = ['/home/jh/Desktop/Bam/Sort_shNFIB.bam'] # control file = ['/home/jh/Desktop/Bam/Sort_Input.bam'] # effective genome size = 1.87e+09 # band width = 300 # model fold = [5, 50] # qvalue cutoff for narrow/strong regions = 5.00e-02 # qvalue cutoff for broad/weak regions = 1.00e-01 # The maximum gap between significant sites is assigned as the read length/tag size. # The minimum length of peaks is assigned as the predicted fragment length \"d\". # Larger dataset will be scaled towards smaller dataset. # Range for calculating regional lambda is: 1000 bps and 10000 bps # Broad region calling is on # Paired-End mode is off INFO @ Sun, 02 May 2021 11:55:38: #1 read tag files... INFO @ Sun, 02 May 2021 11:55:38: #1 read treatment tags... INFO @ Sun, 02 May 2021 11:55:38: Detected format is: BAM INFO @ Sun, 02 May 2021 11:55:38: * Input file is gzipped. INFO @ Sun, 02 May 2021 11:55:40: 1000000 reads parsed INFO @ Sun, 02 May 2021 11:56:09: 13000000 reads parsed INFO @ Sun, 02 May 2021 11:56:12: 13369442 reads have been read. INFO @ Sun, 02 May 2021 11:56:12: #1.2 read input tags... INFO @ Sun, 02 May 2021 11:56:12: Detected format is: BAM INFO @ Sun, 02 May 2021 11:56:12: * Input file is gzipped. INFO @ Sun, 02 May 2021 11:56:16: 1000000 reads parsed INFO @ Sun, 02 May 2021 11:57:03: 13000000 reads parsed INFO @ Sun, 02 May 2021 11:57:07: 13700548 reads have been read. INFO @ Sun, 02 May 2021 11:57:07: #1 tag size is determined as 101 bps INFO @ Sun, 02 May 2021 11:57:07: #1 tag size = 101.0 INFO @ Sun, 02 May 2021 11:57:07: #1 total tags in treatment: 13369442 INFO @ Sun, 02 May 2021 11:57:07: #1 user defined the maximum tags... INFO @ Sun, 02 May 2021 11:57:07: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) INFO @ Sun, 02 May 2021 11:57:08: #1 tags after filtering in treatment: 12297927 INFO @ Sun, 02 May 2021 11:57:08: #1 Redundant rate of treatment: 0.08 INFO @ Sun, 02 May 2021 11:57:08: #1 total tags in control: 13700548 INFO @ Sun, 02 May 2021 11:57:08: #1 user defined the maximum tags... INFO @ Sun, 02 May 2021 11:57:08: #1 filter out redundant tags at the same location and the same strand by allowing at most 1 tag(s) INFO @ Sun, 02 May 2021 11:57:08: #1 tags after filtering in control: 11744178 INFO @ Sun, 02 May 2021 11:57:08: #1 Redundant rate of control: 0.14 INFO @ Sun, 02 May 2021 11:57:08: #1 finished! INFO @ Sun, 02 May 2021 11:57:08: #2 Build Peak Model... INFO @ Sun, 02 May 2021 11:57:08: #2 looking for paired plus/minus strand peaks... INFO @ Sun, 02 May 2021 11:57:12: #2 Total number of paired peaks: 10769 INFO @ Sun, 02 May 2021 11:57:12: #2 Model building with cross-correlation: Done INFO @ Sun, 02 May 2021 11:57:12: #2 finished! INFO @ Sun, 02 May 2021 11:57:12: #2 predicted fragment length is 207 bps INFO @ Sun, 02 May 2021 11:57:12: #2 alternative fragment length(s) may be 207 bps INFO @ Sun, 02 May 2021 11:57:12: #2.2 Generate R script for model : /home/jh/Desktop/MACS/shNFIB_model.r INFO @ Sun, 02 May 2021 11:57:12: #3 Call peaks... INFO @ Sun, 02 May 2021 11:57:12: #3 Call broad peaks with given level1 -log10qvalue cutoff and level2: 1.301030, 1.000000... INFO @ Sun, 02 May 2021 11:57:12: #3 Pre-compute pvalue-qvalue table... INFO @ Sun, 02 May 2021 11:58:19: #3 In the peak calling step, the following will be performed simultaneously: INFO @ Sun, 02 May 2021 11:58:19: #3 Write bedGraph files for treatment pileup (after scaling if necessary)... /home/jh/Desktop/MACS/shNFIB_treat_pileup.bdg INFO @ Sun, 02 May 2021 11:58:19: #3 Write bedGraph files for control lambda (after scaling if necessary)... /home/jh/Desktop/MACS/shNFIB_control_lambda.bdg INFO @ Sun, 02 May 2021 11:58:19: #3 Call peaks for each chromosome... INFO @ Sun, 02 May 2021 11:59:01: #4 Write output xls file... /home/jh/Desktop/MACS/shNFIB_peaks.xls INFO @ Sun, 02 May 2021 11:59:01: #4 Write broad peak in broadPeak format file... /home/jh/Desktop/MACS/shNFIB_peaks.broadPeak INFO @ Sun, 02 May 2021 11:59:01: #4 Write broad peak in bed12/gappedPeak format file... /home/jh/Desktop/MACS/shNFIB_peaks.gappedPeak INFO @ Sun, 02 May 2021 11:59:01: Done! . CRITICAL COMMENTS . Similar to SICER2, MACS3 also makes it important for users to adjust the settings of the algorithm to suit their particular experiment. For specific conditions below, I recommend applying the following parameters to increase efficiency and save the time: . | Typically, use the --broad option for detecting broad peaks associated with histone activity markers. For identifying more variable peaks, such as histone repression markers and TFs, it is advisable not to use this option. | For a more detailed analysis, use --nomodel mode, where the crucial factor is the estimated read size (--extsize). You can determine this using the predictd subcommand of MACS3. Below is the method to utilize this subcommand. $ macs3 predictd -i &lt;InputFile.bam&gt; -g &lt;genomeSize&gt; --rfile &lt;output.R&gt; . In these commands, . | -i &lt;InputFile.bam&gt;: Specifies input file. Possible data type is BAM (recommended), BED, ELANDMULTI, BAMPE, or BEDPE. | -g &lt;genomeSize&gt;: Specifies the genome size. This parameter is the same as the callpeak function. | --rfile &lt;output.R&gt;: Specifies output file as peak model plot. | . Here is an example command to perform predictd: . $ macs3 predictd -i /Users/jchoi/Desktop/Final.sort.Unt_MLL1.bam -g hs \\ --rfile /Users/jchoi/Desktop/predict_model_MLL1.R . When running predictd, it will print out the progress as shown below: . INFO @ Fri, 10 May 2024 14:18:31: # read alignment files... INFO @ Fri, 10 May 2024 14:18:31: # read treatment tags... INFO @ Fri, 10 May 2024 14:18:31: Detected format is: BAM INFO @ Fri, 10 May 2024 14:18:31: * Input file is gzipped.* INFO @ Fri, 10 May 2024 14:18:34: 1000000 reads parsed INFO @ Fri, 10 May 2024 14:18:36: 2000000 reads parsed INFO @ Fri, 10 May 2024 14:18:38: 3000000 reads parsed INFO @ Fri, 10 May 2024 14:18:40: 4000000 reads parsed INFO @ Fri, 10 May 2024 14:18:43: 5000000 reads parsed INFO @ Fri, 10 May 2024 14:18:45: 6000000 reads parsed INFO @ Fri, 10 May 2024 14:18:47: 7000000 reads parsed INFO @ Fri, 10 May 2024 14:18:49: 8000000 reads parsed INFO @ Fri, 10 May 2024 14:18:51: 9000000 reads parsed INFO @ Fri, 10 May 2024 14:18:54: 10000000 reads parsed INFO @ Fri, 10 May 2024 14:18:56: 11000000 reads parsed INFO @ Fri, 10 May 2024 14:18:58: 12000000 reads parsed INFO @ Fri, 10 May 2024 14:19:00: 13000000 reads parsed INFO @ Fri, 10 May 2024 14:19:02: 14000000 reads parsed INFO @ Fri, 10 May 2024 14:19:05: 15000000 reads parsed INFO @ Fri, 10 May 2024 14:19:07: 16000000 reads parsed INFO @ Fri, 10 May 2024 14:19:09: 17000000 reads parsed INFO @ Fri, 10 May 2024 14:19:11: 18000000 reads parsed INFO @ Fri, 10 May 2024 14:19:13: 19000000 reads parsed INFO @ Fri, 10 May 2024 14:19:16: 20000000 reads parsed INFO @ Fri, 10 May 2024 14:19:20: 20958780 reads have been read. INFO @ Fri, 10 May 2024 14:19:20: tag size is determined as 93 bps INFO @ Fri, 10 May 2024 14:19:20: # tag size = 93 INFO @ Fri, 10 May 2024 14:19:20: # total tags in alignment file: 20958780 INFO @ Fri, 10 May 2024 14:19:20: # Build Peak Model... INFO @ Fri, 10 May 2024 14:19:20: #2 looking for paired plus/minus strand peaks... INFO @ Fri, 10 May 2024 14:19:24: #2 Total number of paired peaks: 1407 INFO @ Fri, 10 May 2024 14:19:25: #2 Model building with cross-correlation: Done INFO @ Fri, 10 May 2024 14:19:25: # finished! INFO @ Fri, 10 May 2024 14:19:25: # predicted fragment length is 195 bps INFO @ Fri, 10 May 2024 14:19:25: # alternative fragment length(s) may be 175,195 bps INFO @ Fri, 10 May 2024 14:19:25: # Generate R script for model : predict_model_MLL1.R . | You can use the number of base pair printed in predicted fragment length on line 34, pink as the --extsize option. | The output model file can be output as a PDF image in the terminal with the following command: $ Rscript &lt;output.R&gt; . | . | . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/MACS_MANUAL/#output",
    
    "relUrl": "/docs/ChIPSeq/MACS_MANUAL/#output"
  },"95": {
    "doc": "Peak Detection - MACS",
    "title": "Understanding MACS Output",
    "content": ". | The result of the callpeak will be 3 – 6 files in the specified folder (-n option), according to the specific parameters. These output files are described below: . | name_peaks.xls (e.g. shCtrl_MLL1_peaks.xls): This file is a tabular file which contains information about called peaks. It is in “chromosome name, start, end, length of peak region, absolute peal summit, pileup height, -log10(pvalue), fold enrichment, -log10(qvalue)” format. | name_peaks.narrowPeak (e.g. shCtrl_MLL1_peaks.narrowPeak): This file is BED6+4 format file which contains the peak locations together with peak summit, p-value, and q-value. It is can be loaded directly to the IGV or UCSC brower. | name_summits.bed (e.g. shCtrl_MLL1_summits.bed): This file is in BED format, which contains the peak summits locations for every peak. The 5th column in this file is the same as what is in the narrowPeak file. If you want to find the motifs at the binding sites, this file is recommended. It is can be loaded directly to the IGV or UCSC brower. | name_peaks.broadPeak (e.g. shCtrl_MLL1_peaks.broadPeak): This file is in BED6+3 format which is similar to narrowPeak file, except for missing the 10th column for annotating peak summits. It is only generated when the --broad option is on. For more information on each column, refer to MACS3’s github. It is can be loaded directly to the IGV or UCSC brower. | name_peaks.gappedPeak (e.g. shCtrl_MLL1_peaks.gappedPeak): This file is in BED12+3 format which contains both the broad region and narrow peaks. It is only generated when the --broad option is on. For more information on each column, refer to MACS3’s github. It is can be loaded directly to the IGV or UCSC brower. | name_treat_pileup.bdg and name_control_lambda.bdg: The name_treat_pileup.bdg contains the pileup signals from ChIP/treatment samples. The name_control_lambda.bdg contains local biases estimated for each genomic location from the control/input samples, or from treatment sample when the control sample is absent. when the -B option is on. | . | . ",
    "url": "/docs/ChIPSeq/MACS_MANUAL/#understanding-macs-output",
    
    "relUrl": "/docs/ChIPSeq/MACS_MANUAL/#understanding-macs-output"
  },"96": {
    "doc": "Peak Detection - MACS",
    "title": "Running bdgdiff for Differential Peak Calling",
    "content": "The bdgdiff command takes four input bedGraph files (two targets and two control files) and produces three output files with differential peaks called. Users should provide paired four bedGraph files: for each condition, a treatment pileup signal track in bedGraph format, and a control lambda track in bedGraph format.This differential calling can only handle one replicate per condition. The method I use to define the differential peaks is based on multiple likelihood tests, based on the poisson distribution. The likelihood function I used while comparing two conditions: ChIP (enrichment) or control (chromatin bias) is: . \\[ ln(LR) = x*(ln(x)-ln(y)) + y - x \\] . Here \\(LR\\) is the likelihood ratio, \\(x\\) is the signal (fragment pileup) observed in condition 1, and \\(y\\) is the signal in condition 2. And \\(ln\\) is the natural logarithm. Use the following command to perform differential peak calling analysis with bdgdiff: . $ macs3 bdgdiff --t1 &lt;cond1_treat_pileup.bdg&gt; --c1 &lt;cond1_control_lambda.bdg&gt; \\ --t1 &lt;cond2_treat_pileup.bdg&gt; --c1 &lt;cond2_control_lambda.bdg&gt; \\ -C &lt;int&gt; -l &lt;int&gt; -g &lt;int&gt; --d1 &lt;cond1_depth&gt; --d2 &lt;cond2_depth&gt; \\ --outdir &lt;output_path&gt; --o-prefix &lt;name&gt; . In these commands, . | Parameter | Description | . | --t1 &lt;cond1_treat_pileup.bdg&gt; | Specifies the MACS pileup bdg file for condition 1. | . | --c1 &lt;cond1_control_lambda.bdg&gt; | Specifies the MACS control lambda bdg file for condition 1. | . | --t2 &lt;cond2_treat_pileup.bdg&gt; | Specifies the MACS pileup bdg file for condition 2. | . | --c2 &lt;cond2_control_lambda.bdg&gt; | Specifies the MACS control lambda bdg file for condition 2. | . | -C &lt;int&gt; | Determine log10LR cutoff. Regions with signals lower than the cutoff will not be considered as enriched regions (DEFAULT: 3, likelihood ratio = 1000). | . | -l &lt;int&gt; | Specifies minimum length of the differential region. Try a bigger value to remove small regions (DEFAULT: 200). | . | -g &lt;int&gt; | Specifies maximum gap to merge nearby differential regions. Consider a wider gap for broad marks (DEFAULT: 100). The maximum gap should be smaller than the minimum length (-l). | . | --d1 &lt;cond1_depth&gt; | Specifies sequencing depth for condition 1. | . | --d2 &lt;cond1_depth&gt; | Specifies sequencing depth for condition 2. | . | --outdir &lt;output_path&gt; | Specifies output folder. All output files will be written to that directory. | . | ---o-prefix &lt;name&gt; | Specifies output file prefix. Actual files will be named as PREFIX_cond1.bed, PREFIX_cond2.bed, and PREFIX_common.bed. | . ",
    "url": "/docs/ChIPSeq/MACS_MANUAL/#running-bdgdiff-for-differential-peak-calling",
    
    "relUrl": "/docs/ChIPSeq/MACS_MANUAL/#running-bdgdiff-for-differential-peak-calling"
  },"97": {
    "doc": "Peak Detection - MACS",
    "title": "Step-by-step Manual (Example Code and Output)",
    "content": "Step 1. Determine fix-sized fragment using the predictd funtion. | To get a uniform size for running callpeak, run predictd as following example: . $ macs3 predictd -i Unt_H3K4me3.bam $ macs3 predictd -i H2O2_H3K4me3.bam . | . An easy solution is to use the average of two ‘fragment size’ predicted in callpeak, however any reasonable value will work. For example, you can use 200 for most ChIP-seq datasets for transcription factors, or 147 for most histone modification ChIP-seq. | Anyway, I got the result below with the above commands: . # For Unt_H3K4me3.bam INFO @ Tue, 14 May 2024 09:36:56: 17993682 reads have been read. INFO @ Tue, 14 May 2024 09:36:56: tag size is determined as 85 bps INFO @ Tue, 14 May 2024 09:36:56: # tag size = 85 INFO @ Tue, 14 May 2024 09:36:56: # total tags in alignment file: 17993682 INFO @ Tue, 14 May 2024 09:36:56: # Build Peak Model... INFO @ Tue, 14 May 2024 09:36:56: #2 looking for paired plus/minus strand peaks... INFO @ Tue, 14 May 2024 09:37:00: #2 Total number of paired peaks: 14653 INFO @ Tue, 14 May 2024 09:37:01: #2 Model building with cross-correlation: Done INFO @ Tue, 14 May 2024 09:37:01: # finished! **INFO @ Tue, 14 May 2024 09:37:01: # predicted fragment length is 219 bps** INFO @ Tue, 14 May 2024 09:37:01: # alternative fragment length(s) may be 219 bps INFO @ Tue, 14 May 2024 09:37:01: # Generate R script for model : predictd # For H2O2_H3K4me3.bam INFO @ Tue, 14 May 2024 09:39:00: 18880466 reads have been read. INFO @ Tue, 14 May 2024 09:39:00: tag size is determined as 85 bps INFO @ Tue, 14 May 2024 09:39:00: # tag size = 85 INFO @ Tue, 14 May 2024 09:39:00: # total tags in alignment file: 18880466 INFO @ Tue, 14 May 2024 09:39:00: # Build Peak Model... INFO @ Tue, 14 May 2024 09:39:00: #2 looking for paired plus/minus strand peaks... INFO @ Tue, 14 May 2024 09:39:05: #2 Total number of paired peaks: 15129 INFO @ Tue, 14 May 2024 09:39:05: #2 Model building with cross-correlation: Done INFO @ Tue, 14 May 2024 09:39:05: # finished! **INFO @ Tue, 14 May 2024 09:39:05: # predicted fragment length is 224 bps** INFO @ Tue, 14 May 2024 09:39:05: # alternative fragment length(s) may be 224 bps INFO @ Tue, 14 May 2024 09:39:05: # Generate R script for model : predictd . | . Step 2. Prepare bdg files corresponding to each sample using the callpeak funtion. | Using the size of the fragment calculated above for the --extsize option, perform the callpeak function as shown below. I will not describe the output (refer to the section of basal MACS3). $ macs3 macs3 callpeak -B -t Unt_H3K4me3.bam -c IPT.bam -g hs -n Unt --nomodel --extsize 219 $ macs3 callpeak -B -t H2O2_H3K4me3.bam -c IPT.bam -g hs -n H2O2 --nomodel --extsize 224 . | . Step 3. Determine seqeuncing depth. | Extract the “tags after filtering in treatment” and “tags after filtering in control” lines from the &lt;name&gt;_peaks.xls to see the effective sequencing depths for both conditions. | The effective sequencing depth is the smaller number of treatment and control. For example, use the egrep function in the terminal as the following commands: . $ egrep \"tags after filtering in treatment|tags after filtering in control\" Unt_peaks.xls # tags after filtering in treatment: 14060436 # tags after filtering in control: 16211598 $ egrep \"tags after filtering in treatment|tags after filtering in control\" H2O2_peaks.xls # tags after filtering in treatment: 14486767 # tags after filtering in control: 16211598 . | Then actual effective depths of condition 1 (Unt) and 2 (H2O2) are 14060436 and 14486767, respectively. | . Step 4. Running the bdgdiff function. | The purpose of this step is to do a three ways comparisons to find out where in the genome has differential enrichment between two conditions. A log10 likelihood ratio cutoff (-C option) will be applied in this step. | Three types of differential regions will be reported: PREFIX_cond1.bed (cond1 &gt; cond2), PREFIX_cond2.bed (cond1 &lt; cond2), and PREFIX_common.bed (cond1 = cond2). $ macs3 bdgdiff --t1 Unt_treat_pileup.bdg --c1 Unt_control_lambda.bdg \\ --t2 H2O2_treat_pileup.bdg --c2 H2O2_control_lambda.bdg \\ --d1 14060436 --d2 14486767 -g 60 -l 120 --o-prefix diffPeaks . | When running bdgdiff, it will print out the progress as shown below: . INFO @ Tue, 14 May 2024 10:03:32: Read and build treatment 1 bedGraph... INFO @ Tue, 14 May 2024 10:03:52: Read and build control 1 bedGraph... INFO @ Tue, 14 May 2024 10:04:18: Read and build treatment 2 bedGraph... INFO @ Tue, 14 May 2024 10:04:38: Read and build control 2 bedGraph... INFO @ Tue, 14 May 2024 10:06:51: Write peaks... INFO @ Tue, 14 May 2024 10:06:51: Done . | . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/MACS_MANUAL/#step-by-step-manual-example-code-and-output",
    
    "relUrl": "/docs/ChIPSeq/MACS_MANUAL/#step-by-step-manual-example-code-and-output"
  },"98": {
    "doc": "Peak Detection - MACS",
    "title": "Citation",
    "content": "MACS . | Zhang, Y., Liu, T., Meyer, C. A., Eeckhoute, J., Johnson, D. S., Bernstein, B. E., ... &amp; Liu, X. S. (2008).Model-based analysis of ChIP-Seq (MACS). Genome biology, 9, 1-9. DOI | . ",
    "url": "/docs/ChIPSeq/MACS_MANUAL/#citation",
    
    "relUrl": "/docs/ChIPSeq/MACS_MANUAL/#citation"
  },"99": {
    "doc": "Peak Detection - MACS",
    "title": "Peak Detection - MACS",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/ChIPSeq/MACS_MANUAL/",
    
    "relUrl": "/docs/ChIPSeq/MACS_MANUAL/"
  },"100": {
    "doc": "Motif Enrichment Analysis",
    "title": "Motif Enrichment Analysis of ChIP-seq",
    "content": "In the analysis of ChIP-seq data, motif analysis plays a critical role in understanding the binding patterns of DNA-associated proteins. Tools like HOMER and MEME are pivotal in this research. HOMER is particularly effective for discovering new, short motifs (8-12 bp) within large genomic datasets, operating with a suite of command-line tools in Perl and C++. MEME, meanwhile, excels at identifying motifs across unaligned sequences using statistical models, helping to elucidate potential biological functions. Both tools are instrumental for researchers studying gene regulation and protein-DNA interactions, providing insights into the underlying mechanisms of gene expression. This protocol was created based on HOMER version 4.9.1 and MEME version 5.5.5 running on a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes Python version 3.8.5, SciPy version 1.6.2, NumPy version 1.20.1, Xcode Command Line Tools version 2406, and perl version 5.26.2 under macOS 12.4 environment. ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#motif-enrichment-analysis-of-chip-seq",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#motif-enrichment-analysis-of-chip-seq"
  },"101": {
    "doc": "Motif Enrichment Analysis",
    "title": "Installation HOMER",
    "content": ". To install HOMER using Anaconda, use one of the following commands: . $ conda install -c bioconda homer # OR $ conda install -c bioconda/label/cf201901 homer . ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#installation-homer",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#installation-homer"
  },"102": {
    "doc": "Motif Enrichment Analysis",
    "title": "Installation Reference Genomes",
    "content": "To check the available reference genomes, enter the following commnad in terminal: . $ perl /Users/jchoi/opt/anaconda3/share/homer-4.10-0/configureHomer.pl -list . When running configureHomer.pl, it will print out the progress as shown below: . Current base directory for HOMER is /Users/jchoi/opt/anaconda3/share/homer-4.10-0/ --2024-05-14 15:19:49-- http://homer.ucsd.edu/homer/update.txt Connecting to homer.ucsd.edu (homer.ucsd.edu)|169.228.63.226|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 17857 (17K) [text/plain] Saving to: ‘/Users/jchoi/opt/anaconda3/share/homer-4.10-0//update.txt’ /Users/jchoi/opt/anaconda3/share/homer-4.10-0//updat 100%[====================================================================================================================&gt;] 17.44K --.-KB/s in 0.1s 2024-05-14 15:19:49 (122 KB/s) - ‘/Users/jchoi/opt/anaconda3/share/homer-4.10-0//update.txt’ saved [17857/17857] Updating Settings... Packages with name conflicts have a trailing -o, -p, or -g Version Installed Package Version Description SOFTWARE v4.11.1 homer v5.0.1 Code/Executables, ontologies, motifs for HOMER ORGANISMS =========================================(skip)========================================= + zebrafinch v6.3 Taeniopygia guttata (zebrafinch) accession and ontology information + mushroom v6.3 Agaricus bisporus (mushroom) accession and ontology information + volvox v6.3 Volvox carteri (volvox) accession and ontology information + selaginella v6.3 Selaginella moellendorffii (selaginella) accession and ontology information + mouse-o v6.3 Mus musculus (mouse) accession and ontology information =========================================(skip)========================================= + rhesus v6.3 Macaca mulatta (rhesus) accession and ontology information + ascomycetes v6.0 Neurospora crassa (ascomycetes) accession and ontology information + fugu v6.3 Takifugu rubripes (fugu) accession and ontology information + rice v6.3 Oryza sativa (rice) accession and ontology information =========================================(skip)========================================= PROMOTERS + human-p v5.5 human promoters (human) + frog-p v5.5 frog promoters (frog) + worm-p v5.5 worm promoters (worm) + rat-p v5.5 rat promoters (rat) + fly-p v5.5 fly promoters (fly) + chicken-p v5.5 chicken promoters (chicken) + zebrafish-p v5.5 zebrafish promoters (zebrafish) + arabidopsis-p v6.3 arabidopsis promoters (arabidopsis) + mouse-p v5.5 mouse promoters (mouse) + yeast-p v5.5 yeast promoters (yeast) GENOMES =========================================(skip)========================================= + hg19 v6.4 human genome and annotation for UCSC hg19 + mm10 v6.4 mouse genome and annotation for UCSC mm10 + danRer7 v6.4 zebrafish genome and annotation for UCSC danRer7 + sacCer3 v6.4 yeast genome and annotation for UCSC sacCer3 + danRer11 v6.4 zebrafish genome and annotation for UCSC danRer11 =========================================(skip)========================================= + danRer10 v6.4 zebrafish genome and annotation for UCSC danRer10 + dm3 v6.0 fly genome and annotation for UCSC dm3 + rice.IRGSP-1.0 v5.10 rice genome and annotation (rice.IRGSP-1.0) + panPan2 v6.4 human genome and annotation for UCSC panPan2 + gorGor4 v6.4 human genome and annotation for UCSC gorGor4 =========================================(skip)========================================= + hg38 v6.4 human genome and annotation for UCSC hg38 + panTro3 v6.4 human genome and annotation for UCSC panTro3 + galGal5 v6.4 chicken genome and annotation for UCSC galGal5 . To install the desired reference genomes, promoters, or organisms, enter the following commnad in terminal: . $ perl /Users/jchoi/opt/anaconda3/share/homer-4.10-0/configureHomer.pl -install &lt;specific-name&gt; . ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#installation-reference-genomes",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#installation-reference-genomes"
  },"103": {
    "doc": "Motif Enrichment Analysis",
    "title": "Accessing the 'HOMER' Server from the Office Network",
    "content": "Occasionally, users may encounter difficulties accessing the ‘HOMER’ server from their office network, despite the HOMER website being reachable. This issue typically arises due to specific ports or IP addresses being blocked by our organization’s firewalls or network policies. Should you experience such connectivity issues, the following procedures are recommended: . Option 1. Contact the IT Department: This is the preferred and recommended approach. IT staff are equipped to assess and rectify connectivity issues while ensuring compliance with our security protocols. Option 2. Use a Bypass Program: Utilizing a VPN or other bypass solutions can be considered if direct assistance from IT is not feasible. Please note, employing such methods must comply with your company's IT policies. Option 3. Manual Configuration: This involves manually adding the reference genome. Details on how to perform this configuration will be discussed in the following section. Disclaimer: It is crucial to emphasize that while Option 1 is generally the most effective and secure method to resolve access issues, it might not always be immediately available. As for Option 2, please be aware that I cannot assume responsibility for any security violations or other repercussions that may occur within your organization as a result of using unauthorized bypass methods. Always seek approval from relevant authorities within the company prior to proceeding with such solutions. ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#accessing-the-homer-server-from-the-office-network",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#accessing-the-homer-server-from-the-office-network"
  },"104": {
    "doc": "Motif Enrichment Analysis",
    "title": "Critical Protocol for Adding Reference Genomes in HOMER (Option 3)",
    "content": "This protocol details the steps required to update genome files within the HOMER environment. Please follow these steps meticulously to ensure accurate data handling and integration: . 1. Verify Installation of HOMER: Confirm that HOMER is properly installed on your system. You can locate the configuration file at ./opt/anaconda3/share/homer-XXX/config.txt. 2. Access Configuration File: Navigate to the directory specified above and open the config.txt file using a suitable text editor. 3. Locate Dataset Entry: Within the configuration file, search for the entry corresponding to your desired dataset. This could include genome data, promoters, GO terms, or known transcription factors. Pay particular attention to the HTTP address provided in the fourth column of the file. 4. Download Dataset: Using the HTTP address noted, manually download the dataset of interest. Ensure the source is reliable and secure. 5. Extract and Transfer Data: After downloading, unzip the file and transfer its contents to the data folder as specified in the configuration file. The path to this data folder is typically noted in the fifth column of config.txt. 6. Initiate Motif Analysis: With the new data successfully integrated, you are now prepared to proceed with motif analysis using HOMER. ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#critical-protocol-for-adding-reference-genomes-in-homer-option-3",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#critical-protocol-for-adding-reference-genomes-in-homer-option-3"
  },"105": {
    "doc": "Motif Enrichment Analysis",
    "title": "Running HOMER",
    "content": "Use the following command to find enriched motifs in genomic regions with findMotifsGenome: . $ findMotifsGenome.pl &lt;PeakFiles&gt; &lt;species&gt; &lt;OutputFolder&gt; -size &lt;int&gt; -len &lt;int&gt; -p &lt;int&gt; . In these commands, . | Parameter | Description | . | &lt;PeakFiles&gt; | Specifies the input file. Acceptable input files are peaks files, which have at minimum five columns (separated by tabs, peakID/chromosome/start/end/strand) and BED (recommended) formats. | . | &lt;species&gt; | Specifies the reference genome. Check to the available genome in the configureHomer.pl file. | . | &lt;OutputFolder&gt; | Specifies the output path. | . | -size &lt;int&gt; | Determine region size. It is advisable to use -size 200 option to identify both primary and co-enriched motifs in transcription factors, while regions marked by histones (methyl/acetyl) should be examined with 500-1000. Using the option -size given, HOMER will use the exact regions that were used as input. | . | -len &lt;int&gt; | Specifies the length of motifs to be found. The length of time it takes to find motifs increases greatly with increasing size. In general, it is best to try out enrichment with shorter lengths (less than 15) before trying longer lengths. | . | -p &lt;int&gt; | The number of CPU cores HOMER will use when executing multi-processing tasks. | . ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#running-homer",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#running-homer"
  },"106": {
    "doc": "Motif Enrichment Analysis",
    "title": "Example Code",
    "content": "Here is an example command to find significant motifs for histone ChIP-seq and TF ChIP-seq: . # Human, ChIP-seq with a TF antiboty $ findMotifsGenome.pl MLL1_summits.bed hg19 /Users/jchoi/Desktop/HOMER_peaks -size given -len 15 -p 10 # Mouse, ChIP-seq with a histone marker antibody $ findMotifsGenome.pl H3K4me3_summits.bed mm10 /Users/jchoi/Desktop/HOMER_peaks -size 500 -len 15 -p 10 # Plant, ChIP-seq with a epitope antibody $ findMotifsGenome.pl Obe-W50-G100-FDR0.05-island.bed rice.IRGSP-1.0 /Users/jchoi/Desktop/Obe_HOMER \\ -size given -len 12 -p 10 . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#example-code",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#example-code"
  },"107": {
    "doc": "Motif Enrichment Analysis",
    "title": "Installation MEME",
    "content": ". Unlike HOMER, MEME is recommended for motif analysis in ChIP-seq data due to its flexibility in identifying multiple motifs simultaneously, its robust statistical methods that evaluate the reliability of detected motifs, and its customizable options that allow for precise adjustments to sequence variability. ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#installation-meme",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#installation-meme"
  },"108": {
    "doc": "Motif Enrichment Analysis",
    "title": "Requirements",
    "content": "To successfully use meme, the following prerequisites are necessary: . | Python Environment: Version 3.0 or higher along with the libraries scipy and numpy. | Compiler: A C compiler provided by the Xcode command line tools on macOS. | Bioinformatics Tools: . | bedtools (version specified: 2.30.0). | gs (Ghostscript, version 10.02.1), autoconf (version 2.71), automake (version 1.16.5). These tools can be installed easily using Homebrew with the command brew install &lt;package name&gt;. | . | . ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#requirements",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#requirements"
  },"109": {
    "doc": "Motif Enrichment Analysis",
    "title": "Additional Installation Notes:",
    "content": "If an XML::Parser::Expat error occurs, the necessary parser package can be installed with the following commands in the terminal: . $ cpan App::cpanminus $ cpan XML::Simple $ cpan $ install XML::Parser . ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#additional-installation-notes",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#additional-installation-notes"
  },"110": {
    "doc": "Motif Enrichment Analysis",
    "title": "Step-by-Step Installation Guide for MEME Tools",
    "content": "1. Download the Tools . | Obtain the appropriate version of the MEME tools from the official website. | . 2. Unzip and Install . | Open your terminal and execute the following commands to unpack and install the tools: $ cd ~/downloads $ tar zxf meme-5.5.5.tar.gz $ cd meme-5.5.5 $ ./configure --prefix=/Users/jchoi/meme --enable-build-libxml2 --enable-build-libxslt # --prefix=[/your/pathway]/meme $ make $ make test # Optional, to verify installation $ make install . | . 3. Configure shell environment (based on zsh) . $ nano ~/.zshrc . 4. Add MEME to your path . | Insert the following lines at the end of your ~/.zshrc file to include MEME in your system PATH. Adjust the paths as necessary based on your installation location. # MEME Suite Configuation NOTE: CASE SENSITIVITY! export PATH=[YOUR PATH]/meme/bin:[YOUR PATH]/meme/libexec/meme-5.5.5:$PATH ## For exmaple export PATH=/Users/jchoi/meme/bin:/Users/jchoi/meme/libexec/meme-5.5.5:$PATH . | . 5. Activate the configuration . $ source ~/.zshrc . ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#step-by-step-installation-guide-for-meme-tools",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#step-by-step-installation-guide-for-meme-tools"
  },"111": {
    "doc": "Motif Enrichment Analysis",
    "title": "Prepare Input Files for MEME",
    "content": "The MEME tool requires sequences in FASTA format as the standard input. This section describes how to convert a BED file from peak calling analysis into a FASTA format using the getfasta function of bedtools. ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#prepare-input-files-for-meme",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#prepare-input-files-for-meme"
  },"112": {
    "doc": "Motif Enrichment Analysis",
    "title": "Convert BED to FASTA",
    "content": "Use the following command to convert a peak-call BED file to FASTA format: . $ bedtools getfasta -fi &lt;referenceGenomeFiles&gt; -bed &lt;input.bed&gt; -fo &lt;output.fasta&gt; . In these commands, . | -fi &lt;referenceGenomeFiles&gt;: specifies the reference genome. Possible types are fasta or fa. | -bed &lt;input.bed&gt;: specifies input bed file. | -fo &lt;output.fasta&gt;: specifies output fasta file. | . ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#convert-bed-to-fasta",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#convert-bed-to-fasta"
  },"113": {
    "doc": "Motif Enrichment Analysis",
    "title": "Example Code (Results are not printed)",
    "content": "Here are example commands using getfasta for different BED files generated by peak calling tools like MACS3 and SICER2: . # For MACS3 bed $ bedtools getfasta -fi RGAP_Used.fa -bed /Users/jchoi/Desktop/MACS/obe_IP_summits.bed \\ -fo /Users/jchoi/Desktop/obe_IP.fasta # For SICER2 bed $ bedtools getfasta -fi Mus_musculus.GRCm39.dna.toplevel.fa -bed /Users/jchoi/Desktop/SICER/Unt_MLL1-W30-G60-FDR0.05-island.bed \\ -fo /Users/jchoi/Desktop/Unt_MLL1.fasta . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#example-code-results-are-not-printed",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#example-code-results-are-not-printed"
  },"114": {
    "doc": "Motif Enrichment Analysis",
    "title": "Running MEME",
    "content": "The meme tool is used to identify statistically significant motifs within a single set of DNA or protein sequences. It operates by analyzing how frequently each motif occurs within the sequences. Use the following command to find motif sites with meme: . $ meme &lt;input.fasta&gt; -&lt;alphabet&gt; -mod &lt;type&gt; -pal -revcomp -minw &lt;int&gt; -maxw &lt;int&gt; \\ -nmotifs &lt;int&gt; -p &lt;int&gt; -o &lt;output&gt; . In these commands, . | Parameter | Description | . | &lt;input.fasta&gt; | Specifies the input file in either fasta or fa format. | . | -&lt;alphabet&gt; | Specifies the type of the input file. Possible types are dna, rna, and protein. | . | -mod &lt;type&gt; | Defines the distribution model for motif sites, crucial for precise motif analysis. For more details, see the section Algorithm for the Distribution of Motif Sites. | . | -pal option | Restricts the search to palindromes in datasets that allow complementary matches. | . | -revcomp option | Expands the search to include both the original strand and its reverse complement in datasets with complementable alphabets. | . | -minw &lt;int&gt; | Search for motifs with a width &gt;= minw. | . | -maxw &lt;int&gt; | Search for motifs with a width =&lt; maxw. | . | -nmotifs &lt;int&gt; | Specifies the number of motif sites to identify. | . | -p &lt;int&gt; | Allocates the number of CPU cores for parallel processing, optimizing the performance of the tool. | . | -o &lt;output&gt; | Specifies the directory for storing the output results. | . ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#running-meme",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#running-meme"
  },"115": {
    "doc": "Motif Enrichment Analysis",
    "title": "Algorithm for the Distribution of Motif Sites",
    "content": "| Value | Name | Description | . | oops | One Occurrence Per Sequence | MEME assumes that each sequence in the dataset contains exactly one occurrence of each motif. This option is the fastest and most sensitive but the motifs returned by MEME may be “blurry” if any of the primary sequences is missing them. | . | zoops | Zero or One Occurrence Per Sequence | MEME assumes that each sequence may contain at most one occurrence of each motif. This option is useful when you suspect that some motifs may be missing from some of the primary sequences. In that case, the motifs found will be more accurate than using the first option. This option takes more computer time than the first option (about twice as much) and is slightly less sensitive to weak motifs present in all of the primary sequences. | . | anr | Any Number of Repetitions | MEME assumes each sequence may contain any number of non-overlapping occurrences of each motif. This option is useful when you suspect that motifs repeat multiple times within a single sequence. In that case, the motifs found will be much more accurate than using one of the other options. The anr option can also be used to discover repeats within a single sequence. This option takes the much more computer time than the first option (about ten times as much) and is somewhat less sensitive to weak motifs which do not repeat within a single sequence than the other two options. | . ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#algorithm-for-the-distribution-of-motif-sites",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#algorithm-for-the-distribution-of-motif-sites"
  },"116": {
    "doc": "Motif Enrichment Analysis",
    "title": "Example Code &amp; Output",
    "content": "Here is an example command to find motif sites from ChIP-seq peaks with meme: . $ meme obe_IP.fasta -dna -mod zoops -pal -minw 8 -maxw 20 -nmotifs 10 -p 10 -o /Users/jchoi/Desktop/Motif $ meme obe_IP.fasta -dna -mod oops -pal -revcomp -minw 8 -maxw 20 -nmotifs 10 -p 10 -o /Users/jchoi/Desktop/Motif_oops . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#example-code--output",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#example-code--output"
  },"117": {
    "doc": "Motif Enrichment Analysis",
    "title": "Understanding MEME Output",
    "content": "The result of the meme will be several files in the specified folder (-o option), according to the specific parameters. These output files are described below: . meme.html: an HTML file that provides the results in an interactive, human-readable format. meme.txt: a plain text file of the results for backwards compatibility with earlier versions of MEME. meme.xml: an XML file that provides the results in a format designed for machine processing. logoN.png,.eps: PNG and EPS images files containing sequence logos for each of the motifs found by MEME (where N is the motif number). logo_rcN.png,.eps: (complementable alphabets only) PNG and EPS images files containing reverse-complement sequence logos for each of the motifs found by MEME (where N is the motif number). ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#understanding-meme-output",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#understanding-meme-output"
  },"118": {
    "doc": "Motif Enrichment Analysis",
    "title": "Running meme-chip",
    "content": "meme-chip is an integrated web service used for searching and comparing motifs across various related sequences, including ChIP-seq data. This tool automates motif discovery and analysis using multiple MEME-Suite algorithms. Use the following command to find motif sites from peaks with meme-chip: . $ meme-chip &lt;input.fasta&gt; -&lt;alphabet&gt; -meme-mod &lt;type&gt; -meme-pal -minw &lt;int&gt; -maxw &lt;int&gt; \\ -meme-nmotifs &lt;int&gt; -db &lt;dbpath&gt; -meme-p &lt;int&gt; -o &lt;output&gt; . The fundamental command line remains consistent with that of meme. In these commands: . | Parameter | Description | . | &lt;input.fasta&gt; | Specifies the input file in either fasta or fa format. | . | -&lt;alphabet&gt; | Specifies the type of the input file. Possible types are dna, rna, and protein. | . | -meme-mod &lt;type&gt; | Defines the distribution model for motif sites. Same parameter the -modin meme. | . | -meme-pal option | Restricts the search to palindromes in datasets that allow complementary matches. Same parameter the -palin meme. | . | -minw &lt;int&gt; | Search for motifs with a width &gt;= minw. | . | -maxw &lt;int&gt; | Search for motifs with a width =&lt; maxw. | . | -meme-nmotifs &lt;int&gt; | Specifies the number of motif sites to identify. Same parameter the -nmotifin meme. | . | -db &lt;dbpath&gt; | (Recommended) Specifies known motifs database for comparison. Users may choose any preferred database (such as JASPAR) beyond those provided by meme (in meme/share/meme-5.5.5/db/motif_databases/). Most of these motif files are available in the *.meme format. | . | -meme-p &lt;int&gt; | Allocates the number of CPU cores for parallel processing, optimizing the performance of the tool. | . | -o &lt;output&gt; | Specifies the directory for storing the output results. | . ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#running-meme-chip",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#running-meme-chip"
  },"119": {
    "doc": "Motif Enrichment Analysis",
    "title": "Example Code &amp; Output",
    "content": "Here is an example command to find motif sites from ChIP-seq peaks with meme-chip: . # Use JASPAR core database $ meme-chip obe_IP.fasta -meme-mod zoops -meme-nmotifs 10 -minw 8 -maxw 20 \\ -db /db/motif_databases/JASPAR/JASPAR2022_CORE_plants_non-redundant_v2.meme \\ -o /Users/jchoi/Desktop/JASPAR_Motif # Use cisBP database $ meme-chip obe_IP.fasta -meme-mod zoops -meme-nmotifs 10 -minw 6 -maxw 15 -meme-pal \\ -db db/motif_databases/CIS-BP_2.00/Oryza_sativa.meme -o /Users/jchoi/Desktop/CIS_Motif # Use specific motif data $ meme-chip obe_IP.fasta -meme-mod zoops -meme-nmotifs 10 -minw 6 -maxw 12 -meme-pal \\ -db /Users/jchoi/Desktop/JASPAR2022_Plant_WRKY.meme -o /Users/jchoi/Desktop/WRKY_Motif . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#example-code--output-1",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#example-code--output-1"
  },"120": {
    "doc": "Motif Enrichment Analysis",
    "title": "Citations",
    "content": "HOMER . | Heinz, S., Benner, C., Spann, N., Bertolino, E., Lin, Y. C., Laslo, P., ... &amp; Glass, C. K. (2010). Simple combinations of lineage-determining transcription factors prime cis-regulatory elements required for macrophage and B cell identities. Molecular cell, 38(4), 576-589. DOI | . MEME suite . | Bailey, T. L., Boden, M., Buske, F. A., Frith, M., Grant, C. E., Clementi, L., ... &amp; Noble, W. S. (2009). MEME SUITE: tools for motif discovery and searching. Nucleic acids research, 37(suppl_2), W202-W208. DOI | . ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#citations",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/#citations"
  },"121": {
    "doc": "Motif Enrichment Analysis",
    "title": "Motif Enrichment Analysis",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/ChIPSeq/MotifAnalysis_MANUAL/",
    
    "relUrl": "/docs/ChIPSeq/MotifAnalysis_MANUAL/"
  },"122": {
    "doc": "Exploring ChIP-seq Data with ChIPseeker",
    "title": "Exploring ChIP-seq Data with ChIPseeker: An Essential Tool for Peak Annotation",
    "content": "Peak annotation in ChIP-seq data analysis involves identifying genomic features associated with regions of significant enrichment (peaks), such as genes, promoters, enhancers, or other regulatory elements. This process is crucial for understanding the biological significance of the data by linking DNA-protein interactions to specific functional genomic regions. ChIPseeker is a popular R package designed for the annotation and visualization of ChIP-seq data. It supports multiple genome annotations and can be easily integrated with other bioinformatics tools, enhancing its utility. A key strength of ChIPseeker is its ability to provide detailed annotation of peaks with respect to nearest genes and genomic features, along with comprehensive visualization options like pie charts and histograms that summarize the genomic distribution of the peaks. This protocol was created based on ChIPseeker version 1.32.1 running on a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes R version 4.4.0 under macOS 12.4 environment. ",
    "url": "/docs/ChIPSeq/PeakAnnotation_MANUAL/#exploring-chip-seq-data-with-chipseeker-an-essential-tool-for-peak-annotation",
    
    "relUrl": "/docs/ChIPSeq/PeakAnnotation_MANUAL/#exploring-chip-seq-data-with-chipseeker-an-essential-tool-for-peak-annotation"
  },"123": {
    "doc": "Exploring ChIP-seq Data with ChIPseeker",
    "title": "Installation ChIPseeker",
    "content": ". 1. Check and install ChIPseeker . | Start by ensuring the BiocManager package is installed, then install ChIPseeker using it: . if (!requireNamespace(\"BiocManager\", quietly=TRUE)) install.packages(\"BiocManager\") ## BiocManager::install(\"BiocUpgrade\") ## you may need this BiocManager::install(\"ChIPseeker\") . | . 2. Install Required Libraries . | Install additional libraries necessary for ChIPseeker to function properly. These include packages for genomic data manipulation and annotation. You can install these packages manually using the BiocManager::install(\"&lt;PackageName&gt;\"). The list of packages is shown below. Dependency list . | GenomeInfoDb: Utilities for manipulating chromosome names | GenomicRanges: Representation and manipulation of genomic intervals | GenomicFeatures: Conveniently import and query gene models | rtracklayer: R interface to genome annotation files and the UCSC genome browser | clusterProfiler: statistical analysis and visualization of functional profiles for genes and gene clusters | AnnotationDbi: Manipulation of SQLite-based annotations | . Genome data list (Note, it depends on the species you want to analyze. In this manual, I only provide the analysis of human and mouse genome.) . | TxDb.Mmusculus.UCSC.mm10.knownGene: Annotation package for TxDb objects for mouse | TxDb.Hsapiens.UCSC.hg19.knownGene: Annotation package for TxDb objects for human | EnsDb.Mmusculus.v79: Ensembl based annotation package for mouse | EnsDb.Hsapiens.v86: Ensembl based annotation package for human | org.Mm.eg.db: Genome wide annotation for Mouse | org.Hs.eg.db: Genome wide annotation for human | . | . Critical Note . | Before installing each package, check if it is already installed and only install those that are missing. This can save time and avoid unnecessary installations. Here is how you can check and install a package only if it’s not already installed: . install_if_missing &lt;- function(package_name) { if (!requireNamespace(package_name, quietly = TRUE)) { BiocManager::install(package_name) } else { message(paste(package_name, \"is already installed.\")) } } # List of dependencies dependencies &lt;- c(\"GenomeInfoDb\", \"GenomicRanges\", \"GenomicFeatures\", \"rtracklayer\", \"clusterProfiler\", \"AnnotationDbi\") # Install dependencies one by one lapply(dependencies, install_if_missing) # List of genome data packages (Optional) genome_data &lt;- c(\"TxDb.Mmusculus.UCSC.mm10.knownGene\", \"TxDb.Hsapiens.UCSC.hg19.knownGene\", \"EnsDb.Mmusculus.v79\", \"EnsDb.Hsapiens.v86\", \"org.Mm.eg.db\", \"org.Hs.eg.db\") # Install genome data packages one by one lapply(genome_data, install_if_missing) . | . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/PeakAnnotation_MANUAL/#installation-chipseeker",
    
    "relUrl": "/docs/ChIPSeq/PeakAnnotation_MANUAL/#installation-chipseeker"
  },"124": {
    "doc": "Exploring ChIP-seq Data with ChIPseeker",
    "title": "Step-by-step Running Guide ChIPseeker",
    "content": "1. Load ChIPseeker and its dependency packages . library(ChIPseeker) library(TxDb.Hsapiens.UCSC.hg19.knownGene) library(EnsDb.Hsapiens.v86) library(clusterProfiler) library(AnnotationDbi) library(org.Hs.eg.db) library(ggplot2) library(ggupset) library(ggplotify) library(ggimage) library(RColorBrewer) . 2. Load peak data . | In this course, I will use peak data acquired with SICER. When using data acquired with MACS, you can load narrow, broad, or bed files as you see fit for your analysis. Sicer_H3K4me3 &lt;- readPeakFile(\"/Users/jchoi/Desktop/Unt_H3K4me3-W50-G100-islands-summary\", header = F) Sicer_H3K27me3 &lt;- readPeakFile(\"/Users/jchoi/Desktop/Unt_H3K27me3-W50-G100-islands-summary\", header = F) Sicer_MLL1 &lt;- readPeakFile(\"/Users/jchoi/Desktop/Unt_MLL1-W50-G100-islands-summary\", header = F) Sicer_UTX &lt;- readPeakFile(\"/Users/jchoi/Desktop/Unt_UTX-W50-G100-islands-summary\", header = F) peaks &lt;- list(H3K4me3 = Sicer_H3K4me3, H3K27me3 = Sicer_H3K27me3, MLL1 = Sicer_MLL1, UTX = Sicer_UTX) peaks . | . Enter your code: Copy Clear . | Output: &gt; peaks $H3K4me3 GRanges object with 59583 ranges and 5 metadata columns: seqnames ranges strand | V4 V5 V6 V7 V8 &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; | &lt;integer&gt; &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; [1] chr1 10051-10599 * | 53 68 1.0000000 0.924306 1.0000000 [2] chr1 11601-14399 * | 171 181 0.0653982 1.120382 0.0695043 [3] chr1 14551-15249 * | 34 28 0.0166897 1.440023 0.0182155 [4] chr1 15401-17099 * | 73 77 0.1441852 1.124296 0.1513844 [5] chr1 17251-18049 * | 38 64 1.0000000 0.704129 1.0000000 ................... [59579] chrY 59011501-59026949 * | 1413 778 7.55580e-145 2.1538291 4.09978e-144 [59580] chrY 59027151-59033299 * | 552 225 1.81527e-101 2.9094120 8.81781e-101 [59581] chrY 59213451-59214949 * | 75 5 2.58202e-66 17.7885247 1.10346e-65 [59582] chrY 59362851-59363399 * | 25 46 1.00000e+00 0.6445118 1.00000e+00 [59583] chrM 12351-13249 * | 39 1856 1.00000e+00 0.0249193 1.00000e+00 ------- seqinfo: 25 sequences from an unspecified genome; no seqlengths $H3K27me3 GRanges object with 93824 ranges and 5 metadata columns: seqnames ranges strand | V4 V5 V6 V7 V8 &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; | &lt;integer&gt; &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; [1] chr1 31101-31849 * | 41 11 7.52852e-14 4.02644 2.02150e-13 [2] chr1 32601-33349 * | 32 13 4.73028e-07 2.65911 7.00814e-07 [3] chr1 33701-34499 * | 54 23 8.04691e-10 2.53627 1.53203e-09 [4] chr1 34651-35399 * | 40 11 3.12778e-13 3.92823 7.96170e-13 [5] chr1 35651-36349 * | 54 11 9.84610e-23 5.30312 4.90046e-22 ................... [93820] chrM 4751-5899 * | 62 2070 1 0.0323557 1 [93821] chrM 6051-6999 * | 46 1885 1 0.0263619 1 [93822] chrM 7151-10949 * | 187 6820 1 0.0296202 1 [93823] chrM 11101-14399 * | 202 6535 1 0.0333915 1 [93824] chrM 14551-16549 * | 131 3655 1 0.0387181 1 ------- seqinfo: 25 sequences from an unspecified genome; no seqlengths $MLL1 GRanges object with 34003 ranges and 5 metadata columns: seqnames ranges strand | V4 V5 V6 V7 V8 &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; | &lt;integer&gt; &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; [1] chr1 10001-10499 * | 51 63 1.0000000 0.780916 1.0000000 [2] chr1 11901-13049 * | 60 92 1.0000000 0.629126 1.0000000 [3] chr1 16901-17299 * | 31 22 0.0397828 1.359294 0.0557065 [4] chr1 17451-18099 * | 36 49 1.0000000 0.708730 1.0000000 [5] chr1 19851-20799 * | 39 44 1.0000000 0.855040 1.0000000 ................... [33999] chrY 59029651-59030999 * | 91 52 1.48881e-06 1.688156 5.32648e-06 [34000] chrY 59031151-59032099 * | 68 30 3.24751e-09 2.186563 2.14925e-08 [34001] chrY 59032401-59033199 * | 36 70 1.00000e+00 0.496111 1.00000e+00 [34002] chrY 59362951-59363399 * | 85 44 6.37554e-08 1.863548 3.07182e-07 [34003] chrM 1-16549 * | 7206 29637 1.00000e+00 0.234549 1.00000e+00 ------- seqinfo: 25 sequences from an unspecified genome; no seqlengths $UTX GRanges object with 44845 ranges and 5 metadata columns: seqnames ranges strand | V4 V5 V6 V7 V8 &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; | &lt;integer&gt; &lt;integer&gt; &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt; [1] chr1 10051-10449 * | 58 59 0.161707386 1.127780 0.178211140 [2] chr1 13301-13899 * | 32 35 0.349485362 1.048891 0.373021173 [3] chr1 14551-15249 * | 26 28 0.325894887 1.065279 0.348971602 [4] chr1 16851-17799 * | 47 76 1.000000000 0.709467 1.000000000 [5] chr1 19101-20649 * | 70 53 0.000421408 1.515202 0.000653707 ................... [44841] chrY 59028701-59029749 * | 40 32 1.17852e-02 1.434030 1.48488e-02 [44842] chrY 59030051-59030599 * | 42 24 1.55131e-05 2.007642 3.07036e-05 [44843] chrY 59030851-59032599 * | 85 59 6.65690e-06 1.652780 1.41208e-05 [44844] chrY 59362901-59363399 * | 45 45 1.57970e-01 1.147224 1.74366e-01 [44845] chrM 1-16549 * | 4103 29637 1.00000e+00 0.158824 1.00000e+00 ------- seqinfo: 25 sequences from an unspecified genome; no seqlengths . | . 3. Make coverage plot . | Before depict coverage plot, it is important to understand the structure of the peaks objects: make sure you know what each column means. The output of ‘sicer’ is chromosome (V1; seqnames), start (V2; ranges), end (V2; ranges), strand (V3; strand), ChIP_signal (V4), Input_signal (V5), p-val (V6), fold change (V7), fdr (V8), in that order. This means that to draw a coverage plot, you will need values from V4 or V7. covplot(peaks[[\"H3K4me3\"]], weightCol=\"V4\") # To save the plot, use 'Export' in the 'Plots' section on the right. covplot(peaks[[\"H3K27me3\"]], weightCol=\"V4\") covplot(peaks[[\"MLL1\"]], weightCol=\"V4\") covplot(peaks[[\"UTX\"]], weightCol=\"V4\") # Can be selected specific chromosomes as follow: covplot(peaks[[\"H3K4me3\"]], weightCol=\"V4\", chrs=c(\"chr3\", \"chr4\")) . | Output: . | . 4. Profile of ChIP peaks binding to TSS regions . | For calculating the profile of ChIP peaks binding to TSS regions, prepare the TSS regions, which are defined as the flanking sequence of the TSS sites. Then align the peaks that are mapping to these regions, and generate the tagMatrix: . txdb &lt;- TxDb.Hsapiens.UCSC.hg19.knownGene promoter &lt;- getPromoters(TxDb=txdb, upstream=3000, downstream=3000) tagMatrixList &lt;- lapply(as.list(peaks), getTagMatrix, windows=promoter) . | Output: &gt; txdb &lt;- TxDb.Hsapiens.UCSC.hg19.knownGene &gt; promoter &lt;- getPromoters(TxDb=txdb, upstream=3000, downstream=3000) &gt; tagMatrixList &lt;- lapply(as.list(peaks), getTagMatrix, windows=promoter) &gt;&gt; preparing start_site regions by gene... 2024-05-21 12:41:47 &gt;&gt; preparing tag matrix... 2024-05-21 12:41:47 &gt;&gt; preparing start_site regions by gene... 2024-05-21 12:41:56 &gt;&gt; preparing tag matrix... 2024-05-21 12:41:56 &gt;&gt; preparing start_site regions by gene... 2024-05-21 12:42:01 &gt;&gt; preparing tag matrix... 2024-05-21 12:42:01 &gt;&gt; preparing start_site regions by gene... 2024-05-21 12:42:06 &gt;&gt; preparing tag matrix... 2024-05-21 12:42:06 . | Heatmap of ChIP binding to TSS regions # Multiplot peakHeatmap(peaks, TxDb = txdb, nbin = 100, upstream = 3000, downstream = 3000, by = \"gene\", type = \"start_site\", palette = \"Reds\") # Individual plot peakHeatmap(peaks[[\"PeakName\"]], TxDb = txdb, nbin = 100, upstream = 3000, downstream = 3000, by = \"gene\", type = \"start_site\", palette = \"Reds\") . | In these arguments, . | Parameter | Description | . | peaks | Path to the peak file or a GRanges object containing peak information. | . | TxDb | Transcript Database (TxDb) object. | . | nbin | Number of bins to use for drawing the heatmap. Determines the resolution of the heatmap. The lower the nbin value, the faster the processing, but the lower the image quality. | . | upstream, downstream | Distance upstream and downstream of the TSS, respectively. | . | by | Category to base the peak heatmap on. Possible values are gene, transcript, exon, intron, 3UTR, 5UTR, and UTR. | . | type | Specifies genomic regions to heatmap. Possible values are start_site(tss), end_site(tes), body(gene body). | . | palette | Color palette for the heatmap. | . | . | Output: &gt; peakHeatmap(peaks, TxDb = txdb, nbin = 100, upstream = 3000, downstream = 3000, by = \"gene\", type = \"start_site\", palette = \"Reds\") &gt;&gt; preparing promoter regions... 2024-05-21 14:38:23 &gt;&gt; preparing tag matrix... 2024-05-21 14:38:23 &gt;&gt; binning method is used...2024-05-21 14:38:23 &gt;&gt; preparing start_site regions by gene... 2024-05-21 14:38:23 &gt;&gt; preparing tag matrix by binning... 2024-05-21 14:38:23 &gt;&gt; binning method is used...2024-05-21 14:38:40 &gt;&gt; preparing start_site regions by gene... 2024-05-21 14:38:40 &gt;&gt; preparing tag matrix by binning... 2024-05-21 14:38:40 &gt;&gt; binning method is used...2024-05-21 14:38:47 &gt;&gt; preparing start_site regions by gene... 2024-05-21 14:38:47 &gt;&gt; preparing tag matrix by binning... 2024-05-21 14:38:47 &gt;&gt; binning method is used...2024-05-21 14:38:51 &gt;&gt; preparing start_site regions by gene... 2024-05-21 14:38:51 &gt;&gt; preparing tag matrix by binning... 2024-05-21 14:38:51 &gt;&gt; generating figure... 2024-05-21 14:38:54 &gt;&gt; done... 2024-05-21 14:38:54 . | Average Profile of ChIP peaks binding to TSS region . # Multiplot plotAvgProf(tagMatrixList, xlim=c(-3000, 3000), xlab=\"Genomic Region (5'-&gt;3')\", ylab = \"Read Count Frequency\") # Selected plot plotAvgProf(tagMatrixList[c(\"H3K4me3\", \"MLL1\")], xlim=c(-3000, 3000), xlab=\"Genomic Region (5'-&gt;3')\", ylab = \"Read Count Frequency\") # Selected plot plus confidence interval estimated by bootstrap method plotAvgProf(tagMatrixList[c(\"H3K4me3\", \"MLL1\")], xlim=c(-3000, 3000), xlab=\"Genomic Region (5'-&gt;3')\", ylab = \"Read Count Frequency\", conf = 0.95, resample = 1000) # facet plotAvgProf(tagMatrixList, xlim=c(-3000, 3000), xlab=\"Genomic Region (5'-&gt;3')\", ylab = \"Read Count Frequency\", conf = 0.95, resample = 500, facet = \"row\") . | Output: &gt; plotAvgProf(tagMatrixList[c(\"H3K4me3\", \"MLL1\")], xlim=c(-3000, 3000), xlab=\"Genomic Region (5'-&gt;3')\", ylab = \"Read Count Frequency\",conf = 0.95, resample = 1000) &gt;&gt; plotting figure... 2024-05-21 16:15:42 &gt;&gt; Running bootstrapping for tag matrix... 2024-05-21 16:17:15 &gt;&gt; Running bootstrapping for tag matrix... 2024-05-21 16:17:34 . | . Enter your code: Copy Clear Adding your own Transcript Database(Txdb) . | Species that are less commonly studied often do not have associated database packages in R. In such cases, it is possible to extract the Txdb simply using makeTxDbFromGFF function from the GTF file. In this context, I will use the rice genome as an example to demonstrate the extraction method. gtf_file &lt;- \"/Users/jchoi/Desktop/IRGSP.gtf\" txdb &lt;- makeTxDbFromGFF(gtf_file) . | . 5. Peak Annotation . | The annotatePeak function in the ChIPseeker package is used to annotate peaks in ChIP-seq data analysis. The function identifies and annotates where peaks map to functional elements of the genome, such as promoters, UTRs (5 and 3), exons, introns, intergenic, and downstream regions. peakAnnoList &lt;- lapply(peaks, annotatePeak, TxDb=txdb, tssRegion=c(-3000, 3000), addFlankGeneInfo=TRUE, flankDistance=5000, annoDb=\"org.Hs.eg.db\") peakAnnoList # Check results . | In these arguments, . | Parameter | Description | . | peaks | The list of peak files provided as the first argument to the lapply function. | . | TxDb | Transcript Database (TxDb) object. | . | tssRegion | The distance range from the TSS. The default is c(-3000, 3000), which means peaks will be annotated within 3000 base pairs upstream and downstream of the TSS. | . | addFlankGeneInfo | Specifies whether to add information about genes flanking the peaks. Setting this to TRUE will include information about genes located upstream and downstream of the peaks. | . | flankDistance | Specifies the distance upstream and downstream to include when adding flanking gene information. The default is 5000 base pairs. | . | annoDb | Specifies annotation database. | . | palette | Color palette for the heatmap. | . | . | . Enter your code: Copy Clear . | Output: . &gt; peakAnnoList &lt;- lapply(peaks, annotatePeak, TxDb=txdb, tssRegion=c(-3000, 3000), + addFlankGeneInfo=TRUE, flankDistance=5000, annoDb=\"org.Hs.eg.db\") &gt;&gt; preparing features information... 2024-05-21 16:51:05 &gt;&gt; identifying nearest features... 2024-05-21 16:51:06 &gt;&gt; calculating distance from peak to TSS... 2024-05-21 16:51:06 &gt;&gt; assigning genomic annotation... 2024-05-21 16:51:06 &gt;&gt; adding gene annotation... 2024-05-21 16:51:17 'select()' returned 1:many mapping between keys and columns &gt;&gt; adding flank feature information from peaks... 2024-05-21 16:51:18 &gt;&gt; assigning chromosome lengths 2024-05-21 16:51:26 &gt;&gt; done... 2024-05-21 16:51:26 &gt; peakAnnoList $H3K4me3 Annotated peaks generated by ChIPseeker 59582/59583 peaks were annotated Genomic Annotation Summary: Feature Frequency 9 Promoter (&lt;=1kb) 26.79332684 10 Promoter (1-2kb) 3.96092780 11 Promoter (2-3kb) 3.49434393 4 5' UTR 0.47665402 3 3' UTR 1.22855896 1 1st Exon 0.64113323 7 Other Exon 1.96032359 2 1st Intron 8.64355007 8 Other Intron 14.83501729 6 Downstream (&lt;=300) 0.07384781 5 Distal Intergenic 37.89231647 ====================(skip)======================== $UTX Annotated peaks generated by ChIPseeker 44844/44845 peaks were annotated Genomic Annotation Summary: Feature Frequency 9 Promoter (&lt;=1kb) 3.1375435 10 Promoter (1-2kb) 3.3850682 11 Promoter (2-3kb) 3.1643029 4 5' UTR 0.4147712 3 3' UTR 1.2576933 1 1st Exon 0.3255731 7 Other Exon 3.0171260 2 1st Intron 10.2600125 8 Other Intron 27.2277228 6 Downstream (&lt;=300) 0.1204174 5 Distal Intergenic 47.6897690 . | Save annotated peaks as the csv format as follow: . write.csv(peakAnnoList[[\"H3K4me3\"]], \"Peaked_H3K4me3.csv\") write.csv(peakAnnoList[[\"H3K27me3\"]], \"Peaked_H3K27me3.csv\") write.csv(peakAnnoList[[\"MLL1\"]], \"Peaked_MLL1.csv\") write.csv(peakAnnoList[[\"UTX\"]], \"Peaked_UTX.csv\") . | . 6. Visulize genomic annotation . | Finally, I will discuss and visualize where the annotated peaks are located in the genomic regions, including promoters, UTRs (5 and 3), exons, introns, intergenic, and downstream regions. | Pie plot: This funtion does not provide drawing multiplot. plotAnnoPie(peakAnnoList[[\"PeakName\"]]) # PeakName is an assigned peak name using the list function # For example plotAnnoPie(peakAnnoList[[\"H3K4me3\"]]) # Ouput . Output: . | Bar plot plotAnnoBar(peakAnnoList) # Multiplot, output plotAnnoBar(peakAnnoList[[\"PeakName\"]]) # Indivisual plot . Output: . | Vennpie plot: This funtion does not provide drawing multiplot. vennpie(peakAnnoList[[\"PeakName\"]]) . | UpSet plot: This funtion does not provide drawing multiplot. upsetplot(peakAnnoList[[\"PeakName\"]], vennpie = TRUE) # TRUE/FALSE: with/without vennpie, output . Output: . | Distribution of TF-binding loci relative to TSS: The distance from the peak (binding site) to the TSS of the nearest gene is calculated by annotatePeak and reported in the output. plotDistToTSS(peakAnnoList) # output plotDistToTSS(peakAnnoList[[\"PeakName\"]]) . Output: . | . Enter your code: Copy Clear . Comments . | The functions bdgdiff in MACS3 and sicer-df in SICER2 produce results using the same annotation method (annotatePeak). | Although HOMER's annotatePeaks.pl can be used for annotation, it is rarely employed currently. | Peak distribution analysis, including heatmaps and average plots, can be effectively performed with both deeptools and ngsplot. I recommend ngsplot for optimal results. | Peak feature analysis (Section 6, visualization) is seldom used unless investigating a novel transcription factor via ChIP-seq. | Despite detailed peak analysis, the current trend focuses on identifying meaningful genes from the detected peaks. | . ",
    "url": "/docs/ChIPSeq/PeakAnnotation_MANUAL/#step-by-step-running-guide-chipseeker",
    
    "relUrl": "/docs/ChIPSeq/PeakAnnotation_MANUAL/#step-by-step-running-guide-chipseeker"
  },"125": {
    "doc": "Exploring ChIP-seq Data with ChIPseeker",
    "title": "Citation",
    "content": "ngsplot . | Yu, G., Wang, L. G., &amp; He, Q. Y. (2015). ChIPseeker: an R/Bioconductor package for ChIP peak annotation, comparison and visualization. Bioinformatics, 31(14), 2382-2383. DOI | . ",
    "url": "/docs/ChIPSeq/PeakAnnotation_MANUAL/#citation",
    
    "relUrl": "/docs/ChIPSeq/PeakAnnotation_MANUAL/#citation"
  },"126": {
    "doc": "Exploring ChIP-seq Data with ChIPseeker",
    "title": "Exploring ChIP-seq Data with ChIPseeker",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/ChIPSeq/PeakAnnotation_MANUAL/",
    
    "relUrl": "/docs/ChIPSeq/PeakAnnotation_MANUAL/"
  },"127": {
    "doc": "Data Analysis - RNA-seq",
    "title": "Data Analysis - RNA-seq",
    "content": "RNA-seq analysis is a powerful technique used to examine the transcriptome of organisms, providing insights into gene expression patterns and functional genomics. This method enables the identification of differentially expressed genes (DEGs) under various conditions, offering a comprehensive view of biological responses and regulatory mechanisms. Key steps in RNA-seq analysis include quality control, alignment, quantification, and DEG analysis, followed by downstream analyses such as visualization, correlation studies, heatmaps, and pathway enrichment analyses like KEGG and GO. These steps collectively facilitate a deeper understanding of the complex molecular landscapes within biological systems. ",
    "url": "/docs/RNASeq",
    
    "relUrl": "/docs/RNASeq"
  },"128": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "File Conversion and Management with SAMtools",
    "content": "The reads mapped onto the reference genome generate substantial data files in SAM format, ranging from 20 to 30 GB per sample, which could result in prolonged further analysis durations. SAMtools that is coded in python can be converted SAM into BAM to fast access the sequence data and analyze the sequence depth. This protocol was created based on SAMtools version 1.12 running on a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes Python version 3.8.5, SciPy version 1.6.2, NumPy version 1.20.1, and pySam version 0.16.0.1 under macOS 12.4 OS environment.** The tool offers a variety of functions to analyze sequencing data, but this part will cover only the most commonly used features. ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#file-conversion-and-management-with-samtools",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#file-conversion-and-management-with-samtools"
  },"129": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Installation samtools",
    "content": ". To install HISAT2 via homebrew, type the following commands: . $ brew install Samtools . ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#installation-samtools",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#installation-samtools"
  },"130": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Stats - Check the mapping rate",
    "content": "SAMtools stats collects statistics from SAM/BAM files and outputs in a text format. The output can be visualized graphically using multiqc. Use the following command to perform the stats function of samtools: . $ samtools stats -@ &lt;int&gt; &lt;input sam file.sam&gt; &gt; &lt;output file.stats&gt; . In these commands, . | -@ &lt;int&gt;: specifies core numbers used in this work. | &lt;input.sam&gt;: specifies input file as a SAM format. | &gt; &lt;output.stats&gt;: specifies output file as a stats format. &gt; symbol must appear before the &lt;output file.txt&gt; syntax. | . ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#stats---check-the-mapping-rate",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#stats---check-the-mapping-rate"
  },"131": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Example code (Results are not printed)",
    "content": "$ samtools stats -@ 10 /Users/jchoi/Desktop/SAM/Unt_UTX.sam &gt; /Users/jchoi/Desktop/SAM/Unt_UTX.sam.stats . | The resulting stats file can be opened text editors and it consists of alignment information: # This file was produced by samtools stats (1.12+htslib-1.12) and can be plotted using plot-bamstats # This file contains statistics for all reads. # The command line was: stats -@ 10 /Users/jchoi/Desktop/SAM/Unt_UTX.sam # CHK, Checksum [2]Read Names [3]Sequences [4]Qualities # CHK, CRC32 of reads which passed filtering followed by addition (32bit overflow) CHK 6b2cf2a8 0ec11f5c a187d603 # Summary Numbers. Use `grep ^SN | cut -f 2-` to extract this part. SN raw total sequences: 45639340 # excluding supplementary and secondary reads SN filtered sequences: 0 SN sequences: 45639340 SN is sorted: 0 SN 1st fragments: 22819670 SN last fragments: 22819670 SN reads mapped: 40370690 SN reads mapped and paired: 40243620 # paired-end technology bit set + both mates mapped SN reads unmapped: 5268650 SN reads properly paired: 36659322 # proper-pair bit set SN reads paired: 45639340 # paired-end technology bit set SN reads duplicated: 0 # PCR or optical duplicate bit set SN reads MQ0: 227872 # mapped and MQ=0 SN reads QC failed: 0 SN non-primary alignments: 0 SN supplementary alignments: 0 SN total length: 4562450957 # ignores clipping SN total first fragment length: 2281908536 # ignores clipping SN total last fragment length: 2280542421 # ignores clipping SN bases mapped: 4038619347 # ignores clipping SN bases mapped (cigar): 3942644569 # more accurate ................... | . ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#example-code-results-are-not-printed",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#example-code-results-are-not-printed"
  },"132": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Export stats report via multiqc",
    "content": "The resulting stats files under the presence of the same folder can be compared and analyzed collectively with multiqc, use the following command: . $ multiqc ./ . ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#export-stats-report-via-multiqc",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#export-stats-report-via-multiqc"
  },"133": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "View - Convert to BAM file or View SAM or BAM file",
    "content": "SAMtools view, with no options or regions specified, prints all alignments in the specified input alignment file (in SAM, BAM, or CRAM format) to standard output in SAM format (with no header). Ultimately, the view function can convert text-format SAM files into binary BAM files and vice versa, enabling faster and more detailed manipulation of sequencing reads. Use the following command to perform the view function of samtools: . # For explore the strucure of them. $ samtools view &lt;SAM or BAM files&gt; | head -&lt;int&gt; ## Usage is the same as the 'gzip' and 'cat' commands. # For converting BAM file. $ samtools view -b -q &lt;int&gt; -f &lt;FLAG&gt; -F &lt;FLAG&gt; -@ &lt;int&gt; &lt;input.sam&gt; &gt; &lt;output.bam&gt; . In these commands, . | Parameter | Description | . | -b option | specifies output file format as a SAM. | . | -q &lt;int&gt; option | skip alignments with MAPQ smaller than . **Critical option,** A MAPQ &gt; 30 is considered the highest quality. | . | -f &lt;FLAG&gt; option | only output alignments with all bits set in &lt;FLAG&gt;. | . | -F &lt;FLAG&gt; option | Do not include output alignments with any bits set in &lt;FLAG&gt;. FLAG field refers as bellow table. -f and -F options cannot be used at the same time (mutually exclusive). | . | -@ &lt;int&gt; option | specifies thread numbers &lt;int&gt;. | . | &lt;input.sam&gt; | specifies input sam file. | . | &gt; &lt;output.bam&gt; | specifies output bam file. ‘&gt;’ symbol must appear before the &lt;output.bam&gt; syntax. | . There are no parameters when viewing or converting a specific region, only the following format would be used: chr:start-end. For more information such as global parameter, refers to samtools’ guidelines. ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#view---convert-to-bam-file-or-view-sam-or-bam-file",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#view---convert-to-bam-file-or-view-sam-or-bam-file"
  },"134": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "FLAG field table",
    "content": "| Bit | Flag | Description | . | 0 | 0x1 | read paired | . | 1 | 0x2 | read mapped in proper pair | . | 2 | 0x4 | read unmapped | . | 3 | 0x8 | mate unmapped | . | 4 | 0x10 | read reverse strand | . | 5 | 0x20 | mate reverse strand | . | 6 | 0x40 | first in pair | . | 7 | 0x80 | second in pair | . | 8 | 0x100 | not primary alignment | . | 9 | 0x200 | read fails platform/vendor quality checks | . | 10 | 0x400 | read is PCR or optical duplicate | . | 11 | 0x800 | supplementary alignment | . ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#flag-field-table",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#flag-field-table"
  },"135": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Example code (Results are not printed)",
    "content": "$ samtools view -b -@ 20 shCon_Unt.sam &gt; ~/Desktop/BAM/shCon_Unt.bam $ samtools view -b -@ 20 shCon_H2O2.sam &gt; ~/Desktop/BAM/shCon_H2O2.bam $ samtools view -b -@ 20 shCon_NP.sam &gt; ~/Desktop/BAM/shCon_NP.bam # Convert to BAM file, which has a MAPQ score &gt; 40 and marked FLAG field corresponded to 0x1 and 0x2. $ samtools view -b -q 40 -f 0x1,0x2 -@ 20 shControl.sam &gt; shControl.bam # Convert to BAM file from SAM file, which has a MAPQ score &gt; 30 and excepts FLAG field corresponded to 0x8. $ samtools view -b -q 30 -F 0x8 -@ 20 shNFIB.sam &gt; shNFIB.bam . Enter your code: Copy Clear ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#example-code-results-are-not-printed-1",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#example-code-results-are-not-printed-1"
  },"136": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Rmdup - Remove duplicative reads",
    "content": "SAMtools rmdup removes potential PCR duplicates (only retain the pair with highest mapping quality). The official manual describes “This command is obsolete. Use markdup instead.”, so it probably not operate in lastly versions. Use the following command to perform the rmdup function of samtools: . $ samtools rmdup -s &lt;input.bam&gt; &lt;output.bam&gt; . In these commands, . | -s/-S option: -s is responsible for pair-end mode, whereas -S is for single-end mode. | &lt;input.bam&gt;: specifies input data. | &lt;output.bam&gt;: specifies output data. | . the rmdupfunction does not provide multi-threads processing. ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#rmdup---remove-duplicative-reads",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#rmdup---remove-duplicative-reads"
  },"137": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Example code and output",
    "content": "$ samtools rmdup -s shCon_Unt.bam rmdup.shCon_Unt.bam $ samtools rmdup -s shCon_H2O2.bam rmdup.shCon_H2O2.bam $ samtools rmdup -s shCon_NP.bam rmdup.shCon_NP.bam . Enter your code: Copy Clear . | When rmdup finishes running, it prints messages summarizing what happened. After operation of rmdup, terminal appears to as follows, [bam_rmdupse_core] 590 / 46146253 = 0.0000 in library . | . ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#example-code-and-output",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#example-code-and-output"
  },"138": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Sort - Sort reads by position or name",
    "content": "SAMtools sort function sorts BAM files by leftmost coordinates of references (chromosome position, no option) or by read name (-noption). In general, RNA-seq for feature counting (htseq-count) uses the -n option to sort by read name, while ChIP-seq for visualization or a BED file conversion does not use the -n option to sort by position. Use the following command to perform the sort function of samtools: . $ samtools sort -n -@ &lt;int&gt; &lt;input.bam&gt; -o &lt;output.bam&gt; . In these commands, . | -n option: sort by name, if want to sort by position, remove -n. | -@ option: specifies thread numbers &lt;int&gt;. | &lt;input.bam&gt;: specifies input file. | -o &lt;output.bam&gt;: specifies output file. | . ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#sort---sort-reads-by-position-or-name",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#sort---sort-reads-by-position-or-name"
  },"139": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Example code and output",
    "content": "# with -n option $ samtools sort -n -@ 20 rmdup.shCon_Unt.bam -o sort.shCon_Unt.bam $ samtools sort -n -@ 20 rmdup.shCon_H2O2.bam -o sort.shCon_H2O2.bam $ samtools sort -n -@ 20 rmdup.shCon_NP.bam -o sort.shCon_NP.bam # with no option $ samtools sort -@ 20 /home/jh/Desktop/Bam/Rmdup_shControl.bam -o /home/jh/Desktop/Bam/Sort_shControl.bam $ samtools sort -@ 20 /home/jh/Desktop/Bam/Rmdup_shNFIB.bam -o /home/jh/Desktop/Bam/Sort_shNFIB.bam . Enter your code: Copy Clear . | When sort finishes running, it prints messages summarizing what happened. After operation of sort, terminal appears to as follows, [bam_sort_core] merging from 20 files and 1 in-memory blocks... | . ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#example-code-and-output-1",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#example-code-and-output-1"
  },"140": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Index - for ChIP-seq analysis",
    "content": "SAMtools index function Indexes a coordinate-sorted BGZIP-compressed SAM, BAM, or CRAM file for fast random access. This function requires a BAM file sorted by position. Use the following command to perform the index function of samtools: . $ samtools index &lt;input.bam&gt; . In these commands, . | &lt;input.bam&gt;: specifies input file. | . This command has no parameters that specifically define the output. The resulting bai file is gennerated in the input folder. Preferably, the sorted BAM file and the bai file should exist in the same directory for further analysis. ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#index---for-chip-seq-analysis",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#index---for-chip-seq-analysis"
  },"141": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Example code (Results are not printed)",
    "content": "$ samtools index /home/jh/Desktop/Bam/Sort_input.bam $ samtools index /home/jh/Desktop/Bam/Sort_shControl.bam . ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#example-code-results-are-not-printed-2",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#example-code-results-are-not-printed-2"
  },"142": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Coverage - Check the sequencing depth",
    "content": "SAMtools coverage function computes the coverage at each position or region and draws an ASCII-art histogram or tabulated text. The coverage is defined as the percentage of positions within each bin with at least one base aligned against it. This function requires a BAM file sorted by position and a bai file. Use the following command to perform the coverage function of samtools: . $ samtools coverage -A -r &lt;region&gt; &lt;input.bam&gt; . In these commands, . | -A option: Show only ASCII characters in histogram using colon and fullstop for full and half height characters. | -r &lt;region&gt;: Show specified region. Format: chr:start-end. | &lt;input.bam&gt;: specifies input file. | . ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#coverage---check-the-sequencing-depth",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#coverage---check-the-sequencing-depth"
  },"143": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Example code and output",
    "content": "# Coverage across all chromosome without ASCII histogram $ samtools coverage sort_MA_coverage.bam # Coverage with ASCII histogram on chr1 $ samtools coverage -A -r chr1 sort_MA_coverage.bam . | When coverage with no option finishes running, it prints messages summarizing what happened. #rname numreads covbases coverage meandepth meanbaseq meanmapq 1 1582614 6662248 11.1823 2.66237 36.3 53.9 2 1847826 7551970 12.6625 3.10498 36.3 56.5 3 2100124 8084882 12.9093 3.36035 36.3 54.9 4 1195390 9339824 11.9598 1.5328 36.3 54.2 5 2054896 8817714 12.1623 2.84217 36.3 45 6 1548488 6936500 11.509 2.57578 36.3 53 7 1837930 8069184 10.8628 2.48051 36.3 54.7 8 1513826 6812219 12.5444 2.79332 36.3 54.4 9 1194217 6236630 11.0461 2.1184 36.3 53.5 10 1347613 5541625 12.2006 2.972 36.3 52.1 11 1352685 5446330 11.9739 2.97988 36.3 55.7 12 1125210 5623379 11.4336 2.29375 36.3 52.8 13 1427718 6164305 11.8122 2.74218 36.3 54.2 14 1581018 5558226 10.5549 3.00721 36.3 51.7 15 1194286 5929981 12.3437 2.49079 36.3 55.8 16 1721170 6981746 12.6329 3.12217 36.3 56.2 17 1239184 6120904 11.4493 2.32304 36.3 54.6 18 1010858 5168646 10.1299 1.98516 36.3 51.8 19 2085292 6031878 12.4498 4.31301 36.3 57.3 20 1839414 6841016 12.3928 3.33999 36.3 57.2 21 1744680 6044533 13.1592 3.80718 36.3 57.4 22 1028090 5238163 13.3855 2.63309 36.3 54.9 23 1436699 5811855 12.5734 3.11603 36.3 51.5 24 911126 4395211 10.4219 2.1645 36.3 55.8 25 1158715 4763344 12.7016 3.09503 36.3 55.1 MT 3248278 16596 100 19679.7 36.3 60 . | . Enter your code: Copy Clear . | When coverage with -A option finishes running, it prints messages summarizing what happened. 1 (59.58Mbp) &gt; 25.52% |. : : : | Number of reads: 1582614 &gt; 22.69% |: : : : : . : | (288307 filtered) &gt; 19.85% |: : . : : : .: .: . | Covered bases: 6.66Mbp &gt; 17.02% |:: . : :: . : : : : :: :. :.:: .:::| Percent covered: 11.18% &gt; 14.18% |:: : : . :. :: : : . : : :: .: .::: :: :. ::. : ::::: ::::| Mean coverage: 2.66x &gt; 11.34% |:: :: : .:.: . :: :: . : :.: : ::: : :: .. :: :. ::::: :: ::.:::.: ::::: ::::| Mean baseQ: 36.3 &gt; 8.51% |:: :: : : ::::.::.: :: :: : : ::: ..: :: :::: ::::: : :: : .. :: :: :::::.:: :::::::: ::::: : . ::::| Mean mapQ: 53.9 &gt; 5.67% |:: :: :.:: ::::::::: :: .::: :. : .::: ::: ::... :::: :::::.::::. :.:: ::.:: :. :::.:: ::::::::::: :::::::: ::::: :. ::::::| &gt; 2.84% |:::.:: .. ::::.:::::::::.:::..::::.::: : ::::..::::::::: ::::: :::::::::::: :::::::::: ::: :::::: :::::::::::...::::::::::::::.:: ::::::| Histo bin width: 425.6Kbp &gt; 0.00% |:::::::::::.:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::.::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::| Histo max bin: 28.359% 1 4.26M 8.51M 12.77M 17.02M 21.28M 25.53M 29.79M 34.04M 38.30M 42.56M 46.81M 51.07M 55.32M 59.58M . | . ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#example-code-and-output-2",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#example-code-and-output-2"
  },"144": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Merge",
    "content": "merge function combines multiple sorted alignment files, producing a single sorted output file that contains all the input records and maintains the existing sort order. Use the following command to perform the merge function of samtools: . $ samtools merge -@ &lt;int&gt; &lt;output.bam&gt; &lt;input-1.bam&gt;...&lt;input-N.bam&gt; . In these commands, . | -@ option: specifies thread numbers &lt;int&gt;. | &lt;output.bam&gt;: specifies output file. | &lt;input.bam&gt;...&lt;input-N.bam&gt;: specifies input file. | . ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#merge",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#merge"
  },"145": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Example code (Results are not printed)",
    "content": "$ samtools merge -@ 20 merged_H3K4me3.bam sort.H3K4me3_rep1.bam sort.H3K4me3_rep2.bam sort.H3K4me3_rep3.bam # After merge, performs sort and index. $ samtools sort -@ 20 merged_H3K4me3.bam -o sort.merged_H3K4me3.bam $ samtools index sort.merged_H3K4me3.bam . ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#example-code-results-are-not-printed-3",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#example-code-results-are-not-printed-3"
  },"146": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "Citation",
    "content": "Samtools . | Li, H., Handsaker, B., Wysoker, A., Fennell, T., Ruan, J., Homer, N., ... &amp; 1000 Genome Project Data Processing Subgroup. (2009). The sequence alignment/map format and SAMtools. bioinformatics, 25(16), 2078-2079. DOI | . ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/#citation",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/#citation"
  },"147": {
    "doc": "File Conversion and Management with SAMtools",
    "title": "File Conversion and Management with SAMtools",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/DataProcess/SAMtools_MANUAL/",
    
    "relUrl": "/docs/DataProcess/SAMtools_MANUAL/"
  },"148": {
    "doc": "Peak Detection - SICER2",
    "title": "Broad Peak Detection in ChIP-seq Data Using SICER2",
    "content": "Chromatin immunoprecipitation combined with high-throughput sequencing (ChIP-seq) can be used to map binding sites of a protein of interest in the genome. The resulting peaks data usually occupy broad chromatin domains and result in diffuse patterns that make it difficult to identify signal enrichment. SICER, a spatial clustering approach for the identification of peaks-enriched regions, was developed for calling broad peaks from ChIP-seq data. This tool is used to find peaks whether target binds to the interest genome loci by using sicer command and also can be used to compare peaks between two groups by using sicdr_df command. This protocol was created based on SICER2 version 1.0.3 running on a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes Python version 3.8.5, SciPy version 1.6.2, NumPy version 1.20.1, and Xcode Command Line Tools version 2406 under macOS 12.4 OS environment. ",
    "url": "/docs/ChIPSeq/SICER2_MANUAL/#broad-peak-detection-in-chip-seq-data-using-sicer2",
    
    "relUrl": "/docs/ChIPSeq/SICER2_MANUAL/#broad-peak-detection-in-chip-seq-data-using-sicer2"
  },"149": {
    "doc": "Peak Detection - SICER2",
    "title": "Installation SICER2",
    "content": ". To install SICER2 via Pypi, use the following command: . $ pip install sicer2 . Requirements . To use sicer2 you need: . | Python &gt; 3.0 and its libraries scipy and numpy. | C compiler via Xcode command line tools (in macOS) | BedTools . | To install BedTools via homebrew, type the following command: $ brew install bedtools . | . | . ",
    "url": "/docs/ChIPSeq/SICER2_MANUAL/#installation-sicer2",
    
    "relUrl": "/docs/ChIPSeq/SICER2_MANUAL/#installation-sicer2"
  },"150": {
    "doc": "Peak Detection - SICER2",
    "title": "bamToBed: Convert BAM into BED",
    "content": ". | bamtobed function of the bedtools is a conversion utility that converts sequence alignments in BAM format into BED, BED12, and/or BEDPE records. The BED is the most commonly used file format for peak-call analysis. Use the following command to convert BAM into BED with bamtobed: . $ bedtools bamtobed -i &lt;input.BAM&gt; &gt; &lt;output.bed&gt; . | In these commands, . | -i option: Running command | &lt;input.BAM&gt;: Specifies input bam file. | &gt; &lt;output.bed&gt;: Specifies output bed file. &gt; symbol must appear before the &lt;output.bed&gt; syntax. | . | . ",
    "url": "/docs/ChIPSeq/SICER2_MANUAL/#bamtobed-convert-bam-into-bed",
    
    "relUrl": "/docs/ChIPSeq/SICER2_MANUAL/#bamtobed-convert-bam-into-bed"
  },"151": {
    "doc": "Peak Detection - SICER2",
    "title": "Example Code (Results are not printed)",
    "content": ". | Here is an example command to perform bamtobed: . $ bedtools bamtobed -i Sort_IPT.bam &gt; /Users/jchoi/Desktop/BED/Sort_IPT.bed $ bedtools bamtobed -i Sort_shCtrl.bam &gt; /Users/jchoi/Desktop/BED/Sort_shCtrl.bed . | . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/SICER2_MANUAL/#example-code-results-are-not-printed",
    
    "relUrl": "/docs/ChIPSeq/SICER2_MANUAL/#example-code-results-are-not-printed"
  },"152": {
    "doc": "Peak Detection - SICER2",
    "title": "Running SICER2",
    "content": ". | Use the following command to perform peak-call analysis with sicer2: . $ sicer -t &lt;TargetFile.bed&gt; -c &lt;ControlFile.bed&gt; -s &lt;speciesBuild&gt; -o &lt;outputFolder&gt; \\ -w &lt;int&gt; -f &lt;int&gt; -g &lt;int&gt; -e &lt;int&gt; -fdr &lt;int&gt; -cpu &lt;int&gt; . | In these commands, . | Parameter | Description | . | -t &lt;TargetFile.bed&gt; | Specifies the target data. Possible data type is BAM or BED (recommended). | . | -c &lt;ControlFile.bed&gt; | Specifies the control data (input). Possible data type is BAM or BED (recommended). | . | -s &lt;speciesBuild&gt; | Specifies the reference genome of the species to apply to the analysis (e.g. -s hg38, -s mm10).See the GenomeData.py file for available species. If no species is available, you can add own genome data (see Adding Your Own Species). | . | -o &lt;outputFolder&gt; | Specifies output folder, which includes narrow peaks, score, and peaks BED. | . | -w &lt;int&gt; | Specifies window size (bp) to determine SICER resolution (Default: 200). | . | -f &lt;int&gt; | Specifies the amount of shift from the beginning of a read to the center of the DNA fragment (bp) represented by the read (Default: 150). | . | -g &lt;int&gt; | Specifies the minimum length of a gap such that neighboring window is an island. the -f value must be a multiple of the window size (Default: 600). | . | -e &lt;int&gt; | Specifies E-value (when no control library is provided) (Default: 1000). | . | -fdr &lt;int&gt; | Specifies an FDR cutoff (Default: 0.05) | . | -cpu &lt;int&gt; | The number of CPU cores SICER program will use when executing multi-processing tasks. | . | . CRITICAL COMMENTS . The efficiency of ChIP-seq is highly dependent on the quality of the antibodies, but even with high-quality antibodies, results often show substantial noise and background interference. Under such situations, it is important for users to adjust the settings of the SICER algorithm to fit their specific experiments. Although these adjustments are not universally obligatory, it is generally advisable to adopt certain parameter settings in particular scenarios to enhance efficiency and reduce processing time as follows: . | If the bigwig file exhibits low noise levels and strong peak intensities, it is advisable to use the default parameters, particularly when analyzing antibodies related to the histone activation. However, for more detailed and precise observations, adjusting the parameters to include -w 50 -g 100 is recommended. This adjustment helps enhance the resolution of the data while minimizing the inclusion of noise. | Conversely, if the bigwig file displays strong noise and weak peaks, it is likely associated with ChIP-seq studies of histone repression markers or transcription factors. In such cases, I recommend initializing your analysis with -w 30 -g 60. Subsequently, adjust these parameters to identify significant peaks that do not contain noise. Note, the -gvalue must be a multiple of the -wvalue. | . ",
    "url": "/docs/ChIPSeq/SICER2_MANUAL/#running-sicer2",
    
    "relUrl": "/docs/ChIPSeq/SICER2_MANUAL/#running-sicer2"
  },"153": {
    "doc": "Peak Detection - SICER2",
    "title": "Example Code",
    "content": ". | Here is an example command to find significant peaks for histone ChIP-seq and TF ChIP-seq: # ChIP-seq with H3K4me3 (active) in mouse genome $ sicer -t shCtrl_H3K4me3.bed -c IPT.bed -s mm10 -o /Users/jchoi/Desktop/shCtrl_H3K4me3_peaks \\ -w 50 -g 100 -fdr 0.05 --cpu 10 $ sicer -t shNFIB_H3K4me3.bed -c IPT.bed -s mm10 -o /Users/jchoi/Desktop/shNFIB_H3K4me3_peaks \\ -w 50 -g 100 -fdr 0.05 --cpu 10 $ sicer -t shNFIB_H3K4me3.bed -c IPT.bed -s mm10 -o /Users/jchoi/Desktop/High_shNFIB_H3K4me3_peaks \\ -w 50 -f 100 -g 100 -e 2000 -fdr 0.01 --cpu 10 # with higher tolerence # ChIP-seq with H3K27me3 (repressive) and TF in human genome $ sicer -t Unt_H3K27me3.bed -c IPT.bed -s hg19 -o /Users/jchoi/Desktop/Unt_H3K27me3_peaks \\ -w 30 -g 60 -fdr 0.05 --cpu 10 $ sicer -t Unt_UTX.bed -c IPT.bed -s hg19 -o /Users/jchoi/Desktop/Unt_UTX_peaks \\ -w 30 -g 60 -fdr 0.05 --cpu 10 . | . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/SICER2_MANUAL/#example-code",
    
    "relUrl": "/docs/ChIPSeq/SICER2_MANUAL/#example-code"
  },"154": {
    "doc": "Peak Detection - SICER2",
    "title": "Output",
    "content": "When running SICER2, it will print out the progress as shown below: . Running SICER with given arguments Preprocess the shCtrl_H3K4me3.bed file to remove redundancy with threshold of 1 --------------------------------------------------------------------------------------------------------- chrom Total plus reads Retained plus reads Total minus reads Retained minus reads --------------------------------------------------------------------------------------------------------- chr1 1766092 1431884 1764980 1430659 chr2 1485557 1161343 1483041 1158281 chr3 960345 826762 960396 826969 chr4 1107496 739794 1107511 739038 chr5 721228 629217 720988 629623 chr6 864932 732032 864943 733150 chr7 1230572 1004239 1250754 1004871 chr8 786604 668198 786734 668881 chr9 1083606 912150 1084044 912697 chr10 1498563 867551 1494950 871312 chr11 1018302 861238 1018015 862009 chr12 771400 665668 771318 665672 chr13 414481 361807 416283 362262 chr14 523068 451730 542582 452155 chr15 608521 524778 608300 525030 chr16 1044556 762083 1045318 761785 chr17 872194 716843 872088 716647 chr18 350855 282315 351234 282808 chr19 810430 664801 810497 665854 chr20 693667 579901 694499 580665 chr21 240195 188495 240046 187773 chr22 362922 310091 362330 310141 chrX 532160 463854 532601 464199 chrY 208555 117472 208730 117706 chrM 432 374 437 375 Preprocess the IPT.bed file to remove redundancy with threshold of 1 --------------------------------------------------------------------------------------------------------- chrom Total plus reads Retained plus reads Total minus reads Retained minus reads --------------------------------------------------------------------------------------------------------- chr1 1793368 1659879 1796390 1661774 chr2 1566262 1454864 1566440 1456232 chr3 1208586 1144070 1210949 1146078 chr4 855230 782676 857044 784808 chr5 891684 845550 893595 847589 chr6 1028974 965932 1031353 968165 chr7 1267501 1178355 1288957 1178840 chr8 938191 875990 940666 878220 chr9 1149407 1083731 1151828 1086072 chr10 1037858 881262 1033323 887184 chr11 1097897 1031119 1098541 1032543 chr12 833473 789165 835172 790914 chr13 545134 516610 547243 517319 chr14 557451 527226 576925 528392 chr15 617089 584246 618031 585426 chr16 745122 677722 746904 676697 chr17 682054 637534 682023 637789 chr18 405730 378666 406858 379855 chr19 457734 421102 458917 422443 chr20 693802 653221 694222 653968 chr21 184156 169868 182588 168812 chr22 302711 286166 302785 286096 chrX 623799 590397 625882 591782 chrY 63643 50065 61350 48868 chrM 23001 15339 22962 14331 Partition the genome in windows and generate summary files... Total count of chr1 tags: 2862543 Total count of chr2 tags: 2319624 Total count of chr3 tags: 1653731 Total count of chr4 tags: 1478832 Total count of chr5 tags: 1258840 Total count of chr6 tags: 1465182 Total count of chr7 tags: 2009110 Total count of chr8 tags: 1337079 Total count of chr9 tags: 1824847 Total count of chr10 tags: 1738863 Total count of chr11 tags: 1723247 Total count of chr12 tags: 1331340 Total count of chr13 tags: 724069 Total count of chr14 tags: 903885 Total count of chr15 tags: 1049808 Total count of chr16 tags: 1523868 Total count of chr17 tags: 1433490 Total count of chr18 tags: 565123 Total count of chr19 tags: 1330655 Total count of chr20 tags: 1160566 Total count of chr21 tags: 376268 Total count of chr22 tags: 620232 Total count of chrX tags: 928053 Total count of chrY tags: 235178 Total count of chrM tags: 747 Normalizing graphs by total island filitered reads per million and generating summary WIG file... Finding candidate islands exhibiting clustering... Species: hg19 Window_size: 50 Gap size: 100 E value is: 1000 Total read count: 31855179 Genome Length: 3095693983 Effective genome Length: 2290813547 Window average: 1.3905618395576915 Window pvalue: 0.2 Minimum num of tags in a qualified window: 3 Determining the score threshold from random background... The score threshold is: 26.159 Generating the enriched probscore summary graph and filtering the summary graph to eliminate ineligible windows... Total number of islands: 46740 Calculating significance of candidate islands using the control library... ChIP library read count: 31855182 Control library read count: 36430952 Total number of chip reads on islands is: 12431267 Total number of control reads on islands is: 3296520 Identify significant islands using FDR criterion Given significance 0.05 , there are 41044 significant islands Out of the 31855182 reads in H2O2_H3K4me3.bed , 12080466 reads are in significant islands . ",
    "url": "/docs/ChIPSeq/SICER2_MANUAL/#output",
    
    "relUrl": "/docs/ChIPSeq/SICER2_MANUAL/#output"
  },"155": {
    "doc": "Peak Detection - SICER2",
    "title": "Understanding SICER2 Output",
    "content": ". | Unless you use special parameters(--significant_reads, No explanation is provided for this parameter), the result of the SICER2 will be four files in the specified folder (-o option). The four files are described below: . | Name(-t_-c)-Number(-w)-Number(-g).scoreisland (e.g. shCtrl_H3K4me3-W50-G100.scoreisland): This file is delineation of significant islands controlled by E-value of 1000 (-e 1000is default). It is in “chrom start end score” format. | Name(-t_-c)-Number(-w)-normalized.wig (e.g. shCtrl_H3K4me3-W50.normalized.wig): this file can be used to visualize the windows generated by SICER2. Read count is normalized by library size per million. It is can be loaded directly to the IGV or UCSC brower. | Name(-t_-c)-Number(-w)-Number(-g)-FDR(-fdr)-islands.bed (e.g. shCtrl_H3K4me3-W50-G100-FDR0.05-island.bed): This file indicates delineation of significant islands filtered by FDR. It has the following format: chrom, start, end, read-count. It is can be loaded directly to the IGV or UCSC brower. | Name(-t_-c)-Number(-w)-Number(-g)-islands-summary (e.g. shCtrl_H3K4me3-W50-G100-islands-summary): summary of all candidate islands with their statistical significance. It has the following format: chrom, start, end, ChIP_island_read_count, CONTROL_island_read_count, p_value, fold_change, FDR_threshold. | . This file (4) will be used for further analysis. Note that it has no extension. | In practice, the structure of the file is as follows: . &gt; jchoi:RAW_SICER2/ $ ll total 469984 -rw-r--r-- 1 jchoi staff 1.5M Dec 12 2022 shCtrl_H3K4me3-W50-G100-FDR0.05-island.bed -rw-r--r--@ 1 jchoi staff 5.0M Dec 12 2022 shCtrl_H3K4me3-W50-G100-islands-summary -rw-r--r-- 1 jchoi staff 2.4M Dec 12 2022 shCtrl_H3K4me3-W50-G100.scoreisland -rw-r--r-- 1 jchoi staff 221M Dec 12 2022 shCtrl_H3K4me3-W50-normalized.wig . | . ",
    "url": "/docs/ChIPSeq/SICER2_MANUAL/#understanding-sicer2-output",
    
    "relUrl": "/docs/ChIPSeq/SICER2_MANUAL/#understanding-sicer2-output"
  },"156": {
    "doc": "Peak Detection - SICER2",
    "title": "Adding Your Own Species",
    "content": "The necessary reference genomes for running SICER2 are listed in the GenomeData.py file. This section provides guidance on incorporating your own genome data for species not already included. For example, I will detail the process of adding genome information for ‘Oryza sativa’. Step 1. Calculate the Chromosome Sizes . | Obtain the DNA sequence of the desired genome (Oryza sativa in this guide) from Ensembl in FASTA format (fa extention). | Calculate the chromosome sizes of this genome using the command provided below: . faSize -detailed /Users/jchoi/Desktop/Oryza_sativa.IRGSP-1.0.dna.toplevel.fa &gt; \\ /Users/jchoi/Desktop/chrom.sizes . | Open the resulting chromosome size file (chrom.sizes) with a text editor such as vim and nano: . Chr1 43270923 Chr2 35937250 Chr3 36413819 Chr4 35502694 Chr5 29958434 Chr6 31248787 Chr7 29697621 Chr8 28443022 Chr9 23012720 Chr10 23207287 Chr11 29021106 Chr12 27531856 ChrUn 633585 ChrSy 592136 . | . Step 2. Set up the configuration file . | Use the chromosome size data to update the GenomeData.py file as demonstrated in the example below (see the pink section in the following contexts): | . GenomeDataError = \"Error in GenomeData class\" bg_number_chroms = 1 bg_length_of_chrom = 100000000 background_chroms = [] background_chrom_lengths = {} for i in range(0, bg_number_chroms): background_chroms.append('chr' + str(i + 1)) background_chrom_lengths['chr' + str(i + 1)] = bg_length_of_chrom mm8_chroms = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chrX', 'chrY', 'chrM'] # =========================================(skip)========================================= &lt;!-- Add the following lines (irsgp_chroms). --&gt; irsgp_chroms = ['Chr1', 'Chr2', 'Chr3', 'Chr4', 'Chr5', 'Chr6', 'Chr7', 'Chr8', 'Chr9', 'Chr10', 'Chr11', 'Chr12', 'ChrUn', 'ChrSy'] mm8_chrom_lengths = {'chr1': 197069962, 'chr2': 181976762, 'chr3': 159872112, 'chr4': 155029701, 'chr5': 152003063, 'chr6': 149525685, 'chr7': 145134094, 'chr8': 132085098, 'chr9': 124000669, 'chr10': 129959148, 'chr11': 121798632, 'chr12': 120463159, 'chr13': 120614378, 'chr14': 123978870, 'chr15': 103492577, 'chr16': 98252459, 'chr17': 95177420, 'chr18': 90736837, 'chr19': 61321190, 'chrX': 165556469, 'chrY': 16029404, 'chrM': 16299} # =========================================(skip)========================================= &lt;!-- Add the following lines (irsgp_chroms). --&gt; irsgp_chrom_lengths = {'Chr1': 43270923, 'Chr2': 35937250, 'Chr3': 36413819, 'Chr4': 35502694, 'Chr5': 29958434, 'Chr6': 31248787, 'Chr7': 29697621, 'Chr8': 28443022, 'Chr9': 23012720, 'Chr10': 23207287, 'Chr11': 29021106, 'Chr12': 27531856, 'ChrUn': 633585, 'ChrSy': 592136} species_chroms = {'mm8': mm8_chroms, 'mm9': mm9_chroms, # =========================================(skip)========================================= 'tair8': tair8_chroms, 'irsgp': irsgp_chroms, &lt;!-- Add the following command. --&gt; 'background': background_chroms} species_chrom_lengths = {'mm8': mm8_chrom_lengths, 'mm9': mm9_chrom_lengths, # =========================================(skip)========================================= 'tair8': tair8_chrom_lengths, 'irsgp': irsgp_chrom_lengths, &lt;!-- Add the following command. --&gt; 'background': background_chrom_lengths} . Step 3. Apply the GenomeData.py file . | Once finished with editing GenomeData.py, run pip install -e . in the top directory of the repo. This should install the user’s local version of SICER2. | You can now perform peak-call analysis for oryza sativa with -s irsgp option. | . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/SICER2_MANUAL/#adding-your-own-species",
    
    "relUrl": "/docs/ChIPSeq/SICER2_MANUAL/#adding-your-own-species"
  },"157": {
    "doc": "Peak Detection - SICER2",
    "title": "Running sicer-df for Differential Peak Calling",
    "content": ". | Use the following command to perform differentially peak-call analysis with sicer-df: . $ sicer-df -t &lt;CompareFiles.bed&gt; -c &lt;InputFiles.bed&gt; -s &lt;speciesBuild&gt; -o &lt;outputFolder&gt; \\ -w &lt;int&gt; -f &lt;int&gt; -g &lt;int&gt; -e &lt;int&gt; -fdr_df &lt;int&gt; -cpu &lt;int&gt; . | The fundamental command line remains consistent with that of sicer. In these commands, . | Parameter | Description | . | -t &lt;CompareFiles.bed&gt; | Two files must be given as input. The first file must be the target (KO/KD/Treated) file and the second file must be the control (WT/shCtrl/Untreated) file. Possible data type is BAM or BED (recommended). | . | -c &lt;InputFiles.bed&gt; | Specifies the control data (input). Possible data type is BAM or BED (recommended). | . | -fdr_df &lt;int&gt; | Specifies an FDR cutoff (Default: 0.05), Do not confuse -fdr &lt;int&gt; for sicer. | . | . ",
    "url": "/docs/ChIPSeq/SICER2_MANUAL/#running-sicer-df-for-differential-peak-calling",
    
    "relUrl": "/docs/ChIPSeq/SICER2_MANUAL/#running-sicer-df-for-differential-peak-calling"
  },"158": {
    "doc": "Peak Detection - SICER2",
    "title": "Example Code &amp; Output",
    "content": ". | Here is an example command to find differentially significant peaks between two samples: . $ sicer_df -t H2O2_H3K4me3.bed Unt_H3K4me3.bed -s hg19 -w 50 -g 100 -fdr_df 0.05 --cpu 10 \\ -o /Users/jchoi/Desktop/sicer_df/H3K4me3 $ sicer_df -t H2O2_MLL1.bed Unt_MLL1.bed -s hg19 -w 30 -g 60 -fdr_df 0.05 --cpu 10 \\ -o /Users/jchoi/Desktop/sicer_df/MLL1 . | . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/SICER2_MANUAL/#example-code--output",
    
    "relUrl": "/docs/ChIPSeq/SICER2_MANUAL/#example-code--output"
  },"159": {
    "doc": "Peak Detection - SICER2",
    "title": "Citations",
    "content": "SICER . | Zang, C., Schones, D. E., Zeng, C., Cui, K., Zhao, K., &amp; Peng, W. (2009). A clustering approach for identification of enriched domains from histone modification ChIP-Seq data. Bioinformatics, 25(15), 1952-1958. DOI | . Bedtools . | Quinlan, A. R., &amp; Hall, I. M. (2010). BEDTools: a flexible suite of utilities for comparing genomic features. Bioinformatics, 26(6), 841-842. DOI | . ",
    "url": "/docs/ChIPSeq/SICER2_MANUAL/#citations",
    
    "relUrl": "/docs/ChIPSeq/SICER2_MANUAL/#citations"
  },"160": {
    "doc": "Peak Detection - SICER2",
    "title": "Peak Detection - SICER2",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/ChIPSeq/SICER2_MANUAL/",
    
    "relUrl": "/docs/ChIPSeq/SICER2_MANUAL/"
  },"161": {
    "doc": "Basal setting and troubleshooting",
    "title": "Converting Shell Environment and Installing Homebrew",
    "content": "Homebrew is an open-source package manager for macOS and Linux systems. It simplifies the process of installing and managing software, enabling users to easily install various packages with a single command line instruction. Using the brew command, Homebrew allows for the straightforward installation, update, and removal of packages. It also provides an environment where users can create or modify packages, fostering a community-driven platform for extensions. Additionally, Homebrew automates dependency management, ensuring that various software can coexist without conflicts. This feature makes it an essential tool for many developers and researchers. ",
    "url": "/docs/DataProcess/Tr/#converting-shell-environment-and-installing-homebrew",
    
    "relUrl": "/docs/DataProcess/Tr/#converting-shell-environment-and-installing-homebrew"
  },"162": {
    "doc": "Basal setting and troubleshooting",
    "title": "Step 1: Convert to Z shell in macOS",
    "content": "Zsh (Z Shell) is favored among developers and power users for its advanced features and user-friendly experience. It offers robust autocomplete capabilities, which streamline command input and enhance productivity. Zsh is also known for its powerful file globbing, allowing intricate file manipulation and pattern matching. Users appreciate its modular configuration, enabling detailed customization of prompts, themes, and shell options through frameworks like Oh My Zsh. Additionally, Zsh supports complex scripting with enhanced built-in functions and improved mathematical and array operations, making it a popular choice over other shells. Note: Starting with macOS 10.15, the default shell is zsh. | Check your shell environment and convert to zsh: # Check your current shell $ echo $SHELL # Check the list of acceptable shells and convert if you are currently using bash. $ cat /etc/shells # Convert to zsh $ chsh -s /bin/zsh . | . ",
    "url": "/docs/DataProcess/Tr/#step-1-convert-to-z-shell-in-macos",
    
    "relUrl": "/docs/DataProcess/Tr/#step-1-convert-to-z-shell-in-macos"
  },"163": {
    "doc": "Basal setting and troubleshooting",
    "title": "Step 2: Install Homebrew and Its Recommended Plugins",
    "content": ". | Type the following command to install homebrew: | . $ /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" . | Installing oh-my-zsh: . | Install the plugin: $ sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\" . | After installation, you will see a screen where you can customize your shell environment. | Open the shell configuration file with text editor $ nano ~/.zshrc . | Find the syntax ZSH_THEME=”rubbyrussell“ followed by the name of the theme you want between the double quotes. You can check out the available themes on the oh-my-zsh GitHub. ZSH_THEME=\"clean\" . In programming languages like shells (ZSH/Bash), Python, and R, the # symbol marks comments that are not executed. | Save and reload the shell $ source ~/.zshrc . | . | Installing Syntax highlighting: . | install the plugin: $ brew install zsh-syntax-highlighting . | Open the shell configuration file. | Add the following syntax in the file: source /path/to/your/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh # For example source /usr/local/share/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh . | Save and reload the shell. | . | . ",
    "url": "/docs/DataProcess/Tr/#step-2-install-homebrew-and-its-recommended-plugins",
    
    "relUrl": "/docs/DataProcess/Tr/#step-2-install-homebrew-and-its-recommended-plugins"
  },"164": {
    "doc": "Basal setting and troubleshooting",
    "title": "In the Case of Linux (Ubuntu 20.04.2 LTS)",
    "content": ". | Check your shell environment using echo $SHELL. | Install and convert to zsh as the following commands: $ sudo apt install zsh $ chsh -s /usr/bin/zsh . | Install essential libraries, containing C/C++ compiler, GNU make, curl, and git, as the follwing command: $ sudo apt-get install build-essential curl file git . | Install homebrew: $ sh -c \"$(curl -fsSL https://raw.githubusercontent.com/Linuxbrew/install/master/install.sh)\" . | Open the configuration file and set up the necessary environment paths: # Open the shell configuration file $ nano ~/.zshrc # Add path settings export PATH=\"/path/to/your/linuxbrew/.linuxbrew/bin:$PATH\" export MANPATH=\"/path/to/your/linuxbrew/.linuxbrew/share/man:$MANPATH\" export INFOPATH=\"/path/to/your/linuxbrew/.linuxbrew/share/info:$INFOPATH\" # For example export PATH=\"/home/linuxbrew/.linuxbrew/bin:$PATH\" export MANPATH=\"/home/linuxbrew/.linuxbrew/share/man:$MANPATH\" export INFOPATH=\"/home/linuxbrew/.linuxbrew/share/info:$INFOPATH\" . | Save and reload the shell. Plugin for homebrew installation for Linux mirrors the process on macOS. | . ",
    "url": "/docs/DataProcess/Tr/#in-the-case-of-linux-ubuntu-20042-lts",
    
    "relUrl": "/docs/DataProcess/Tr/#in-the-case-of-linux-ubuntu-20042-lts"
  },"165": {
    "doc": "Basal setting and troubleshooting",
    "title": "Setting Up Anaconda in Linux",
    "content": "Anaconda is a popular distribution of Python and R programming languages for scientific computing, aimed at simplifying package management and deployment. It includes a wide range of pre-installed packages geared towards data science and machine learning. On macOS, Anaconda can be installed via a .pkg file, allowing for a straightforward setup without the need for additional configurations. However, on Linux, after installing Anaconda, additional configuration steps are typically required to fully integrate and utilize all features of the Anaconda environment. ",
    "url": "/docs/DataProcess/Tr/#setting-up-anaconda-in-linux",
    
    "relUrl": "/docs/DataProcess/Tr/#setting-up-anaconda-in-linux"
  },"166": {
    "doc": "Basal setting and troubleshooting",
    "title": "Step-by-Step Guide",
    "content": ". | Checking installed Python version . | Ensure that Python is installed, as Ubuntu 20.04 LTS comes with Python pre-installed, and update your system’s package list and upgrade Python: | . $ python3 --version $ sudo apt-get update $ sudo apt-get upgrade python3 . | Installing essential libraries and Pypi3 management package . $ sudo apt-get install build-essential checkinstall $ sudo apt-get install libreadline-gplv2-dev libncursesw5-dev libssl-dev \\ libsqlite3-dev tk-dev libgdbm-dev libc6-dev libbz2-dev libffi-dev zlib1g-dev $ sudo apt-get install python3-pip . | Installing and updating Anaconda . | Download the Anaconda installer script from the Anaconda website and execute it. | . $ cd Downloads $ sudo bash Ana*.sh . | Follow the on-screen instructions to agree to the license, choose the install location, and decline the initialization. | Ensure the base version of conda is up-to-date: | . $ conda update -n base conda . | setting path for Anaconda and updating essential Anaconda components . | Open the shell file and add your Anaconda PATH: | . export PATH=\"/path/to/your/anaconda/anaconda3/bin:$PATH\" # For example export PATH=\"/home/jh/anaconda3/bin:$PATH\" . | Reload the shell configuration to apply changes, and make sure all components are up-to-date: | . $ sudo apt-get update $ conda update xz . | . ",
    "url": "/docs/DataProcess/Tr/#step-by-step-guide",
    
    "relUrl": "/docs/DataProcess/Tr/#step-by-step-guide"
  },"167": {
    "doc": "Basal setting and troubleshooting",
    "title": "Troubleshooting Library Issues",
    "content": ". | Resolve issues related to shared library dependencies as bellow: . XXXXXXXX: error while loading shared libraries: libssl.so.1.0.0: cannot open shared object file: No such file or directory . | Solution: . # If encountering shared library errors, execute the following: $ sudo nano /etc/apt/sources.list # Add the line in the source file and save it: deb http://security.ubuntu.com/ubuntu bionic-security main $ sudo apt update &amp;&amp; apt-cache policy libssl1.0-dev $ sudo apt-get install libssl1.0-dev . | . ",
    "url": "/docs/DataProcess/Tr/#troubleshooting-library-issues",
    
    "relUrl": "/docs/DataProcess/Tr/#troubleshooting-library-issues"
  },"168": {
    "doc": "Basal setting and troubleshooting",
    "title": "Installing Java JDK 16 in Linux",
    "content": "Java is a powerful programming language used by millions of developers worldwide, essential for developing servers, mobile apps, and large systems across various platforms. The Java Development Kit (JDK) provides the necessary compiler, libraries, and other tools required for Java application development. This section outlines step-by-step instructions for installing Java JDK 16 on Linux operating systems. ",
    "url": "/docs/DataProcess/Tr/#installing-java-jdk-16-in-linux",
    
    "relUrl": "/docs/DataProcess/Tr/#installing-java-jdk-16-in-linux"
  },"169": {
    "doc": "Basal setting and troubleshooting",
    "title": "Step-by-Step Installation",
    "content": ". | Download the JDK files suitable for your operating system from the Oracle website. It is recommended to download the gz compressed file (e.g., jdk-16_linux-x64_bin.tar.gz), not rpm or deb formats. | Move the downloaded file and extract it: $ sudo mv jdk-16_linux-x64_bin.tar.gz /usr/local/java/ $ cd /usr/local/java/ $ sudo tar xvfz jdk-16_linux-x64_bin.tar.gz . | Set Java environment and update system alternatives: $ sudo nano /etc/profile # Add the following line at the end of the file, and then save it: export JAVA_HOME=$(readlink -f /usr/bin/java | sed \"s:bin/java::\") # Exit then type the following commands $ sudo update-alternatives --install \"/usr/bin/java\" \"java\" \"/usr/local/java/jdk-16/bin/java\" 1 $ sudo update-alternatives --install \"/usr/bin/javac\" \"javac\" \"/usr/local/java/jdk-16/bin/javac\" 1 $ sudo update-alternatives --set java /usr/local/java/jdk-16/bin/java $ sudo update-alternatives --set javac /usr/local/java/jdk-16/bin/javac . | Reload profile and verify installation $ . /etc/profile . &gt; $ java -version # Expected output: # java version \"16\" 2021-03-16 # Java(TM) SE Runtime Environment (build 16+36-2231) # Java HotSpot(TM) 64-Bit Server VM (build 16+36-2231, mixed mode, sharing) . | . ",
    "url": "/docs/DataProcess/Tr/#step-by-step-installation",
    
    "relUrl": "/docs/DataProcess/Tr/#step-by-step-installation"
  },"170": {
    "doc": "Basal setting and troubleshooting",
    "title": "Alternative Installation Method (Not Recommended)",
    "content": ". | Add repository: $ sudo add-apt-repository ppa:linuxuprising/java $ sudo apt update . | Change to root user and set repository $ su - `#` echo \"deb http://ppa.launchpad.net/linuxuprising/java/ubuntu focal main\" | tee /etc/apt/sources.list.d/linuxuprising-java.list `#` apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 73C3DB2A `#` apt-get update `#` exit # Logout from root . | Install Oracle Java 16 via apt $ sudo apt install oracle-java16-installer --install-recommends . | . ",
    "url": "/docs/DataProcess/Tr/#alternative-installation-method-not-recommended",
    
    "relUrl": "/docs/DataProcess/Tr/#alternative-installation-method-not-recommended"
  },"171": {
    "doc": "Basal setting and troubleshooting",
    "title": "Troubleshooting",
    "content": "Problem 1. Authentication Failure . | If you have never switched super root before and do not know the password, you will see the following Authentication Error: &gt; su - Password: su: Authentication failure . | You can set the password with the command below: $ sudo passwd . XXX ~$ &gt; sudo passwd New password: # silent password prompt Retype new password: # silent password prompt XXX ~$ &gt; su - Password: # silent password prompt XXX ~# &gt; . | When entering a password, a silent password prompt is applied. | When your account is switched to super root, the dollar marks ($) are replaced with sharp marks (#). | . | . Problem 2. Installing Error . | During the installation process, it is possible to encounter an error similar to the one described below: Oracle JDK 16 is NOT installed. dpkg: error processing package oracle-java16-installer (--configure): installed oracle-java16-installer package post-installation script subprocess returned error exit status 1 Errors were encountered while processing: oracle-java16-installer E: Sub-process /usr/bin/dpkg returned an error code (1) . | Solution: $ sudo rm /var/lib/dpkg/info/oracle-java16-installer.postinst -f $ sudo dpkg --configure oracle-java16-installer . | . ",
    "url": "/docs/DataProcess/Tr/#troubleshooting",
    
    "relUrl": "/docs/DataProcess/Tr/#troubleshooting"
  },"172": {
    "doc": "Basal setting and troubleshooting",
    "title": "Troubleshooting in R for macOS",
    "content": " ",
    "url": "/docs/DataProcess/Tr/#troubleshooting-in-r-for-macos",
    
    "relUrl": "/docs/DataProcess/Tr/#troubleshooting-in-r-for-macos"
  },"173": {
    "doc": "Basal setting and troubleshooting",
    "title": "Problem 1: Adjusting Language Setting in Shell",
    "content": "Sometimes, RStudio may default to the system language, or you may prefer to use RStudio in a different language. For Mac users, setting RStudio to use English (US) can be accomplished by modifying the system locale. Solution 1: Setting Language Environment in Shell . This guide provides steps to change the default language of the shell environment in macOS, which affects all applications run from the shell. | Open the zsh configuration file (.zshrc) using text editors. | Add the following line to set the default shell language to English (US): export LANG=en_US.UTF-8 . | Source the .zshrc to apply the changes immediately. | . Solution 2: Change Language to English in RStudio . This solution ensures that RStudio runs in English, regardless of your Mac’s system language settings, providing a consistent experience in the specified language. | Open your Terminal and type the following command to enforce English as the default language for R: defaults write org.R-project.R force.LANG en_US.UTF-8 . | For the change to take effect, you might need to restart your Terminal or RStudio. This command adjusts the locale specifically for R, making RStudio display menus and messages in English (US). | . ",
    "url": "/docs/DataProcess/Tr/#problem-1-adjusting-language-setting-in-shell",
    
    "relUrl": "/docs/DataProcess/Tr/#problem-1-adjusting-language-setting-in-shell"
  },"174": {
    "doc": "Basal setting and troubleshooting",
    "title": "Problem 2: Disappearance of Library Packages Post R Update",
    "content": "When R is updated to a new minor version, previously installed library packages might not be recognized due to changes in the library path. These packages are not lost but are just not linked to the new version. Solution: Set the Path to the Previous Version's Library . | Configure Library Paths in RStudio . | Direct RStudio to recognize the libraries from the previous version by setting the library paths manually. Enter the following command in RStudio’s console: .libPaths(c(\"/path/to/your/R_path/Versions/DESIRED_VERSION/Resources/library\", .libPaths())) . For example: .libPaths(c(\"/Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/library\", .libPaths())) . | . | Persistent Configuration . | To make this change persistent across all R sessions, modify the .Rprofile file in your home directory: .First &lt;- function() { .libPaths(c(\"/Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/library\", .libPaths())) cat(\"Custom library path set.\\n\") } . | Save the changes to .Rprofile and restart RStudio to apply them. | . | . By following these steps, you ensure that RStudio can access and load library packages installed under previous versions, even after updating R to a newer version. ",
    "url": "/docs/DataProcess/Tr/#problem-2-disappearance-of-library-packages-post-r-update",
    
    "relUrl": "/docs/DataProcess/Tr/#problem-2-disappearance-of-library-packages-post-r-update"
  },"175": {
    "doc": "Basal setting and troubleshooting",
    "title": "Problem 3: R Dependency Package and gfortran Compatibility on Silicon Macs",
    "content": "Silicon Macs may encounter compatibility issues with R dependency packages that require the gfortran compiler, as the conventional GNU/Fortran compiler does not natively support Silicon Mac architecture. I acknowledge that this issue has been resolved automatically through a recent update (2022). Solution: Install a Compatible gfortran Version . | Download and Install gfortran . | Download a compatible version of gfortran for Silicon Mac from mac.r-project.org/libs-arm64. | Decompress the downloaded file and move it to the /opt/R/arm64 directory. | . | Configure the R Environment . | Locate the R environment configuration file: /Library/Frameworks/R.framework/Resources/etc/Makeconf . | Open the Makeconf file and modify the Fortran compiler path to the newly installed gfortran: FC = /opt/R/arm64/gfortran/bin/gfortran -mtune=native FLIBS = -L/opt/R/arm64/gfortran/lib/gcc/aarch64-apple-darwin20.2.0/11.0.0 -L/opt/R/arm64/gfortran/lib -lgfortran -lemutls_w -lm . Note: Intel Macs use the flags -lgfortran -lemutls_w -lquadmath, but Silicon Macs do not require -lquadmath. | . | . Optional: Configure Homebrew for Silicon Mac . | If Homebrew is not yet installed on your Silicon Mac, or if you need to configure it for the Silicon architecture, follow these steps: . nano ~/.zshrc # Add the following line to configure Homebrew: eval $(/opt/homebrew/bin/brew shellenv) . | . ",
    "url": "/docs/DataProcess/Tr/#problem-3-r-dependency-package-and-gfortran-compatibility-on-silicon-macs",
    
    "relUrl": "/docs/DataProcess/Tr/#problem-3-r-dependency-package-and-gfortran-compatibility-on-silicon-macs"
  },"176": {
    "doc": "Basal setting and troubleshooting",
    "title": "Basal setting and troubleshooting",
    "content": "© 2022 Janghyun Choi . This section offers a comprehensive guide to the fundamental aspects of installing and maintaining software via package managers, specifically focusing on Python, Java, and R. Additionally, it outlines potential solutions to common challenges encountered on silicon Mac computers. This section is organized as follows: . 1. Converting Shell Environment and Installing Homebrew . 2. Setting Up Anaconda in Linux . 3. Installing Java JDK 16 in Linux . 4. Troubleshooting in R for macOS . Disclaimer: The provided solutions are based on individual experiences and are not comprehensive. They should be considered as general guidance only. ",
    "url": "/docs/DataProcess/Tr/",
    
    "relUrl": "/docs/DataProcess/Tr/"
  },"177": {
    "doc": "Trimmed reads with Trimmomatic",
    "title": "Remove Adaptor and Low-Quality Reads with Trimmomatic",
    "content": "Removing adapters and low-quality sequences from sequencing data is essential for ensuring data accuracy and quality. Most sequencers employ a sequencing adapter to generate raw data; however, these artificial sequences must be removed during data processing. This not only eliminates the adapter but also improves the overall quality of the data by removing errors or low-quality read ends that may occur during the sequencing process. Trimmomatic, a multithreaded tool based on the JavaScript platform, is highly effective in performing these tasks, making it a valuable resource in bioinformatics for obtaining high-quality data. This protocol was created based on Trimmomatic version 0.39 running on a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes Python version 3.8.5 and Java version 16.0.1 under macOS 12.4 environment. ",
    "url": "/docs/DataProcess/Trimmmomatic_manual/#remove-adaptor-and-low-quality-reads-with-trimmomatic",
    
    "relUrl": "/docs/DataProcess/Trimmmomatic_manual/#remove-adaptor-and-low-quality-reads-with-trimmomatic"
  },"178": {
    "doc": "Trimmed reads with Trimmomatic",
    "title": "Installation Trimmomatic",
    "content": ". Download the file from the official website and unzip it to a folder of your choice. Requirments . | To run Trimmomatic, you need Java version 7 or higher. Use the following command to check Java version: $ java -version java version \"16.0.1\" 2020-04-20 Java(TM) SE Runtime Environment (build 16.0.1+9-24) Java HotSpot(TM) 64-Bit Server VM (build 16.0.1+9-24, mixed mode, sharing) . | . ",
    "url": "/docs/DataProcess/Trimmmomatic_manual/#installation-trimmomatic",
    
    "relUrl": "/docs/DataProcess/Trimmmomatic_manual/#installation-trimmomatic"
  },"179": {
    "doc": "Trimmed reads with Trimmomatic",
    "title": "Running Trimmomatic",
    "content": "Use the following command to perform Trimmomatic via Java machine: Trimmomatic and its related command-lines must be typed in directory of trimmomatic. $ java -var Trimmomatic-0.39.jar &lt;mode&gt; -&lt;score&gt; -threads &lt;int&gt; &lt;input1&gt; ... &lt;inputN&gt; \\ &lt;PairedOutput1.fq.gz&gt; &lt;UnpairOutput1.fq.gz&gt; ... &lt;PairedOutputN.fq.gz&gt; &lt;UnpairOutputN.fq.gz&gt; \\ &lt;OptionalParameters&gt; # e.g. Full commands for pair-end mode $ java -var Trimmomatic-0.39.jar &lt;mode&gt; -&lt;score&gt; -threads &lt;int&gt; &lt;input1&gt; &lt;input2&gt; \\ &lt;PairedOutput1.fq.gz&gt; &lt;UnpairOutput1.fq.gz&gt; &lt;PairedOutput2.fq.gz&gt; &lt;UnpairOutput2.fq.gz&gt; \\ ILLUMINACLIP:[adaptor file.fa]:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 # e.g. Full commands for single-end mode $ java -var Trimmomatic-0.39.jar &lt;mode&gt; -&lt;score&gt; -threads &lt;int&gt; &lt;input1&gt; &lt;PairedOutput1.fq.gz&gt; \\ ILLUMINACLIP:[adaptor file.fa]:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 . In these commands: . | Parameter | Description | . | java -var Trimmomatic-0.39.jar | Executes trimmomatic code | . | &lt;mode&gt; option | Specifies sequence type from either pair-end (PE) or single-end (SE) | . | -&lt;score&gt; option | Determines quality score whether this score is based on 33 (phred33) or 64 (phred64). | . | -threads &lt;int&gt; | Specifies thread numbers for this operation. | . | &lt;input1&gt; ... &lt;inputN&gt; | Specifies forward and reverse input files, they are separated by spaces. | . | &lt;PairedOutputN.fq.gz&gt; &lt;UnpairOutputN.fq.gz&gt; | Specifies output files. In PE mode, each input file will result in the creation of two output files, arranged in the specific order of “pair” and “unpair”. It is imperative to preserve this order to prevent any discrepancies. In SE mode, each input file will generate a single output file, irrespective of any pairing configuration. | . | The &lt;OptionalParameters&gt; offer a wide range of variables as bellow, see the Trimmomatic’s manual for details (For more information such as global parameter, refers to Trimmomatic’s guidelines.). | Parameter | Description | . | ILLUMINACLIP:&lt;path/to/CLIP.fa&gt; | Specifies a adaptor clip file. Trimmomtic provide this universal sequence clip in /adapters folder. ILLUMINACLIP would be assigned relative path. | . | :&lt;seed mismatches&gt;:&lt;palindrome clip threshold&gt;:&lt;simple clip threshold&gt; | Specifies the maximum mismatch, how accurate the match between the two adapter ligated reads, and how accurate the match between any adapter, respectively. This parameter should come after the ILLUMINACLIP, most commonly :2:30:10. | . | LEADING:&lt;quality&gt; | Remove low quality bases from the beginning. Specifies the minimum quality required to keep a base, most commonly LEADING:3. | . | TRAILING:&lt;quality&gt; | Remove low quality bases from the end. Specifies the minimum quality required to keep a base, most commonly TRAILING:3 | . | SLIDINGWINDOW:&lt;size:&lt;quality&gt; | Perform a sliding window trimming, cutting once the average quality (quality) within the window (size)falls below a threshold, most commonly SLIDINGWINDOW:4:15. | . | MINLEN:&lt;length&gt; | This module removes reads that fall below the specified minimal length. Specifies the minimum length of reads to be kept, most commonly MINLEN:36. | . | . ",
    "url": "/docs/DataProcess/Trimmmomatic_manual/#running-trimmomatic",
    
    "relUrl": "/docs/DataProcess/Trimmmomatic_manual/#running-trimmomatic"
  },"180": {
    "doc": "Trimmed reads with Trimmomatic",
    "title": "Example Code with explanation",
    "content": "Here is an example command with footnote for explanation to perform Trimmomatic on QCed fastq files: . # Example for PE mode java -jar trimmomatic-0.39.jar PE -threads 20 -phred33 \\ # Run a Trimmomatic, consist pair-end and base on ASCII 33, using 20 threads. ~/Desktop/Bone_fastq/shC_D0_1.fastq.gz ~/Desktop/Bone_fastq/shC_D0_2.fastq.gz \\ # Speficies forward and reverse input files, respectively. ~/Desktop/Bone_Trim/Trim_shC_D0_1.fastq.gz ~/Desktop/Bone_Trim/unTrim_shC_D0_1.fastq.gz \\ # Output for forward ~/Desktop/Bone_Trim/Trim_shC_D0_2.fastq.gz ~/Desktop/Bone_Trim/unTrim_shC_D0_2.fastq.gz \\ # Output for reverse ILLUMINACLIP:adapters/TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 # Specify adaptor sequence and global parameters # Example for SE mode java -jar trimmomatic-0.39.jar SE -threads 20 -phred33 \\ # Run a Trimmomatic with SE mode ~/Desktop/ChIP_seq/H3K4me3.fastq.gz TRIM_H3K4me3.fq.gz \\ # Input and ouput ILLUMINACLIP:adapters/TruSeq3-SE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 # global parameters . ",
    "url": "/docs/DataProcess/Trimmmomatic_manual/#example-code-with-explanation",
    
    "relUrl": "/docs/DataProcess/Trimmmomatic_manual/#example-code-with-explanation"
  },"181": {
    "doc": "Trimmed reads with Trimmomatic",
    "title": "Output",
    "content": "When Trimmomatic finishes running, it prints messages summarizing what happened. TrimmomaticPE: Started with arguments: -threads 20 -phred33 /Users/jchoi/Desktop/Bone_fastq/shC_D0_1.fastq.gz /Users/jchoi/Desktop/Bone_fastq/shC_D0_2.fastq.gz /Users/jchoi/Desktop/Bone_Trim/Trim_shC_D0_1.fastq.gz /Users/jchoi/Desktop/Bone_Trim/unTrim_shC_D0_1.fastq.gz /Users/jchoi/Desktop/Bone_Trim/Trim_shC_D0_2.fastq.gz /Users/jchoi/Desktop/Bone_Trim/unTrim_shC_D0_2.fastq.gz ILLUMINACLIP:adapters/TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36 Using PrefixPair: 'TACACTCTTTCCCTACACGACGCTCTTCCGATCT' and 'GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT' ILLUMINACLIP: Using 1 prefix pairs, 0 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences Input Read Pairs: 41429555 Both Surviving: 40573408 (97.93%) Forward Only Surviving: 646381 (1.56%) Reverse Only Surviving: 168217 (0.41%) Dropped: 41549 (0.10%) TrimmomaticPE: Completed successfully . ",
    "url": "/docs/DataProcess/Trimmmomatic_manual/#output",
    
    "relUrl": "/docs/DataProcess/Trimmmomatic_manual/#output"
  },"182": {
    "doc": "Trimmed reads with Trimmomatic",
    "title": "Citation",
    "content": "Trimmomatic . | Bolger, A. M., Lohse, M., &amp; Usadel, B. (2014). Trimmomatic: a flexible trimmer for Illumina sequence data. Bioinformatics, 30(15), 2114-2120. DOI | . ",
    "url": "/docs/DataProcess/Trimmmomatic_manual/#citation",
    
    "relUrl": "/docs/DataProcess/Trimmmomatic_manual/#citation"
  },"183": {
    "doc": "Trimmed reads with Trimmomatic",
    "title": "Trimmed reads with Trimmomatic",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/DataProcess/Trimmmomatic_manual/",
    
    "relUrl": "/docs/DataProcess/Trimmmomatic_manual/"
  },"184": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "Exploring Deep-sequencing Data with deepTools",
    "content": "The deepTools effectively manages the vast data volumes routinely produced from sequencing platforms. This tool suite includes versatile modules designed to process mapped reads, performing numerous quality assessments. It also generates normalized coverage files in standard bedGraph and bigWig formats, facilitating comparisons between various datasets, such as treatment and control groups. This protocol was created based on deepTools version 3.5.1 running on a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes Python version 3.8.5, SciPy version 1.6.2, NumPy version 1.20.1, and conda version 22.9.0 under macOS 12.4 environment. ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#exploring-deep-sequencing-data-with-deeptools",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#exploring-deep-sequencing-data-with-deeptools"
  },"185": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "Installation deepTools",
    "content": ". To install deepTools using Anaconda, use the following command: . $ conda install -c conda-forge -c bioconda deeptools . ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#installation-deeptools",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#installation-deeptools"
  },"186": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "Troubleshooting in Linux Environment",
    "content": ". | If error occurs for freeze environment, update conda as follow; $ sudo apt-get update $ conda update xz . | If error occurs for repository, remove it as follow; $ sudo add-apt-repository --remove ppa:[Dir]/[Sub-Dir] # For example $ sudo add-apt-repository --remove ppa:webupd8team/sublime-text-3 . | If deeptools cannot be run due to libcryto.so.1.0.0 source error, refer to document of ‘phyton setting’ | . ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#troubleshooting-in-linux-environment",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#troubleshooting-in-linux-environment"
  },"187": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "BamCoverage: Convert BAM into bigWig",
    "content": ". | BamCoverage module takes an alignment of reads or fragments as input (BAM file) and generates a coverage track (bigWig or bedGraph) as output. Use the following command to convert BAM to BigWig with BamCoverage: . This module requires a BAM file sorted by position and a bai file in the same folder. $ bamCoverage -b &lt;input.bam&gt; -o &lt;output.bigwig&gt; -of &lt;outputType&gt; -bs &lt;int&gt; \\ --normalizeUsing &lt;Norm&gt; --effectiveGenomeSize &lt;int&gt; --smoothLength &lt;int&gt; \\ --region &lt;region&gt; -p &lt;int&gt; -e . | In these commands, . | Parameter | Description | . | -b &lt;input.bam&gt; | Specifies the input data. | . | -o &lt;output.bigwig&gt; | Specifies output file. | . | -of &lt;outputType&gt; | Specifies format of the output data. Possible values are bigWig or bdg. | . | -bs &lt;int&gt; | Size of the bins, in bases, for the output of the bigwig/bedgraph file (Default: 50). -bs 1 setting is recommended for publication. The smaller the value of -bs, the more computation. | . | --normalizeUsing &lt;Norm&gt; | Specifies whether to apply a method to normalize the number of reads per bin.Possible values for &lt;Norm&gt; are RPCG, RPKM, CPM, or none (default: none). | . | --effectiveGenomeSize &lt;int&gt; | The effective genome size (EGS) is the portion of the genome that is mappable. this parameter is couple with RPGC normalization. human: 2.7e9 (2700000000), mouse: 1.87e9 (1870000000). | . | --smoothLength &lt;int&gt; | The smooth length defines a window, larger than the binSize, to average the number of reads. For example, if the –binSize is set to 20 and the –smoothLength is set to 60, then, for each bin, the average of the bin and its left and right neighbors is considered. For Publication, -bs 1, --smoothLength 10settting is recommended. The larger the value of ---smoothLength, the more computation. | . | --region &lt;region&gt; | Region of the genome to limit the operation to - this is useful when testing parameters to reduce the computing time.The format is chr:start:end, for example --region chr2:178104147:178154424. | . | -p &lt;int&gt; | Specifies thread numbers &lt;int&gt; | . | -e option | This parameter allows the extension of reads to fragment size. If set, each read is extended, without exception. Can not apply to RNA-seq data. | . | . ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#bamcoverage-convert-bam-into-bigwig",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#bamcoverage-convert-bam-into-bigwig"
  },"188": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "Example code",
    "content": ". | Here is an example command to perform converting a bigWig file from the BAM file: . # Coded to quickly identify track patterns. $ bamcoverage -b Final.sort.Unt_IPT.bam -o /Users/jchoi/desktop/Unt_IPT.bigwig \\ -bs 100 --normalizeUsing RPGC --effectiveGenomeSize 2700000000 -e -p 10 # For GEO submission, it takes a very long time. $ bamcoverage -b Final.sort.Unt_IPT.bam -o /Users/jchoi/desktop/Unt_IPT.bigwig -bs 1 \\ --normalizeUsing RPGC --effectiveGenomeSize 2700000000 --smoothLength 10 -e -p 10 $ bamcoverage -b Final.sort.Unt_IPT.bam -o /Users/jchoi/desktop/Unt_IPT.bigwig -bs 5 \\ --normalizeUsing RPGC --effectiveGenomeSize 2700000000 --smoothLength 20 -e -p 10 # This code makes the bigWig file by specifying a target gene region as wide, which can be a time saver. $ bamcoverage -b Final.sort.Unt_MLL1.bam -o /Users/jchoi/desktop/Unt_MLL1_NRF2.bigwig -bs 1 \\ --normalizeUsing RPGC --effectiveGenomeSize 2700000000 --region chr2:178104147:178154424 \\ --smoothLength 20 -e . | . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#example-code",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#example-code"
  },"189": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "Output",
    "content": ". | When BamCoverage running, it prints messages printing as the follow: bamFilesList: ['Final.sort.Unt_MLL1.bam'] binLength: 1 numberOfSamples: None blackListFileName: None skipZeroOverZero: False bed_and_bin: False genomeChunkSize: None defaultFragmentLength: 254 numberOfProcessors: 2 verbose: False region: None bedFile: None minMappingQuality: None ignoreDuplicates: False chrsToSkip: [] stepSize: 1 center_read: False samFlag_include: None samFlag_exclude: None minFragmentLength: 0 maxFragmentLength: 0 zerosToNans: False smoothLength: None save_data: False out_file_for_raw_data: None maxPairedFragmentLength: 1016 . | . ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#output",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#output"
  },"190": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "bigwigCompare and bamCompare",
    "content": ". | bigwigCompare compares two bigWig files based on the number of mapped reads. To compare the bigWig files, the genome is partitioned into bins of equal size, then the number of reads found in each BAM file are counted per bin and finally a summary value is reported. Similarly, bamCompare can be used to generate a bigWig or bedGraph file based on two BAM files that are compared to each other while being simultaneously normalized for sequencing depth. Use the following command to compare two bigWigs or two BAMs: . # bigwigCompare $ bigwigCompare -b1 &lt;target.bigwig&gt; -b2 &lt;control.bigwig&gt; --operation &lt;ratio&gt; \\ -o &lt;output.bigwig&gt; -p &lt;INT&gt; # bamCompare $ bamCompare -b1 &lt;target.bam&gt; -b2 &lt;control.bam&gt; --operation &lt;ratio&gt; \\ -o &lt;output.bigwig&gt; -p &lt;INT&gt; . | In these commands, . | Parameter | Description | . | -b1 &lt;target.bigwig&gt; | Specifies the bigwig or the sorted BAM file for the target/treatment. | . | -b2 &lt;control.bigwig&gt; | Specifies the bigwig or the sorted BAM file for the control. | . | ---operation &lt;ratio&gt; | Specifies how to determine two values are compared.Possible values for &lt;ratio&gt; are log2, ratio, substrate, add, or mean (default: log2). | . | -o &lt;output.bigwig&gt; | Specifies output file. | . | -p &lt;int&gt; | Specifies thread numbers &lt;int&gt; | . | . ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#bigwigcompare-and-bamcompare",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#bigwigcompare-and-bamcompare"
  },"191": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "Example code (Results are not printed)",
    "content": ". | Here is an example command to perform bigwigCompare and bamCompare: . # bigwigCompare $ bigwigCompare -b1 /Users/jchoi/desktop/Unt_H3K4me3.bigwig \\ -b2 /Users/jchoi/desktop/Unt_IPT.bigwig --operation log2 \\ -o /Users/jchoi/desktop/Matrix/Unt_IPT_H3K4me3.bigwig -p 10 $ bigwigCompare -b1 /Users/jchoi/desktop/Unt_H3K27me3.bigwig \\ -b2 /Users/jchoi/desktop/Unt_IPT.bigwig --operation log2 \\ -o /Users/jchoi/desktop/Matrix/Unt_IPT_H3K27me3.bigwig -p 10 # bamCompare $ bamCompare -b1 /Users/jchoi/desktop/BAM/Sorted.Unt_NFIB.bam \\ -b2 /Users/jchoi/desktop/BAM/Sorted.Unt_IPT.bam --operation log2 \\ -o /Users/jchoi/desktop/BAM/Matrix/Unt_IPT_NFIB.bigwig -p 10 $ bamCompare -b1 /Users/jchoi/desktop/BAM/Sorted.Unt_MLL1.bam \\ -b2 /Users/jchoi/desktop/BAM/Sorted.Unt_IPT.bam --operation log2 \\ -o /Users/jchoi/desktop/BAM/Matrix/Unt_IPT_MLL1.bigwig -p 10 . | . ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#example-code-results-are-not-printed",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#example-code-results-are-not-printed"
  },"192": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "computeMatrix: Prepare matrix data",
    "content": ". | computeMatrix calculates scores per genome regions and prepares an intermediate file that can be used with plotHeatmap and plotProfiles. computeMatrix accepts multiple score files (bigWig format) and multiple regions files (BED format). This tool can also be used to filter and sort regions according to their score. Use the following command to make a matrix data using bigWig files generated from bigwigCompare: . $ computeMatrix &lt;mode&gt; --referencePoint &lt;point&gt; -b &lt;int&gt; -a &lt;int&gt; -R &lt;referenceGenome&gt; \\ -S &lt;bigwigCompared_1.bigwig&gt;...&lt;bigwigCompared_N.bigwig&gt; \\ --skipZeros --missingDataAsZero -o &lt;matrix file.gz&gt; -p &lt;int&gt; . | In these commands, . | Parameter | Description | . | &lt;mode&gt; | Possible values are reference-point or scale-regions. See the bellow | . | --referencePoint &lt;point&gt; | Specifies a reference point. The reference point for the plotting could be either the region start (TSS), the region end (TES) or the center of the region. | . | -b &lt;int&gt; | Distance upstream of the reference-point selected. | . | -a &lt;int&gt; | Distance downstream of the reference-point selected. | . | -R &lt;referenceGenome&gt; | File name or names, in BED or GTF format, containing the regions to plot. It is recommend to use the GTF file obtained in the htseeq-count step. | . | -S &lt;bigwigCompared_1.bigwig&gt;...&lt;bigwigCompared_N.bigwig&gt; | specifies input data, it is separated by spaces. These files should be obtained by using the bamCoverage or bamCompare modules. | . | --skipZeros option | Whether regions with only scores of zero should be included or not. | . | --missingDataAsZero option | If set, missing data (NAs) will be treated as zeros. | . | -o &lt;matrix file.gz&gt; | Specifies output file. The matrix file must have a ‘gz’ extension. | . | -p &lt;int&gt; | Specifies thread numbers &lt;int&gt; | . The reference-point mode plots genomic positions upstream and downstream from a specified position within a genome region, such as the starting point. Conversely, the scale-regions mode adjusts all regions in the genome file to a user-defined length, stretching or shrinking them as necessary. | . ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#computematrix-prepare-matrix-data",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#computematrix-prepare-matrix-data"
  },"193": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "Example code",
    "content": ". | Here is an example command to prepare a matrix data with computeMatrix: . # Mouse, reference-point mode, TSS, TF ChIP-seq $ computeMatrix reference-point --referencePoint TSS -b 3000 -a 3000 \\ -R /Users/jchoi/desktop/RefGene/mm10.refGene.gtf -S IPT_shCtrl_rep1.bigwig IPT_shCtrl_rep2.bigwig IPT_shNFIB_rep1.bigwig IPT_shNFIB_rep2.bigwig \\ --skipZeros --missingDataAsZero -o /Users/jchoi/desktop/bigWig/Matrix/matrix_TSS.gz -p 10 # Rice, reference-point mode, TES, histone ChIP-seq $ computeMatrix reference-point --referencePoint TES -b 3000 -a 3000 \\ -R /Users/jchoi/Desktop/ProfYoon/O_Sativa_Genome/RGAP_Used/all.gtf \\ -S /Users/jchoi/Desktop/ProfYoon/ChIPSeq_Track/LowBin_WTe.bigwig /Users/jchoi/Desktop/ProfYoon/ChIPSeq_Track/LowBin_ehd1e.bigwig \\ --skipZeros --missingDataAsZero -o /Users/jchoi/Desktop/matrix_TES.gz -p 10 . | . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#example-code-1",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#example-code-1"
  },"194": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "Output",
    "content": ". | This code does not output any results or progress, but sometimes you will see a message like the one below: Skipping XX_XXXXXX_XX, due to being absent in the computeMatrix output. Skipping NR_164356_11, due to being absent in the computeMatrix output. | Ignore these mentions because they mean missing data and has been processed by --skipZeros and --missingDataAsZero commands. | . ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#output-1",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#output-1"
  },"195": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "plotHeatmap",
    "content": ". | plotHeatmap creates a heatmap for scores associated with genomic regions. The program requires a matrix file generated by the computeMatrix. Use the following command to make a heatmap: . $ plotHeatmap -m &lt;matrixFile.gz&gt; -out &lt;output.extention&gt; --colorMap &lt;colorCode&gt; --colorList &lt;\"colorCode\"&gt; \\ --whatToShow &lt;'type'&gt; --zMin &lt;group1 ... groupN&gt; --zMax &lt;group1 ... groupN&gt; \\ --yMin &lt;group1 ... groupN&gt; --yMax &lt;group1 ... groupN&gt; \\ --kmeans &lt;int&gt; --perGroup --dpi &lt;int&gt; . | In these commands, . | Parameter | Description | . | -m &lt;matrixFile.gz&gt; | Specifies matrix file. | . | -out &lt;output.extention&gt; | Specifies output file. Possible values for file extention are png, eps, pdf, and svg. | . | --colorMap &lt;colorCode&gt; | Color map to use for the heatmap. If more than one heatmap is being plotted the color of each heatmap can be enter individually (e.g. –colorMap Reds Blues). Available color codes | . | --colorList &lt;colorCode&gt; | List of colors to use to create a colormap. For example, if –colorList black,yellow,blue is set (colors separated by comas) then a color map that starts with black, continues to yellow and finishes in blue is created. You can also use hexagonal color codes (#000000). | . | --whatToShow &lt;'type'&gt; | The default is to include a summary or profile plot on top of the heatmap and a heatmap colorbar. Other options are 'plot and heatmap', 'heatmap only', and 'heatmap and colorbar'. Not recommended for use. | . | --zMin/--zMax option | adjust heatmap intensities. If more than one heatmap is being plotted the intensity of each heatmap can be enter individually. | . | --yMin/--yMax option | adjust plot range of the y-axis. If more than one heatmap is being plotted the intensity of each heatmap can be enter individually. | . | --kmeans &lt;int&gt; | Number of clusters to compute. When this option is set, the matrix is split into clusters using the k-means algorithm. --hclustoption is also possible for Hierarchical clustering. | . | --perGroup option | The default is to plot all groups of regions by sample. Using this option instead plots all samples by group of regions. | . | . ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#plotheatmap",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#plotheatmap"
  },"196": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "Example Code (Results are not printed)",
    "content": ". | Here is an example command to plot heatmap with plotHeatmap: . $ plotHeatmap -m /Users/jchoi/desktop/bigWig/Matrix/matrix_TSS.gz \\ -out /Users/jchoi/desktop/Distribution.svg --colorMap RdBu --zMin -1 --zMax 6 --yMin 0 --yMax 4 --dpi 300 $ plotHeatmap -m /Users/jchoi/desktop/bigWig/Matrix/matrix_TSS.gz \\ -out /Users/jchoi/desktop/Distribution_heatmap.svg --colorMap RdBu --whatToShow 'heatmap only' --zMin -1 --zMax 6 --kmeans 3 --dpi 300 $ plotHeatmap -m /Users/jchoi/Desktop/matrix_TSS.gz -out /Users/jchoi/Desktop/Rice_H3ac.svg --colorList \"white,#bd1829\" --yMin 20 --yMax 50 --zMin 40 . | . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#example-code-results-are-not-printed-1",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#example-code-results-are-not-printed-1"
  },"197": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "plotProfile",
    "content": ". | plotProfile creates a profile plot for scores over sets of genomic regions. This is a simplified version of the plotHeatmap provided above that only plots individual line graphs. The parameters for this function are quite similar to others, so I will keep the explanation brief without example code. Unfortunately, plotProfile is currently not used by many users. $ plotProfile -m &lt;matrix file.gz&gt; -out &lt;output.extention&gt; --plotType=&lt;select&gt; --color &lt;'color code'&gt; --numPlotsPerRow &lt;int&gt; --plotTitle &lt;\"Test data profile\"&gt; --kmeans &lt;int&gt; --perGroup --dpi &lt;int&gt; . | In these commands, . | --plotType=&lt;select&gt;: Possible values are lines, fill, se, std, overlapped_lines, and heatmap. | --color &lt;'color code'&gt;: List of colors to use for the plotted lines (color names or hex strings). For example --colors '#e89b81' '#959dc8' '#f6f0a8' | --numPlotsPerRow &lt;int&gt;: Number of plots per row | . Critical Note . | Overall, the plotHeatmap and plotProfile functions, powered by computeMatrix, are commonly used to visualize the tag distribution of peaks and are featured prominently in numerous publications. | However, for more detailed analysis, I recommend using Python-based ngs.plot.r or the ChIPseeker R package , which offer enhanced detail and additional analytical capabilities. | . | . ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#plotprofile",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#plotprofile"
  },"198": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "multiBigwigSummary and multiBamSummary",
    "content": ". | multiBigwigSummary and multiBamSummary compute the average score/read coverages for genomic regions for two or more bigWig and BAM files, respectively. This analysis is performed for the entire genome by running the program in bins mode, or for certain user selected regions in BED-file mode. Most commonly, the default output of multiBigwigSummary (a compressed numpy array, .npz) is used by other tools such as plotCorrelation or plotPCA for visualization and diagnostic purposes. Use the following command to make a summary matrix from bigWig files with multiBigwigSummary: . $ multiBigwigSummary bins -b &lt;file1.bigwig&gt;...&lt;fileN.bigwig&gt; -l &lt;file1&gt;...&lt;fileN&gt; -o &lt;results.npz&gt; $ multiBamSummary bins -b &lt;file1.bam&gt;...&lt;fileN.bam&gt; -l &lt;file1&gt;...&lt;fileN&gt; -e -o &lt;results.npz&gt; . | In these commands, . | -b &lt;file1.bigwig&gt;...&lt;fileN.bigwig&gt;: Specifies input data, it is separated by spaces. | -l &lt;file1&gt;...&lt;fileN&gt;: User defined labels instead of default labels from file names. Multiple labels have to be separated by a space. | -o &lt;results.npz&gt;: Specifies output data as npz format. | -eoption: only multiBamSummary, allows the extension of reads to fragment size. | . | . ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#multibigwigsummary-and-multibamsummary",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#multibigwigsummary-and-multibamsummary"
  },"199": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "Example Code (Results are not printed)",
    "content": ". | Here is an example command to make a coverage matrix with multiBigwigSummary: . $ multiBigwigSummary bins -b shControl_Input.bigwig shControl_H3K4me3.bigwig shNFIB_H3K4me3.bigwig shMLL1_H3K4me3.bigwig \\ -l Input shControl shNFIB shMLL1 -o /Users/jchoi/Desktop/CorrMatrix.npz . | . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#example-code-results-are-not-printed-2",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#example-code-results-are-not-printed-2"
  },"200": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "plotCorrelation",
    "content": ". | plotCorrelationanalyzes and visualizes sample correlations based on the output of multiBamSummary or multiBigwigSummary. Pearson or Spearman methods are available to compute correlation coefficients. Use the following command to perform plotting for correlation with plotCorrelation: . $ plotCorrelation -in &lt;CorrMatrix.npz&gt; --corMethod &lt;select&gt; --skipZeros --whatToPlot &lt;type&gt; \\ --removeOutliers --colorMap &lt;color&gt; --plotNumbers -o &lt;output.extention&gt; --outFileCorMatrix &lt;matrix_name.tab&gt; . | In these commands, . | Parameter | Description | . | -in &lt;CorrMatrix.npz&gt; | Specifies a coverage matrix file. | . | ---corMethod &lt;select&gt; | Specifies a correlation method. Possible values for &lt;select&gt; are spearman and pearson. | . | --skipZeros option | By setting this option, genomic regions that have zero or missing (NaN) values in all samples are excluded. | . | --whatToPlot &lt;type&gt; | Choose between a heatmap or pairwise scatter plots. Possible values for &lt;type&gt; are heatmap and scatterplot. | . | --removeOutliers option | If set, bins with very large counts are removed (only pearson). | . | --colorMap &lt;color&gt; | Color map to use for the heatmap. | . | --zMin/--zMax option | adjust heatmap intensities. If not specified, the value is set automatically. | . | --xRange/--yRange option | adjust plot range of the x/y-axis. If not specified, the value is set automatically. | . | --plotNumbers option | If set, then the correlation number is plotted on top of the heatmap (only heatmap). | . | -o &lt;output.extention&gt; | Specifies output file. Possible values for file extention are png, eps, pdf, and svg (recommended). | . | --outFileCorMatrix &lt;matrix_name.tab&gt; | Save matrix with pairwise correlation values to a tab-separated file. | . | . ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#plotcorrelation",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#plotcorrelation"
  },"201": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "Example Code (Results are not printed)",
    "content": ". | Here is an example command to make a correlation plot with plotCorrelation: # Heatmap, Pearson r $ plotCorrelation -in /Users/jchoi/Desktop/CorrMatrix.npz --corMethod pearson --skipZeros \\ --whatToPlot heatmap --removeOutliers --colorMap RdYlBu --plotNumbers \\ -o /Users/jchoi/Desktop/heatmap_PearsonCorr.svg --outFileCorMatrix /Users/jchoi/Desktop/heatmap_PearsonCorr.tab # Scatter plot, Spearman r $ plotCorrelation -in /Users/jchoi/Desktop/CorrMatrix.npz --corMethod spearman --skipZeros \\ --whatToPlot scatterplot --colorMap RdYlBu -o /Users/jchoi/Desktop/heatmap_SpearmanCorr.svg \\ --outFileCorMatrix /Users/jchoi/Desktop/heatmap_SpearmanCorr.tab . | . ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#example-code-results-are-not-printed-3",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#example-code-results-are-not-printed-3"
  },"202": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "Citations",
    "content": "deeptools . | Ramírez, F., Dündar, F., Diehl, S., Grüning, B. A., &amp; Manke, T. (2014). deepTools: a flexible platform for exploring deep-sequencing data. Nucleic acids research, 42(W1), W187-W191. DOI | Ramírez, F., Ryan, D. P., Grüning, B., Bhardwaj, V., Kilpert, F., Richter, A. S., ... &amp; Manke, T. (2016). deepTools2: a next generation web server for deep-sequencing data analysis. Nucleic acids research, 44(Web Server issue), W160. DOI | . ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/#citations",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/#citations"
  },"203": {
    "doc": "Exploring Sequencing Data with deepTools",
    "title": "Exploring Sequencing Data with deepTools",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/ChIPSeq/deepTools_MANUAL/",
    
    "relUrl": "/docs/ChIPSeq/deepTools_MANUAL/"
  },"204": {
    "doc": "Feature counts with htseqCount",
    "title": "Counting Reads in Features with htseq-count",
    "content": "HTSeq is a Python library designed to process and analyze data from high-throughput sequencing (HTS) experiments. This tool counts the number of reads mapping to each genomic feature. It requires input files, such as BAM files sorted by name or position, to be provided. To ensure comprehensive analysis and avoid zero-frequency issues, it is crucial to include all relevant input files (e.g., control, treat A, treat B, … , treat N) consecutively. While this operation did not require high CPU usage, demands higher memory (&gt; 16 Gb) to fast count the reads (i.e. this step takes a very long times, approx. 6 hrs on 12 samples). This protocol was created based on HTseq version 0.11.1 running on a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes Python version 3.8.5, SciPy version 1.6.2, NumPy version 1.20.1, and pySam version 0.16.0.1 under macOS 12.4 environment. ",
    "url": "/docs/DataProcess/htseqCount_MANUAL/#counting-reads-in-features-with-htseq-count",
    
    "relUrl": "/docs/DataProcess/htseqCount_MANUAL/#counting-reads-in-features-with-htseq-count"
  },"205": {
    "doc": "Feature counts with htseqCount",
    "title": "Installation HTSeq",
    "content": ". To install HTSeq via anaconda or PyPI, use the following commands: . $ conda install -c bioconda htseq # OR $ pip install HTSeq . ",
    "url": "/docs/DataProcess/htseqCount_MANUAL/#installation-htseq",
    
    "relUrl": "/docs/DataProcess/htseqCount_MANUAL/#installation-htseq"
  },"206": {
    "doc": "Feature counts with htseqCount",
    "title": "Obtain a Gene Annotated File from Ensembl",
    "content": ". | Select a desire species in the section of All genome from Ensemble website. | Click “Download GTF (or GTF3)” in the Gene annotation section. | An FTP server appears where you can download the GTF files. | The GTF files that can be used for RNA-seq analysis have the following names: [species].[species version].[release version].gtf.gz. (e.g. human: Homo_sapiens.GRCh38.111.gtf.gz, mouse: Mus_musculus.GRCm39.111.gtf.gz, zebrafish: Danio_rerio.GRCz11.111.gtf.gz) | Download and uncompress (optional) it and move desired folder. | . Users may find it more convenient to download GTF files for human and mouse transcriptome analysis from “gencode”. ",
    "url": "/docs/DataProcess/htseqCount_MANUAL/#obtain-a-gene-annotated-file-from-ensembl",
    
    "relUrl": "/docs/DataProcess/htseqCount_MANUAL/#obtain-a-gene-annotated-file-from-ensembl"
  },"207": {
    "doc": "Feature counts with htseqCount",
    "title": "Running htseq-count",
    "content": "Use the following command to perform counting transcripts in mapped genome with htseq-count: . $ htseq-count -f &lt;format&gt; --strand=&lt;yes/no&gt; --mode=&lt;mode&gt; -r &lt;name/pos&gt; \\ &lt;input_1.bam&gt;...&lt;input_N&gt; &lt;AnnotateFile.gtf&gt; &gt; &lt;output.txt&gt; . In these commands, . | Parameter | Description | . | -f &lt;format&gt; | Specifies format of the input data. Possible values are SAM or BAM. | . | --strand=&lt;strand&gt; | Specifies whether the data is from a strans-specific assay. Possible value for &lt;strand&gt;are yes, no, and reverse. (default: yes). | . | --mode=&lt;mode&gt; | Mode to handle reads overlapping more than one feature. Possible values for &lt;mode&gt; are union, intersection-strict and intersection-nonempty (default: union). Several researchers most used as intersection-nonempty. Overlapping methods refer as bellow table. | . | -r &lt;order&gt; | Specifies how the BAM files are sorted. The BAM files used in this operation must be sorted either by name (name) or position (pos). As ‘name’ option expects all the alignments to appear in adjacent records in input, most users use name. | . | &lt;input_1.bam&gt;...&lt;input_N&gt; | Specifies input data, it is separated by spaces. | . | &lt;AnnotateFile.gtf&gt; | For count the reads, must be required gene annotation files as a GTF format. | . | &gt; &lt;output.txt&gt; | Specifies output file, this file generates as a plain text file. &gt; symbol must appear before the &lt;output.txt&gt; syntax. | . ",
    "url": "/docs/DataProcess/htseqCount_MANUAL/#running-htseq-count",
    
    "relUrl": "/docs/DataProcess/htseqCount_MANUAL/#running-htseq-count"
  },"208": {
    "doc": "Feature counts with htseqCount",
    "title": "Overlapping Table",
    "content": "The following table illustrates the effect of these three modes (union, intersection-strict and intersection-nonempty) : . ",
    "url": "/docs/DataProcess/htseqCount_MANUAL/#overlapping-table",
    
    "relUrl": "/docs/DataProcess/htseqCount_MANUAL/#overlapping-table"
  },"209": {
    "doc": "Feature counts with htseqCount",
    "title": "Example Code",
    "content": "Here is an example command to perform htseq-count with the zebrafish genome on 4 samples: . $ htseq-count -f bam --strand=no --mode=intersection-nonempty -r name \\ sort_MA_rep1.bam sort_MA_rep2.bam sort_Y_rep1.bam sort_Y_rep2.bam \\ /Users/jchoi/Desktop/Danio_rerio.GRCz11.111.gtf &gt; /Users/jchoi/Desktop/Age.txt . | When htseq-count is running, it will print out the progress in real time. The output is very long, so I will not describe it. | . Enter your code: Copy Clear ",
    "url": "/docs/DataProcess/htseqCount_MANUAL/#example-code",
    
    "relUrl": "/docs/DataProcess/htseqCount_MANUAL/#example-code"
  },"210": {
    "doc": "Feature counts with htseqCount",
    "title": "Citation",
    "content": "HTSeq . | Anders, S., Pyl, P. T., &amp; Huber, W. (2015). HTSeq—a Python framework to work with high-throughput sequencing data. bioinformatics, 31(2), 166-169. DOI | . ",
    "url": "/docs/DataProcess/htseqCount_MANUAL/#citation",
    
    "relUrl": "/docs/DataProcess/htseqCount_MANUAL/#citation"
  },"211": {
    "doc": "Feature counts with htseqCount",
    "title": "Feature counts with htseqCount",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/DataProcess/htseqCount_MANUAL/",
    
    "relUrl": "/docs/DataProcess/htseqCount_MANUAL/"
  },"212": {
    "doc": "Home",
    "title": "Hello! I’m Janghyun Choi",
    "content": " ",
    "url": "/#hello-im-janghyun-choi",
    
    "relUrl": "/#hello-im-janghyun-choi"
  },"213": {
    "doc": "Home",
    "title": "A dedicated explorer in the field of molecular biology with a Ph.D.",
    "content": ". This fluorescent image shows H3K4me3 (green), actin (red), and the nucleus (blue). © 2024 Janghyun Choi. All rights reserved. My portfolio centers on my work with sequencing data—processing and analyzing to uncover meaningful patterns and insights. This page serves as a brief introduction to who I am: someone who skillfully applies molecular tools to solve complex problems in genomics. Dive into my work and discover the impact of precision and innovation. Read More Github . ",
    "url": "/",
    
    "relUrl": "/"
  },"214": {
    "doc": "Home",
    "title": "Home",
    "content": ". ",
    "url": "/",
    
    "relUrl": "/"
  },"215": {
    "doc": "Efficient Analysis and Visualization with ngs.plot",
    "title": "Efficient Analysis and Visualization of ChIP-seq Data via Genomic Databases",
    "content": "The ‘ngs.plot’ tool is a specialized resource designed to enhance the visualization and analysis of next-generation sequencing (NGS) data. This tool is particularly adept at quickly accessing and integrating large genomic databases to plot dense NGS data against a backdrop of functional genomic elements. One of the primary advantages of ‘ngs.plot’ is its ability to manage and visualize complex datasets with ease and precision. Users can rapidly generate high-quality plots of genomic regions of interest, which is critical for interpreting interactions and expression levels in various genomic studies, such as ChIP-seq and RNA-seq analyses. This protocol was created based on ngs.plot version 2.61 running on a system equipped with an Intel 10th generation i9-10910 processor and 48GB of memory. The test environment includes Python version 3.8.5, Perl version 5.26.2, and R version 4.4.0 under macOS 12.4 environment. ",
    "url": "/docs/ChIPSeq/ngsplot_MANUAL/#efficient-analysis-and-visualization-of-chip-seq-data-via-genomic-databases",
    
    "relUrl": "/docs/ChIPSeq/ngsplot_MANUAL/#efficient-analysis-and-visualization-of-chip-seq-data-via-genomic-databases"
  },"216": {
    "doc": "Efficient Analysis and Visualization with ngs.plot",
    "title": "Step-by-Step Installation",
    "content": ". 1. Download ngs.plot package from GDrive (Official) to a desired folder and exract it as follow. $ cd downloads $ tar xvfz ngsplot-2.61.tar.gz $ mv ngsplot-2.61 /Users/jchoi/ngsplot . 2. Add ngsplot executables to your path under zshrc. $ nano ~/.zshrc # Add syntax as follows; export PATH=\"/your/path/to/ngsplot/bin:$PATH\" export NGSPLOT=\"/your/path/to/ngsplot\" # For example export PATH=\"/Users/Desktop/ChIP_seq/ngsplot/bin:$PATH\" export NGSPLOT=\"/Users/Desktop/ChIP_seq/ngsplot\" . 3. save and reload shell environment as follow. $ source ~/.zshrc . 4. Install ngs.plot dependent libraries in R. install.packages(\"doMC\", dep=T) install.packages(\"caTools\", dep=T) install.packages(\"utils\", dep=T) BiocManager::install(\"BSgenome\") BiocManager::install(\"Rsamtools\") BiocManager::install(\"ShortRead\") . 5. Prepare Genome Database. | Download desired genome database from GDrive (Official). | Install this file as follows: | . $ ngsplotdb.py list # check current list ID Assembly Species EnsVer NPVer InstalledFeatures hg19 GRCh37 homo_sapiens 75.0 3.0 cgi,exon,genebody,tss,tes IRGSP-1 IRGSP-1.0 oryza_sativa 21.0 3.0 exon,genebody,tss,tes $ ngsplotdb.py install /Users/jchoi/Downloads/ngsplotdb_mm10_75_3.00.tar.gz # install databse $ ngsplotdb.py list # check the installed database ID Assembly Species EnsVer NPVer InstalledFeatures hg19 GRCh37 homo_sapiens 75.0 3.0 cgi,exon,genebody,tss,tes IRGSP-1 IRGSP-1.0 oryza_sativa 21.0 3.0 exon,genebody,tss,tes mm10 GRCm38 mus_musculus 75.0 3.0 cgi,exon,genebody,tss,tes . This tool may occasionally experience malfunctions. These are predominantly attributed to issues with Python syntax, and the author swiftly addresses and resolves these concerns by issuing updated source code. Should the tool cease to function abruptly, it is advisable to consult the creator’s GitHub repository. Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/ngsplot_MANUAL/#step-by-step-installation",
    
    "relUrl": "/docs/ChIPSeq/ngsplot_MANUAL/#step-by-step-installation"
  },"217": {
    "doc": "Efficient Analysis and Visualization with ngs.plot",
    "title": "Running ngs.plot",
    "content": ". | Use the following command to visulize enriched peaks from ChIP-seq data with ngs.plot: . $ ngs.plot.r -G &lt;genome&gt; -R &lt;region&gt; -C &lt;IndexedInput.bam&gt; -O &lt;outputFolder&gt; &lt;OptionalParameters&gt; . | In these commands, . | Parameter | Description | . | -G &lt;Genome&gt; | Specifies the genome name. Use ngsplotdb.py list to show available genomes. See the Step-by-step Installation section. | . | -R &lt;region&gt; | Specifies genomic regions to plot. Possible values for region are tss, tes, genebody, exon, cgi, and enhancer. | . | -C &lt;IndexedInput.bam&gt; | Specifies the input file. This file reqires an indexed BAM file for single plot or a specific configuration file for multiplot (See the below). | . | -O &lt;outputFolder&gt; | Specifies the output file. Several files will be generated. | . | Prepare a configuration file and save as plaintext (name.txt) as follow: . # If you want to specify the gene list as \"genome\", use \"-1\". # Use TAB to separate the three columns: coverage file&lt;TAB&gt;gene list&lt;TAB&gt;title # \"title\" will be shown in the figure's legend. hesc.H3k4me3.rmdup.sort.bam high_expressed_genes.txt \"High\" hesc.H3k4me3.rmdup.sort.bam medium_expressed_genes.txt \"Med\" hesc.H3k4me3.rmdup.sort.bam low_expressed_genes.txt \"Low\" . | Major Optional Parameters (&lt;OptionalParameter&gt;) . | Parameter | Description | . | -T &lt;Title&gt; | Specifies image title (Default: NoName). | . | -L &lt;int&gt; | Specifies size in bps. By default, when -R tss, tes, genebody, -L 2000; when -R exon, cgi, -L 500. | . | -P &lt;int&gt; | Specifies 0 to use all CPUs that are detected on your machine. | . | -FL &lt;int&gt; | This parameter calculates physical instead of read coverage. This will produce figures that contain more accurate representation of ChIP enrichment. You should set this value equal to the average fragment length in your sequencing library (Default: 150). | . | -LEG &lt;int&gt; | Control the display of legend: 1 (default) or 0 (No legend). | . | -VLN &lt;int&gt; | Control the display of vertical lines: 1 (default) or 0 (No line). | . | For more detailed parameter options, see the ProgramArguments101. | . ",
    "url": "/docs/ChIPSeq/ngsplot_MANUAL/#running-ngsplot",
    
    "relUrl": "/docs/ChIPSeq/ngsplot_MANUAL/#running-ngsplot"
  },"218": {
    "doc": "Efficient Analysis and Visualization with ngs.plot",
    "title": "Example Code",
    "content": ". | Here is an example command to depict peaks distribution: . # Single plot $ ngs.plot.R -G mm10 -R genebody -C /Users/jchoi/Desktop/R_FINAL.bam -O /Users/jchoi/Desktop/NFIB \\ -T NFIB -L 2000 -SE 0 -FL 100 -LEG 0 -VLN 0 # Multiplot ## Configuration file, H3K4_K27.txt Final.sort.H2O2_H3K27me3.bam:Final.sort.Unt_IPT.bam -1 \"H3K27me3\" Final.sort.H2O2_H3K4me3.bam:Final.sort.Unt_IPT.bam -1 \"H3K4me3\" ## Command $ ngs.plot.r -G hg19 -R genebody -C H3K4_K27.txt -O /Users/jchoi/Desktop/Bivalency \\ -L 3000 -SE 0 -FL 100 -LEG 0 -VLN 0 -YAS -0.4,1.5 -SC -2,4 . | . Enter your code: Copy Clear ",
    "url": "/docs/ChIPSeq/ngsplot_MANUAL/#example-code",
    
    "relUrl": "/docs/ChIPSeq/ngsplot_MANUAL/#example-code"
  },"219": {
    "doc": "Efficient Analysis and Visualization with ngs.plot",
    "title": "Example Plot",
    "content": "The graph created using the second (multiplot) of the example codes above, refined using Illustrator 2024. ",
    "url": "/docs/ChIPSeq/ngsplot_MANUAL/#example-plot",
    
    "relUrl": "/docs/ChIPSeq/ngsplot_MANUAL/#example-plot"
  },"220": {
    "doc": "Efficient Analysis and Visualization with ngs.plot",
    "title": "Citation",
    "content": "ngsplot . | Shen, L., Shao, N., Liu, X., &amp; Nestler, E. (2014). ngs. plot: Quick mining and visualization of next-generation sequencing data by integrating genomic databases. BMC genomics, 15, 1-14. DOI | . ",
    "url": "/docs/ChIPSeq/ngsplot_MANUAL/#citation",
    
    "relUrl": "/docs/ChIPSeq/ngsplot_MANUAL/#citation"
  },"221": {
    "doc": "Efficient Analysis and Visualization with ngs.plot",
    "title": "Efficient Analysis and Visualization with ngs.plot",
    "content": "© 2022 Janghyun Choi . ",
    "url": "/docs/ChIPSeq/ngsplot_MANUAL/",
    
    "relUrl": "/docs/ChIPSeq/ngsplot_MANUAL/"
  }
}
